<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Ten's Thoughts]]></title><description><![CDATA[Just another Dev blog]]></description><link>https://blog.tenzhiyang.com</link><generator>GatsbyJS</generator><lastBuildDate>Wed, 10 Feb 2021 06:50:13 GMT</lastBuildDate><item><title><![CDATA[Hacking together auto posting to dev.to from my blog]]></title><description><![CDATA[In order to increase my online presence, I decided to create a dev.to account. I’ve never posted on medium before so I can’t compare the…]]></description><link>https://blog.tenzhiyang.com/2021-02-10-blog-auto-post/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2021-02-10-blog-auto-post/</guid><pubDate>Wed, 10 Feb 2021 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;In order to increase my online presence, I decided to create a dev.to account. I’ve never posted on medium before so I can’t compare the experience from one platform to another, but dev.to was pretty intuitive. However, I already have somewhat of a content creation flow right here on my blog, and I tried manually cross posting, but I didn’t really like the whole doing one thing twice. Hence I decided to hack up some auto posting script. With some luck, you’ll be reading this post itself on dev.to!&lt;/p&gt;
&lt;h2&gt;Existing blog setup&lt;/h2&gt;
&lt;p&gt;I’m a very very lazy dev, and my blog really is for me to throw things together, so don’t expect a production ready system here. I’ve tinkered around with it a bit, so I don’t fully remember what came out of the box when I started this gatsby blog, but I’ll list out things that are relevant to this task.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Blog:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Starter for a blog powered by Gatsby and Markdown from &lt;a href=&quot;https://twitter.com/kylemathews&quot;&gt;Kyle Mathews&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;gatsby-plugin-feed (default configs)&lt;/li&gt;
&lt;li&gt;hosted on digital ocean&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Digital ocean server&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Nginx reverse proxy-ing a few web apps and some simple nodejs scripts&lt;/li&gt;
&lt;li&gt;cron job that pulls my latest build from my gatsby blog (a hacked imitation of CI, ideally you will use github’s webhooks to push to the server and have the server run the build script, but I ran into issues building on my lowest tier DO server, but hey, if it works it works)&lt;/li&gt;
&lt;li&gt;nodejs script that automates some tasks for me&lt;/li&gt;
&lt;li&gt;Fetches my RSS feed from my blog every 5 mins and caches the response in memory&lt;/li&gt;
&lt;li&gt;Tweets for me if there’s a new blog post since the last cache&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Changes made&lt;/h2&gt;
&lt;p&gt;I won’t provide the code snippets for this project as I’m not confident it will work as of writing this blog, but I will layout the steps I did and hopefully this will help someone out there.&lt;/p&gt;
&lt;h3&gt;Get my api key from dev to&lt;/h3&gt;
&lt;p&gt;Following the &lt;a href=&quot;https://docs.dev.to/api/&quot;&gt;docs&lt;/a&gt;, I went to my settings &gt; account &gt; generate api key. I entered this key into my .env for my nodejs script.&lt;/p&gt;
&lt;h3&gt;Modify RSS feeds to include raw markdown&lt;/h3&gt;
&lt;p&gt;Initially I had the default settings of gatsby-plugin-feed. I copied the configuration from &lt;a href=&quot;https://www.gatsbyjs.com/plugins/gatsby-plugin-feed/&quot;&gt;https://www.gatsbyjs.com/plugins/gatsby-plugin-feed/&lt;/a&gt;. Comparing this output with my existing output, I found that it was exactly the same, so I was confident I wouldn’t break anything that’s currently working. Checking my graphql queries locally, I found that I could directly query &lt;code class=&quot;language-text&quot;&gt;rawMarkdownBody&lt;/code&gt; I added that into the query in the config, as well as &lt;code class=&quot;language-text&quot;&gt;{&amp;quot;content:raw&amp;quot;: edge.node.rawMarkdownBody}&lt;/code&gt; to &lt;code class=&quot;language-text&quot;&gt;custom_elements&lt;/code&gt;. I then checked by building my site locally.&lt;/p&gt;
&lt;h3&gt;Modify nodejs script&lt;/h3&gt;
&lt;p&gt;I knew that the script was already capable of tweeting when I posted a new post and I could get any information from my blog as long as it was in the RSS feed, so I wrote a function that sends a POST request to the &lt;code class=&quot;language-text&quot;&gt;https://dev.to/api/articles&lt;/code&gt; endpoint and added my &lt;code class=&quot;language-text&quot;&gt;api-key&lt;/code&gt; to my header. I then called this function where I implemented my twitter bot, passing in the title, canonical url, and content.&lt;/p&gt;
&lt;p&gt;That’s it! hopefully everything worked. I’ll probably update this if it didn’t.&lt;/p&gt;
&lt;h3&gt;Improvements&lt;/h3&gt;
&lt;p&gt;Assuming everything worked as planed, there are still a few changes I would want to make. The images being used will reference a relative url, so it will definitely not work in the dev.to article. I would also add tags and series to my front matter on my blog and pass it into the rss feed, and also the dev.to api.&lt;/p&gt;</content:encoded><content:raw>
In order to increase my online presence, I decided to create a dev.to account. I&apos;ve never posted on medium before so I can&apos;t compare the experience from one platform to another, but dev.to was pretty intuitive. However, I already have somewhat of a content creation flow right here on my blog, and I tried manually cross posting, but I didn&apos;t really like the whole doing one thing twice. Hence I decided to hack up some auto posting script. With some luck, you&apos;ll be reading this post itself on dev.to!

## Existing blog setup

I&apos;m a very very lazy dev, and my blog really is for me to throw things together, so don&apos;t expect a production ready system here. I&apos;ve tinkered around with it a bit, so I don&apos;t fully remember what came out of the box when I started this gatsby blog, but I&apos;ll list out things that are relevant to this task.

- Blog:
  - Starter for a blog powered by Gatsby and Markdown from [Kyle Mathews](https://twitter.com/kylemathews)
  - gatsby-plugin-feed (default configs)
  - hosted on digital ocean
- Digital ocean server
  - Nginx reverse proxy-ing a few web apps and some simple nodejs scripts
  - cron job that pulls my latest build from my gatsby blog (a hacked imitation of CI, ideally you will use github&apos;s webhooks to push to the server and have the server run the build script, but I ran into issues building on my lowest tier DO server, but hey, if it works it works)
  - nodejs script that automates some tasks for me
    - Fetches my RSS feed from my blog every 5 mins and caches the response in memory
    - Tweets for me if there&apos;s a new blog post since the last cache

## Changes made

I won&apos;t provide the code snippets for this project as I&apos;m not confident it will work as of writing this blog, but I will layout the steps I did and hopefully this will help someone out there.

### Get my api key from dev to

Following the [docs](https://docs.dev.to/api/), I went to my settings &gt; account &gt; generate api key. I entered this key into my .env for my nodejs script.

### Modify RSS feeds to include raw markdown

Initially I had the default settings of gatsby-plugin-feed. I copied the configuration from [https://www.gatsbyjs.com/plugins/gatsby-plugin-feed/](https://www.gatsbyjs.com/plugins/gatsby-plugin-feed/). Comparing this output with my existing output, I found that it was exactly the same, so I was confident I wouldn&apos;t break anything that&apos;s currently working. Checking my graphql queries locally, I found that I could directly query `rawMarkdownBody` I added that into the query in the config, as well as `{&quot;content:raw&quot;: edge.node.rawMarkdownBody}` to `custom_elements`. I then checked by building my site locally.

### Modify nodejs script

I knew that the script was already capable of tweeting when I posted a new post and I could get any information from my blog as long as it was in the RSS feed, so I wrote a function that sends a POST request to the `https://dev.to/api/articles` endpoint and added my `api-key` to my header. I then called this function where I implemented my twitter bot, passing in the title, canonical url, and content.

That&apos;s it! hopefully everything worked. I&apos;ll probably update this if it didn&apos;t.

### Improvements

Assuming everything worked as planed, there are still a few changes I would want to make. The images being used will reference a relative url, so it will definitely not work in the dev.to article. I would also add tags and series to my front matter on my blog and pass it into the rss feed, and also the dev.to api.</content:raw></item><item><title><![CDATA[Weekly solutions: product list class]]></title><description><![CDATA[I decided since I’ve been solving the interview questions on Cassidy’s weekly newsletter I might as well put a little bit more effort into…]]></description><link>https://blog.tenzhiyang.com/2021-02-09-product-list-class/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2021-02-09-product-list-class/</guid><pubDate>Tue, 09 Feb 2021 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;I decided since I’ve been solving the interview questions on &lt;a href=&quot;https://twitter.com/cassidoo&quot;&gt;Cassidy’s&lt;/a&gt; weekly &lt;a href=&quot;https://buttondown.email/cassidoo/archive/cc677716-37b2-4cfd-a691-bc6e87d7abce&quot;&gt;newsletter&lt;/a&gt; I might as well put a little bit more effort into writing my thought processes down, in the scenario where people are looking for a way to solve these. That’s my goal for this year. I’m not confident I can be consistent, but it doesn’t hurt to try!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This may or may not be the optimal solution, DO NOT blindly memorize my solutions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Target audience: beginners in js (please feedback!)&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This week’s question:
Implement a ProductList class that has two methods, add(n) (which pushes the value n to the back of the list) and product(m) (which returns the product of the last m numbers in the list). David made an awesome template for submitting your solutions, if you’d like to use it!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Usage:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;ProductList p = new ProductList();
p.add(7);         // [7]
p.add(0);         // [7,0]
p.add(2);         // [7,0,2]
p.add(5);         // [7,0,2,5]
p.add(4);         // [7,0,2,5,4]
p.product(3);     // return 40 because 2 * 5 * 4&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As someone who’s been writing nothing but JS for a while, the first thing that comes to mind is to make use of &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Closures&quot;&gt;lexical scope&lt;/a&gt; of JS functions to store the array. I can’t say I’m super familiar with the Scope and Closure terminologies, but I’m fairly aware of what they do and how to make use of them.&lt;/p&gt;
&lt;p&gt;so let’s create a list in a function.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;function ProductList() {
  this.list = [];
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;So to look at what’s happening with the array, we can write some driver code&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;let p = new ProductList();
let p2 = new ProductList();
console.log(p.list, p2.list); // [] []
p.list.push(1);
p.list.push(2);
console.log(p.list, p2.list); // [1, 2] []&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;so far so good, we know that using the &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/new&quot;&gt;new operator&lt;/a&gt; essentially creates an object with the &lt;code class=&quot;language-text&quot;&gt;this&lt;/code&gt; context from the function.  &lt;/p&gt;
&lt;p&gt;The next step we want to do is to add elements to the list from a function provided by ProductList instead of using the one from the array. We will return this function in a JSON object, as well as the list array (if not the list will be undefined, see link to new operator above)&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;function ProductList() {
  this.list = [];

  function add(num) {
    this.list.push(num);
  }
  return { add, list: this.list };
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If we change the &lt;code class=&quot;language-text&quot;&gt;p.list.push(1)&lt;/code&gt; in the driver code above to &lt;code class=&quot;language-text&quot;&gt;p.add(1)&lt;/code&gt; we should have the same result.&lt;/p&gt;
&lt;p&gt;Finally we need a product function to multiply all the elements in the list. We want the last &lt;code class=&quot;language-text&quot;&gt;n&lt;/code&gt; numbers, so we can have a for loop that increments up to &lt;code class=&quot;language-text&quot;&gt;n&lt;/code&gt; and create an index that starts from the back and gets smaller up till &lt;code class=&quot;language-text&quot;&gt;n&lt;/code&gt;. Plugging in the given driver code, we should get the correct solution.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;function ProductList() {
  this.list = [];

  function add(num) {
    this.list.push(num);
  }

  function product(n) {
    let result = null;
    for (let i = 0; i &amp;lt; n; i++) {
      const index = this.list.length - 1 - i;
      if (result === null) {
        result = this.list[index];
      } else {
        result *= this.list[index];
      }
    }
    return result;
  }
  return { add, list: this.list, product };
}

let p = new ProductList();

p.add(7); // [7]
p.add(0); // [7,0]
p.add(2); // [7,0,2]
p.add(5); // [7,0,2,5]
p.add(4); // [7,0,2,5,4]
console.log(p.product(3)); // return 40 because 2 * 5 * 4&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Bonus: O(1) product but with O(n) add&lt;/h2&gt;
&lt;p&gt;This sprang to mind as an optimization upon deeper thinking it doesn’t really work, as it makes the add function slower. &lt;/p&gt;
&lt;p&gt;If we look at the problem, we realise there’s no need to remove items from the list, therefore there’s no need to keep the original values. How about calculating the product on insertion and then returning the results directly?&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;function ProductList() {
  this.list = [];

  function add(num) {
    for (let i = 0; i &amp;lt; this.list.length; i++) {
      this.list[i] *= num;
    }
    this.list.push(num);
  }

  function product(n) {
    let index = this.list.length - n;
    return this.list[index];
  }
  return { add, list: this.list, product };
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;codepen:&lt;/h2&gt;
&lt;iframe height=&quot;265&quot; style=&quot;width: 100%;&quot; scrolling=&quot;no&quot; title=&quot;cassidoo newsletter 2021/6&quot; src=&quot;https://codepen.io/Tzyinc/embed/bGBeMmW?height=296&amp;theme-id=dark&amp;default-tab=js&quot; frameborder=&quot;no&quot; loading=&quot;lazy&quot; allowtransparency=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
  See the Pen &lt;a href=&apos;https://codepen.io/Tzyinc/pen/bGBeMmW&apos;&gt;cassidoo newsletter 2021/6&lt;/a&gt; by Ten Zhi Yang
  (&lt;a href=&apos;https://codepen.io/Tzyinc&apos;&gt;@Tzyinc&lt;/a&gt;) on &lt;a href=&apos;https://codepen.io&apos;&gt;CodePen&lt;/a&gt;.
&lt;/iframe&gt;</content:encoded><content:raw>
I decided since I&apos;ve been solving the interview questions on [Cassidy&apos;s](https://twitter.com/cassidoo) weekly [newsletter](https://buttondown.email/cassidoo/archive/cc677716-37b2-4cfd-a691-bc6e87d7abce) I might as well put a little bit more effort into writing my thought processes down, in the scenario where people are looking for a way to solve these. That&apos;s my goal for this year. I&apos;m not confident I can be consistent, but it doesn&apos;t hurt to try!

**This may or may not be the optimal solution, DO NOT blindly memorize my solutions**

Target audience: beginners in js (please feedback!)

&gt;This week’s question:
Implement a ProductList class that has two methods, add(n) (which pushes the value n to the back of the list) and product(m) (which returns the product of the last m numbers in the list). David made an awesome template for submitting your solutions, if you’d like to use it!

&gt; Usage:
```
ProductList p = new ProductList();
p.add(7);         // [7]
p.add(0);         // [7,0]
p.add(2);         // [7,0,2]
p.add(5);         // [7,0,2,5]
p.add(4);         // [7,0,2,5,4]
p.product(3);     // return 40 because 2 * 5 * 4
```

As someone who&apos;s been writing nothing but JS for a while, the first thing that comes to mind is to make use of [lexical scope](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Closures) of JS functions to store the array. I can&apos;t say I&apos;m super familiar with the Scope and Closure terminologies, but I&apos;m fairly aware of what they do and how to make use of them.

so let&apos;s create a list in a function.

```
function ProductList() {
  this.list = [];
}
```

So to look at what&apos;s happening with the array, we can write some driver code

```
let p = new ProductList();
let p2 = new ProductList();
console.log(p.list, p2.list); // [] []
p.list.push(1);
p.list.push(2);
console.log(p.list, p2.list); // [1, 2] []
```

so far so good, we know that using the [new operator](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/new) essentially creates an object with the `this` context from the function.  

The next step we want to do is to add elements to the list from a function provided by ProductList instead of using the one from the array. We will return this function in a JSON object, as well as the list array (if not the list will be undefined, see link to new operator above)

```
function ProductList() {
  this.list = [];

  function add(num) {
    this.list.push(num);
  }
  return { add, list: this.list };
}
```

If we change the `p.list.push(1)` in the driver code above to `p.add(1)` we should have the same result.

Finally we need a product function to multiply all the elements in the list. We want the last `n` numbers, so we can have a for loop that increments up to `n` and create an index that starts from the back and gets smaller up till `n`. Plugging in the given driver code, we should get the correct solution.

```
function ProductList() {
  this.list = [];

  function add(num) {
    this.list.push(num);
  }

  function product(n) {
    let result = null;
    for (let i = 0; i &lt; n; i++) {
      const index = this.list.length - 1 - i;
      if (result === null) {
        result = this.list[index];
      } else {
        result *= this.list[index];
      }
    }
    return result;
  }
  return { add, list: this.list, product };
}

let p = new ProductList();

p.add(7); // [7]
p.add(0); // [7,0]
p.add(2); // [7,0,2]
p.add(5); // [7,0,2,5]
p.add(4); // [7,0,2,5,4]
console.log(p.product(3)); // return 40 because 2 * 5 * 4
```

## Bonus: O(1) product but with O(n) add

This sprang to mind as an optimization upon deeper thinking it doesn&apos;t really work, as it makes the add function slower. 

If we look at the problem, we realise there&apos;s no need to remove items from the list, therefore there&apos;s no need to keep the original values. How about calculating the product on insertion and then returning the results directly?

```
function ProductList() {
  this.list = [];

  function add(num) {
    for (let i = 0; i &lt; this.list.length; i++) {
      this.list[i] *= num;
    }
    this.list.push(num);
  }

  function product(n) {
    let index = this.list.length - n;
    return this.list[index];
  }
  return { add, list: this.list, product };
}
```

## codepen:

&lt;iframe height=&quot;265&quot; style=&quot;width: 100%;&quot; scrolling=&quot;no&quot; title=&quot;cassidoo newsletter 2021/6&quot; src=&quot;https://codepen.io/Tzyinc/embed/bGBeMmW?height=296&amp;theme-id=dark&amp;default-tab=js&quot; frameborder=&quot;no&quot; loading=&quot;lazy&quot; allowtransparency=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
  See the Pen &lt;a href=&apos;https://codepen.io/Tzyinc/pen/bGBeMmW&apos;&gt;cassidoo newsletter 2021/6&lt;/a&gt; by Ten Zhi Yang
  (&lt;a href=&apos;https://codepen.io/Tzyinc&apos;&gt;@Tzyinc&lt;/a&gt;) on &lt;a href=&apos;https://codepen.io&apos;&gt;CodePen&lt;/a&gt;.
&lt;/iframe&gt;</content:raw></item><item><title><![CDATA[Ways to play sound on browser]]></title><description><![CDATA[Here are some lightweight code for playing sounds on browser Audio element: quick and easy setup comes with player and controls Audio buffer…]]></description><link>https://blog.tenzhiyang.com/2020-10-13-ways-to-play-sound/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2020-10-13-ways-to-play-sound/</guid><pubDate>Tue, 13 Oct 2020 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Here are some lightweight code for playing sounds on browser&lt;/p&gt;
&lt;h2&gt;Audio element:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;quick and easy setup&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;comes with player and controls&lt;/p&gt;
&lt;iframe height=&quot;265&quot; style=&quot;width: 100%;&quot; scrolling=&quot;no&quot; title=&quot;Playing audio via file upload and audio element&quot; src=&quot;https://codepen.io/Tzyinc/embed/wvWKzjb?height=265&amp;theme-id=light&amp;default-tab=js,result&quot; frameborder=&quot;no&quot; loading=&quot;lazy&quot; allowtransparency=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
See the Pen &lt;a href=&apos;https://codepen.io/Tzyinc/pen/wvWKzjb&apos;&gt;Playing audio via file upload and audio element&lt;/a&gt; by Ten Zhi Yang
(&lt;a href=&apos;https://codepen.io/Tzyinc&apos;&gt;@Tzyinc&lt;/a&gt;) on &lt;a href=&apos;https://codepen.io&apos;&gt;CodePen&lt;/a&gt;.
&lt;/iframe&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Audio buffer&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;better for short audio clips&lt;/li&gt;
&lt;li&gt;easy implementation to take audio from a fetch&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;good for sound effects&lt;/p&gt;
&lt;iframe height=&quot;265&quot; style=&quot;width: 100%;&quot; scrolling=&quot;no&quot; title=&quot;Playing audio via file upload and audio buffer&quot; src=&quot;https://codepen.io/Tzyinc/embed/OJXybbP?height=265&amp;theme-id=light&amp;default-tab=js,result&quot; frameborder=&quot;no&quot; loading=&quot;lazy&quot; allowtransparency=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
See the Pen &lt;a href=&apos;https://codepen.io/Tzyinc/pen/OJXybbP&apos;&gt;Playing audio via file upload and audio buffer&lt;/a&gt; by Ten Zhi Yang
(&lt;a href=&apos;https://codepen.io/Tzyinc&apos;&gt;@Tzyinc&lt;/a&gt;) on &lt;a href=&apos;https://codepen.io&apos;&gt;CodePen&lt;/a&gt;.
&lt;/iframe&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Media stream&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;to receive a stream from somewhere&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;can take user devices, including mic and webcam&lt;/p&gt;
&lt;iframe height=&quot;265&quot; style=&quot;width: 100%;&quot; scrolling=&quot;no&quot; title=&quot;Playing audio via media devices and media stream&quot; src=&quot;https://codepen.io/Tzyinc/embed/ZEObBav?height=265&amp;theme-id=light&amp;default-tab=js,result&quot; frameborder=&quot;no&quot; loading=&quot;lazy&quot; allowtransparency=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
See the Pen &lt;a href=&apos;https://codepen.io/Tzyinc/pen/ZEObBav&apos;&gt;Playing audio via media devices and media stream&lt;/a&gt; by Ten Zhi Yang
(&lt;a href=&apos;https://codepen.io/Tzyinc&apos;&gt;@Tzyinc&lt;/a&gt;) on &lt;a href=&apos;https://codepen.io&apos;&gt;CodePen&lt;/a&gt;.
&lt;/iframe&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Oscillator&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;for manipulating the sound wave directly&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;good for creating micro-tonal sounds&lt;/p&gt;
&lt;iframe height=&quot;265&quot; style=&quot;width: 100%;&quot; scrolling=&quot;no&quot; title=&quot;Playing audio via oscillator&quot; src=&quot;https://codepen.io/Tzyinc/embed/dyXYOqB?height=265&amp;theme-id=light&amp;default-tab=js,result&quot; frameborder=&quot;no&quot; loading=&quot;lazy&quot; allowtransparency=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
See the Pen &lt;a href=&apos;https://codepen.io/Tzyinc/pen/dyXYOqB&apos;&gt;Playing audio via oscillator&lt;/a&gt; by Ten Zhi Yang
(&lt;a href=&apos;https://codepen.io/Tzyinc&apos;&gt;@Tzyinc&lt;/a&gt;) on &lt;a href=&apos;https://codepen.io&apos;&gt;CodePen&lt;/a&gt;.
&lt;/iframe&gt;
&lt;/li&gt;
&lt;/ul&gt;</content:encoded><content:raw>
Here are some lightweight code for playing sounds on browser

## Audio element:
- quick and easy setup
- comes with player and controls
&lt;iframe height=&quot;265&quot; style=&quot;width: 100%;&quot; scrolling=&quot;no&quot; title=&quot;Playing audio via file upload and audio element&quot; src=&quot;https://codepen.io/Tzyinc/embed/wvWKzjb?height=265&amp;theme-id=light&amp;default-tab=js,result&quot; frameborder=&quot;no&quot; loading=&quot;lazy&quot; allowtransparency=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
  See the Pen &lt;a href=&apos;https://codepen.io/Tzyinc/pen/wvWKzjb&apos;&gt;Playing audio via file upload and audio element&lt;/a&gt; by Ten Zhi Yang
  (&lt;a href=&apos;https://codepen.io/Tzyinc&apos;&gt;@Tzyinc&lt;/a&gt;) on &lt;a href=&apos;https://codepen.io&apos;&gt;CodePen&lt;/a&gt;.
&lt;/iframe&gt;

## Audio buffer
- better for short audio clips
- easy implementation to take audio from a fetch
- good for sound effects
&lt;iframe height=&quot;265&quot; style=&quot;width: 100%;&quot; scrolling=&quot;no&quot; title=&quot;Playing audio via file upload and audio buffer&quot; src=&quot;https://codepen.io/Tzyinc/embed/OJXybbP?height=265&amp;theme-id=light&amp;default-tab=js,result&quot; frameborder=&quot;no&quot; loading=&quot;lazy&quot; allowtransparency=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
  See the Pen &lt;a href=&apos;https://codepen.io/Tzyinc/pen/OJXybbP&apos;&gt;Playing audio via file upload and audio buffer&lt;/a&gt; by Ten Zhi Yang
  (&lt;a href=&apos;https://codepen.io/Tzyinc&apos;&gt;@Tzyinc&lt;/a&gt;) on &lt;a href=&apos;https://codepen.io&apos;&gt;CodePen&lt;/a&gt;.
&lt;/iframe&gt;

## Media stream
- to receive a stream from somewhere
- can take user devices, including mic and webcam
&lt;iframe height=&quot;265&quot; style=&quot;width: 100%;&quot; scrolling=&quot;no&quot; title=&quot;Playing audio via media devices and media stream&quot; src=&quot;https://codepen.io/Tzyinc/embed/ZEObBav?height=265&amp;theme-id=light&amp;default-tab=js,result&quot; frameborder=&quot;no&quot; loading=&quot;lazy&quot; allowtransparency=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
  See the Pen &lt;a href=&apos;https://codepen.io/Tzyinc/pen/ZEObBav&apos;&gt;Playing audio via media devices and media stream&lt;/a&gt; by Ten Zhi Yang
  (&lt;a href=&apos;https://codepen.io/Tzyinc&apos;&gt;@Tzyinc&lt;/a&gt;) on &lt;a href=&apos;https://codepen.io&apos;&gt;CodePen&lt;/a&gt;.
&lt;/iframe&gt;

## Oscillator
- for manipulating the sound wave directly
- good for creating micro-tonal sounds
&lt;iframe height=&quot;265&quot; style=&quot;width: 100%;&quot; scrolling=&quot;no&quot; title=&quot;Playing audio via oscillator&quot; src=&quot;https://codepen.io/Tzyinc/embed/dyXYOqB?height=265&amp;theme-id=light&amp;default-tab=js,result&quot; frameborder=&quot;no&quot; loading=&quot;lazy&quot; allowtransparency=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
  See the Pen &lt;a href=&apos;https://codepen.io/Tzyinc/pen/dyXYOqB&apos;&gt;Playing audio via oscillator&lt;/a&gt; by Ten Zhi Yang
  (&lt;a href=&apos;https://codepen.io/Tzyinc&apos;&gt;@Tzyinc&lt;/a&gt;) on &lt;a href=&apos;https://codepen.io&apos;&gt;CodePen&lt;/a&gt;.
&lt;/iframe&gt;</content:raw></item><item><title><![CDATA[Music in browser basics]]></title><description><![CDATA[I’ve recently started a tech in music interest group within Shopee that will run for 8 weeks, and I want to have some content out for the…]]></description><link>https://blog.tenzhiyang.com/2020-09-30-music-in-browser-basics/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2020-09-30-music-in-browser-basics/</guid><pubDate>Wed, 30 Sep 2020 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;I’ve recently started a tech in music interest group within Shopee that will run for 8 weeks, and I want to have some content out for the first week as we will be doing mostly introductions. So this shall be my welcome and beginner starting kit to my 3 amigos Adriel, Stanley and James.&lt;/p&gt;
&lt;p&gt;This post will try to provide an non technical explanation for some of the magic behind the web audio api so that we know what to google and research on our own. &lt;strong&gt;This article is suitable for people comfortable with working in JS, with minimal to no signal processing background knowledge&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API&quot;&gt;reference&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;Web audio api&lt;/h1&gt;
&lt;p&gt;The web audio api is powerful in that you should be able to build anything you need to relating sound, but as I found out, it’s not very easy to use without some background in signal processing. All of our operations will revolve around the &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/AudioContext&quot;&gt;Audio Context&lt;/a&gt;, which is essentially a graph built from modular &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/AudioNode&quot;&gt;Audio Node&lt;/a&gt;s One audio context can have multiple Audio nodes. An audio node can be an audio source, an audio destination or some audio processing module. These nodes are routed to each other (eg, source -&gt; processing -&gt; destination) and form a graph. There can be multiple input and output nodes.&lt;/p&gt;
&lt;h3&gt;Audio sampling&lt;/h3&gt;
&lt;p&gt;Because it’s not very feasible to store a continuous audio input, we usually &lt;code class=&quot;language-text&quot;&gt;sample&lt;/code&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Discrete_time_and_continuous_time&quot;&gt;the continuous signal into a discrete representation&lt;/a&gt;, in the form of X values at Y time&lt;/p&gt;
&lt;h2&gt;Audio Sources&lt;/h2&gt;
&lt;p&gt;After creating an audio context, we usually want to take an input, known as an audio source. Audio sources can be in the form of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;sound generated from js (eg. creating a signal via &lt;code class=&quot;language-text&quot;&gt;oscillator&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;raw audio data known as &lt;a href=&quot;https://en.wikipedia.org/wiki/Pulse-code_modulation&quot;&gt;PCM&lt;/a&gt; (eg. &lt;code class=&quot;language-text&quot;&gt;AudioBuffer&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;HTML elements like &lt;code class=&quot;language-text&quot;&gt;&amp;lt;audio&amp;gt;&lt;/code&gt; or &lt;code class=&quot;language-text&quot;&gt;&amp;lt;video&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;or some &lt;code class=&quot;language-text&quot;&gt;MediaStream&lt;/code&gt; like your microphone&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Effects&lt;/h2&gt;
&lt;p&gt;A lot of cool interactions we want to do involves adding effects to audio sources. We usually use the term &lt;code class=&quot;language-text&quot;&gt;connect&lt;/code&gt; to apply these effects onto an audio context Some things we can do is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;GainNode&lt;/code&gt; change the volume. We can add gain to an input to increase the loudness &lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;ConvolverNode&lt;/code&gt; gives reverb effects&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;WaveShaper&lt;/code&gt; applies a non-liner distorter, can be used to change the tone of the sound.&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;DynamicsCompressorNode&lt;/code&gt; lowers volume of loudest parts in the signal to help reduce clipping and distortion&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Destination (Output)&lt;/h2&gt;
&lt;p&gt;We can use &lt;code class=&quot;language-text&quot;&gt;AudioDestinationNode&lt;/code&gt; to select the audio source, usually for speakers of the device. Alternatively we can have &lt;code class=&quot;language-text&quot;&gt;MediaStreamAudioDestinationNode&lt;/code&gt; it uses &lt;code class=&quot;language-text&quot;&gt;WebRTC&lt;/code&gt; &lt;code class=&quot;language-text&quot;&gt;MediaStream&lt;/code&gt; under the hood. An interesting thing we can do with audio output is to have &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Web_audio_spatialization_basics&quot;&gt;spatialization effects&lt;/a&gt; to simulate where the sound is coming from.&lt;/p&gt;
&lt;h2&gt;Analysis&lt;/h2&gt;
&lt;p&gt;The &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode&quot;&gt;AnalyserNode&lt;/a&gt; allows us to take numerical representations of the audio context. This is usually used for [visualizations] (&lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Visualizations_with_Web_Audio_API&quot;&gt;https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Visualizations_with_Web_Audio_API&lt;/a&gt;)&lt;/p&gt;</content:encoded><content:raw>
I&apos;ve recently started a tech in music interest group within Shopee that will run for 8 weeks, and I want to have some content out for the first week as we will be doing mostly introductions. So this shall be my welcome and beginner starting kit to my 3 amigos Adriel, Stanley and James.

This post will try to provide an non technical explanation for some of the magic behind the web audio api so that we know what to google and research on our own. **This article is suitable for people comfortable with working in JS, with minimal to no signal processing background knowledge**

[reference](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API)

# Web audio api

The web audio api is powerful in that you should be able to build anything you need to relating sound, but as I found out, it&apos;s not very easy to use without some background in signal processing. All of our operations will revolve around the [Audio Context](https://developer.mozilla.org/en-US/docs/Web/API/AudioContext), which is essentially a graph built from modular [Audio Node](https://developer.mozilla.org/en-US/docs/Web/API/AudioNode)s One audio context can have multiple Audio nodes. An audio node can be an audio source, an audio destination or some audio processing module. These nodes are routed to each other (eg, source -&gt; processing -&gt; destination) and form a graph. There can be multiple input and output nodes.

### Audio sampling

Because it&apos;s not very feasible to store a continuous audio input, we usually `sample` [the continuous signal into a discrete representation](https://en.wikipedia.org/wiki/Discrete_time_and_continuous_time), in the form of X values at Y time

## Audio Sources

After creating an audio context, we usually want to take an input, known as an audio source. Audio sources can be in the form of:
- sound generated from js (eg. creating a signal via `oscillator`)
- raw audio data known as [PCM](https://en.wikipedia.org/wiki/Pulse-code_modulation) (eg. `AudioBuffer`)
- HTML elements like `&lt;audio&gt;` or `&lt;video&gt;`
- or some `MediaStream` like your microphone

## Effects

A lot of cool interactions we want to do involves adding effects to audio sources. We usually use the term `connect` to apply these effects onto an audio context Some things we can do is:
- `GainNode` change the volume. We can add gain to an input to increase the loudness 
- `ConvolverNode` gives reverb effects
- `WaveShaper` applies a non-liner distorter, can be used to change the tone of the sound.
- `DynamicsCompressorNode` lowers volume of loudest parts in the signal to help reduce clipping and distortion

## Destination (Output)

We can use `AudioDestinationNode` to select the audio source, usually for speakers of the device. Alternatively we can have `MediaStreamAudioDestinationNode` it uses `WebRTC` `MediaStream` under the hood. An interesting thing we can do with audio output is to have [spatialization effects](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Web_audio_spatialization_basics) to simulate where the sound is coming from.

## Analysis

The [AnalyserNode](https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode) allows us to take numerical representations of the audio context. This is usually used for [visualizations] (https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Visualizations_with_Web_Audio_API)
</content:raw></item><item><title><![CDATA[A look into building twatter]]></title><link>https://blog.tenzhiyang.com/2020-06-06-twatter-talk/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2020-06-06-twatter-talk/</guid><pubDate>Sat, 06 Jun 2020 00:00:00 GMT</pubDate><content:encoded>&lt;div class=&quot;gatsby-resp-iframe-wrapper&quot; style=&quot;padding-bottom: 56.25%; position: relative; height: 0; overflow: hidden; margin-bottom: 1.0725rem&quot; &gt; &lt;iframe src=&quot;https://www.youtube.com/embed/Mut4F3C_dv8&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen style=&quot; position: absolute; top: 0; left: 0; width: 100%; height: 100%; &quot;&gt;&lt;/iframe&gt; &lt;/div&gt;</content:encoded><content:raw>
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/Mut4F3C_dv8&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen&gt;&lt;/iframe&gt;</content:raw></item><item><title><![CDATA[froot loops]]></title><description><![CDATA[A look into js loops slides: https://slides.com/tzyinc/deck]]></description><link>https://blog.tenzhiyang.com/2020-04-24-froot-loops/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2020-04-24-froot-loops/</guid><pubDate>Fri, 24 Apr 2020 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;A look into js loops&lt;/p&gt;
&lt;p&gt;slides: &lt;a href=&quot;https://slides.com/tzyinc/deck&quot;&gt;https://slides.com/tzyinc/deck&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;gatsby-resp-iframe-wrapper&quot; style=&quot;padding-bottom: 56.25%; position: relative; height: 0; overflow: hidden; margin-bottom: 1.0725rem&quot; &gt; &lt;iframe src=&quot;https://www.youtube.com/embed/v=UxkI6dF06R8&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen style=&quot; position: absolute; top: 0; left: 0; width: 100%; height: 100%; &quot;&gt;&lt;/iframe&gt; &lt;/div&gt;</content:encoded><content:raw>
A look into js loops

slides: [https://slides.com/tzyinc/deck](https://slides.com/tzyinc/deck)

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/v=UxkI6dF06R8&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen&gt;&lt;/iframe&gt;
</content:raw></item><item><title><![CDATA[butt is a valid css value]]></title><link>https://blog.tenzhiyang.com/2020-03-04-five-months-into-LIP/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2020-03-04-five-months-into-LIP/</guid><pubDate>Wed, 04 Mar 2020 00:00:00 GMT</pubDate><content:encoded>&lt;div class=&quot;gatsby-resp-iframe-wrapper&quot; style=&quot;padding-bottom: 56.25%; position: relative; height: 0; overflow: hidden; margin-bottom: 1.0725rem&quot; &gt; &lt;iframe src=&quot;https://youtu.be/FJfCL3TCCHQ&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen style=&quot; position: absolute; top: 0; left: 0; width: 100%; height: 100%; &quot;&gt;&lt;/iframe&gt; &lt;/div&gt;</content:encoded><content:raw>
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://youtu.be/FJfCL3TCCHQ&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen&gt;&lt;/iframe&gt;
</content:raw></item><item><title><![CDATA[SVGs are good butt can you style them]]></title><description><![CDATA[Script for the above slides Hi everyone I’m Ten Zhi Yang, Front end Engineer at Shopee. For my talk today, I really want everyone to know…]]></description><link>https://blog.tenzhiyang.com/2020-02-26-svgs-are-good-butt-can-you-style-them/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2020-02-26-svgs-are-good-butt-can-you-style-them/</guid><pubDate>Wed, 26 Feb 2020 00:00:00 GMT</pubDate><content:encoded>&lt;div class=&quot;gatsby-resp-iframe-wrapper&quot; style=&quot;padding-bottom: 56.25%; position: relative; height: 0; overflow: hidden; margin-bottom: 1.0725rem&quot; &gt; &lt;iframe src=&quot;https://www.youtube.com/embed/FJfCL3TCCHQ&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen style=&quot; position: absolute; top: 0; left: 0; width: 100%; height: 100%; &quot;&gt;&lt;/iframe&gt; &lt;/div&gt;
&lt;video width=&quot;320&quot; height=&quot;240&quot; controls&gt;
  &lt;source src=&quot;/669c7bb37ff5345b62a946f77bde4cb1/pechakuchafix.mp4&quot; type=&quot;video/mp4&quot;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;h1&gt;Script for the above slides&lt;/h1&gt;
&lt;p&gt;Hi everyone I’m Ten Zhi Yang, Front end Engineer at Shopee. For my talk today, I really want everyone to know that Butt is a valid css value. That’s it. That’s the whole talk. Thank you.&lt;/p&gt;
&lt;p&gt;Just kidding. The title of this presentation was inspired by the tweet above from Chris coyer. Unfortunately, I can’t make a full presentation talking about butts in css, so I’ll have to make do with talking about SVGs using CSS, to produce effects like with the farting cat below.&lt;/p&gt;
&lt;p&gt;Apart from the usual rotate and transform techniques that we normally use with images, we actually have a list of css properties and values that are unique to vector images, and SVGs. You can read for more details in the css docs&lt;/p&gt;
&lt;p&gt;For most of the examples, I drew these fart lines using vectr.com. We can see that the lines in this SVG are essentially represented by waypoints, shown as circles here. To get your hands on SVGs and play around, you can also draw your own like I did,&lt;/p&gt;
&lt;p&gt;Or with some of my examples, from freesvg. Programmes like figma and sketch allow you to export shapes as SVGs, and there are many libraries that either provides svgs, or even allow you to draw SVGs with the JS canvas syntax&lt;/p&gt;
&lt;p&gt;If we peek into the SVG content, we see that it is mostly a series of paths. Although not in this example, other representations can be in the form of some basic shapes or fill strategies. Do take note of the property pathLength equals to one here &lt;/p&gt;
&lt;p&gt;Being a vector based representation gives us some benefits. We can have crisp and sharp images at all sizes. If we declare the SVGs in our markup itself, we don’t have to send another HTTP request for each image, We can easily scale not just the whole thing but parts of our image, and vector representation of images are generally small.&lt;/p&gt;
&lt;p&gt;Basic SVG support is already in all browsers, even mini browsers! If anyone out there’s still using PNG for gifs for their icons, I suggest to immediately switch to svgs just based on those benefits themselves&lt;/p&gt;
&lt;p&gt;We don’t have to draw paths as lines. We can also do fun things like make text follow a path. Or make shapes from paths. Or make other paths follow a path. Or make other Paths follow a Path that follows another path. &lt;/p&gt;
&lt;p&gt;Some common CSS uses that we have are things like stroke, fill, and stroke width. These are normally used in our daily development to change colors of icons, we can also add stroke width on hover to show a highlighted effect.&lt;/p&gt;
&lt;p&gt;The namesake of this presentation is just a value for the linecap properties, which represents the ends of the lines. In the first line, you can see that the line ends or caps are round. For the Butt line, they stop with a flat edge. Square value looks very similar to butt, except that it extends a square beyond where the path. You can see the effect a little bit, where the line with square caps starts a little before the other two lines.&lt;/p&gt;
&lt;p&gt;Other properties that we can play around with are the dash array and dash offset. I mentioned Pathlength = 1 about a minute ago. This allows us to use float values from 0 to 1 as a ratio to the total path length when setting these values. In the second example, I removed the property, so I have to use pixel values instead. In the last example, I changed the offset, the dash line starts further to the right.&lt;/p&gt;
&lt;p&gt;All these examples are kinda boring, unlike the farting cat animation shown pretty much at the start of the presentation. So using these concepts, what can we abuse these properties for weird animation effects?&lt;/p&gt;
&lt;p&gt;We can use css animations to shift dash offset at certain intervals. This is a single-lined spiral that I just found on freesvg, without any prior knowledge of the path itself, I can create this spiral effect by changing the dash offset&lt;/p&gt;
&lt;p&gt;Alternatively we can change multiple things together to achieve other effects. By changing the color for dark blue to a vibrant blue color and then making the stroke width larger, I can create a glowing neon sign effect&lt;/p&gt;
&lt;p&gt;We can also animate color fills like the one here. With CSS animations, we only need to write out color stops, like keyframes, and the fading from color to color will be automagically handled for us.&lt;/p&gt;
&lt;p&gt;A very common use of svg is to create a sketching effect. Here I added the pathLength = 1 to every path, and adjusted the dash offset from 0 to 1, repeating back and forth. I could stagger the start timing of each animations to make look more like it’s being drawn, but I’m lazy&lt;/p&gt;
&lt;p&gt;But we don’t have to use CSS alone to create this effect. As U said earlier, I’m lazy, so lazy that I didn’t want to manually add PathLength to the 20 or so paths that make up this image, so I wrote a loop to iteratively set all path lengths. &lt;/p&gt;
&lt;p&gt;We can also use the markup itself in our css rules. All I had to do was to copy the path from the svg wholesale and paste it into this path-offset property. By changing the offset-distance percentage, I can make it move back and forth on the path.&lt;/p&gt;
&lt;p&gt;There are lots of libraries out there that use these same few concepts under the hood to achieve animations and interactions with SVGs. A general idea for things that are easy to play around with are simple line art drawings without fills. That’s all for my talk, you can access this talk and my weird programming hijinks from these links&lt;/p&gt;</content:encoded><content:raw>
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/FJfCL3TCCHQ&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;video width=&quot;320&quot; height=&quot;240&quot; controls&gt;
  &lt;source src=&quot;./pechakuchafix.mp4&quot; type=&quot;video/mp4&quot;&gt;
Your browser does not support the video tag.
&lt;/video&gt;

# Script for the above slides

Hi everyone I&apos;m Ten Zhi Yang, Front end Engineer at Shopee. For my talk today, I really want everyone to know that Butt is a valid css value. That’s it. That’s the whole talk. Thank you.

Just kidding. The title of this presentation was inspired by the tweet above from Chris coyer. Unfortunately, I can&apos;t make a full presentation talking about butts in css, so I’ll have to make do with talking about SVGs using CSS, to produce effects like with the farting cat below.

Apart from the usual rotate and transform techniques that we normally use with images, we actually have a list of css properties and values that are unique to vector images, and SVGs. You can read for more details in the css docs

For most of the examples, I drew these fart lines using vectr.com. We can see that the lines in this SVG are essentially represented by waypoints, shown as circles here. To get your hands on SVGs and play around, you can also draw your own like I did,

Or with some of my examples, from freesvg. Programmes like figma and sketch allow you to export shapes as SVGs, and there are many libraries that either provides svgs, or even allow you to draw SVGs with the JS canvas syntax

If we peek into the SVG content, we see that it is mostly a series of paths. Although not in this example, other representations can be in the form of some basic shapes or fill strategies. Do take note of the property pathLength equals to one here 

Being a vector based representation gives us some benefits. We can have crisp and sharp images at all sizes. If we declare the SVGs in our markup itself, we don’t have to send another HTTP request for each image, We can easily scale not just the whole thing but parts of our image, and vector representation of images are generally small.

Basic SVG support is already in all browsers, even mini browsers! If anyone out there’s still using PNG for gifs for their icons, I suggest to immediately switch to svgs just based on those benefits themselves

We don’t have to draw paths as lines. We can also do fun things like make text follow a path. Or make shapes from paths. Or make other paths follow a path. Or make other Paths follow a Path that follows another path. 

Some common CSS uses that we have are things like stroke, fill, and stroke width. These are normally used in our daily development to change colors of icons, we can also add stroke width on hover to show a highlighted effect.

The namesake of this presentation is just a value for the linecap properties, which represents the ends of the lines. In the first line, you can see that the line ends or caps are round. For the Butt line, they stop with a flat edge. Square value looks very similar to butt, except that it extends a square beyond where the path. You can see the effect a little bit, where the line with square caps starts a little before the other two lines.

Other properties that we can play around with are the dash array and dash offset. I mentioned Pathlength = 1 about a minute ago. This allows us to use float values from 0 to 1 as a ratio to the total path length when setting these values. In the second example, I removed the property, so I have to use pixel values instead. In the last example, I changed the offset, the dash line starts further to the right.

All these examples are kinda boring, unlike the farting cat animation shown pretty much at the start of the presentation. So using these concepts, what can we abuse these properties for weird animation effects?

We can use css animations to shift dash offset at certain intervals. This is a single-lined spiral that I just found on freesvg, without any prior knowledge of the path itself, I can create this spiral effect by changing the dash offset

Alternatively we can change multiple things together to achieve other effects. By changing the color for dark blue to a vibrant blue color and then making the stroke width larger, I can create a glowing neon sign effect

We can also animate color fills like the one here. With CSS animations, we only need to write out color stops, like keyframes, and the fading from color to color will be automagically handled for us.

A very common use of svg is to create a sketching effect. Here I added the pathLength = 1 to every path, and adjusted the dash offset from 0 to 1, repeating back and forth. I could stagger the start timing of each animations to make look more like it’s being drawn, but I’m lazy

But we don’t have to use CSS alone to create this effect. As U said earlier, I’m lazy, so lazy that I didn’t want to manually add PathLength to the 20 or so paths that make up this image, so I wrote a loop to iteratively set all path lengths. 

We can also use the markup itself in our css rules. All I had to do was to copy the path from the svg wholesale and paste it into this path-offset property. By changing the offset-distance percentage, I can make it move back and forth on the path.

There are lots of libraries out there that use these same few concepts under the hood to achieve animations and interactions with SVGs. A general idea for things that are easy to play around with are simple line art drawings without fills. That’s all for my talk, you can access this talk and my weird programming hijinks from these links
</content:raw></item><item><title><![CDATA[Two months on rendezvous with @cassidoo , how did I do?]]></title><description><![CDATA[In case you don’t already know, @cassidoo has a really fun weekly newsletter. In it, she shares things she did that week, web links, an…]]></description><link>https://blog.tenzhiyang.com/2020-02-24-two-months-on-cassidoo-how-did-i-do/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2020-02-24-two-months-on-cassidoo-how-did-i-do/</guid><pubDate>Mon, 24 Feb 2020 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;In case you don’t already know, &lt;a href=&quot;https://twitter.com/cassidoo&quot;&gt;@cassidoo&lt;/a&gt; has a really fun weekly &lt;a href=&quot;https://cassidoo.co/newsletter/&quot;&gt;newsletter&lt;/a&gt;. In it, she shares things she did that week, web links, an interview question and a joke of the week. It’s definitely a lot of work to be so consistent (132 issues!), so I figured why not show my appreciation by attempting the interview questions every week? &lt;/p&gt;
&lt;p&gt;I’ve been attempting the questions if I felt that I had an interesting take on the question, so I had a rough idea on the difficulty and how varied these questions are, but being consistent is much harder for me. I decided to see if I could last two months of every problem before I write a retrospective on some sort. To make sure everything is in one place, and also easily referenced,  I would only use codepen to do it. So here’s my review on the questions:&lt;/p&gt;
&lt;h2&gt;&lt;a href=&quot;https://codepen.io/Tzyinc/pen/LYEeqOO&quot;&gt;2020 Issue 1: Array.filter&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Implement array.filter() by hand (or whatever your language of choice uses to do this functionality).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This one was not very difficult technically, but I had to reference the polyfill on how to implement it. This question really tested my understanding on how my everyday tools work behind the abstraction, and sadly, I only had a rough understanding on the general case.&lt;/p&gt;
&lt;p&gt;Educational rating: 10/10&lt;/p&gt;
&lt;h2&gt;&lt;a href=&quot;https://codepen.io/Tzyinc/pen/JjoZREZ&quot;&gt;2020 Issue 2: N palindromes&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Given a number n, find the sum of all n-digit palindromes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Deceptively difficult, this problem probably has a better solution out there. I didn’t want to do a simple check if x to xxx is palindromic, so I tried to find a way to get the next palindrome given the current value. I managed to break it down into 3 generic cases, which was good enough for me. Really happy with how this solution came out.&lt;/p&gt;
&lt;p&gt;Deceptiveness rating: 10/10&lt;/p&gt;
&lt;h2&gt;&lt;a href=&quot;https://codepen.io/Tzyinc/pen/YzPRgzb&quot;&gt;2020 Issue 3: is N factorial &lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Given a number, return true if the input is a factorial of any natural number.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A very classic style of question I would expect in university, I had an inkling there was a significantly better solution. I thought that O(n) was good enough, but &lt;a href=&quot;https://twitter.com/sophiebits/status/1219395327142219776&quot;&gt;@sophiebits&lt;/a&gt;’s solution blew my mind out of the water! As my colleague said: it’s sophie, else what did you expect?&lt;/p&gt;
&lt;p&gt;Classic-ness rating: 10/10&lt;/p&gt;
&lt;h2&gt;&lt;a href=&quot;https://codepen.io/Tzyinc/pen/QWwPWPE&quot;&gt;2020 Issue 4: Helo wrd&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Write a function that prints “Hello, world!” but doesn’t repeat any characters in the program. The program should not use &lt;em&gt;any&lt;/em&gt; character more than once (except whitespace, I’ll allow that)!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I’m not sure if there’s a proper solution in javascript for this. I don’t think it’s possible without the quotes or an external file. I did look around for inspiration but not before I already tried atob. I had to use some greek letters to at least keep the alphabet to one character each&lt;/p&gt;
&lt;p&gt;Impossible-ness rating: 10/10&lt;/p&gt;
&lt;h2&gt;&lt;a href=&quot;https://codepen.io/Tzyinc/pen/eYNOpvx?editors=0010&quot;&gt;2020 Issue 5: Even Word&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Given that an “even word” is a word in which each character appears an even number of times, write a function that takes in a string and returns the minimum number of letters to be removed to make that string an even word.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I found this question easy, but I was wondering if my solution was correct as I made the assumption that it’s equivalent to “how many letters are odd?” it seems like that’s the same question phrased differently, so I wonder why the original question was phrased as such.&lt;/p&gt;
&lt;p&gt;Odd rating: 10/10&lt;/p&gt;
&lt;h2&gt;&lt;a href=&quot;https://codepen.io/Tzyinc/pen/RwPPQJJ?editors=0011&quot;&gt;2020 Issue 6: Point in Triangle&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Given an array of points that represent the 3 vertices of a triangle, and a point K, return true if K is inside the triangle.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Such a simple yet difficult question. I’m not sure if my solution is entirely correct, but I can’t think of a counter example and I’m too lazy to proof it. While looking for better solutions, I found that this was not a simple problem at all, especially when dealing with more than two dimensions.&lt;/p&gt;
&lt;p&gt;The most intuitive solution was to check if the point is on the “correct” side of each line in the triangle. To do that, you calculate the vector from the side to the point, and do it for all 3 sides. if all the vectors point towards each other, the point is on the inside.&lt;/p&gt;
&lt;p&gt;The more efficient and supposedly best solution is the &lt;a href=&quot;https://en.wikipedia.org/wiki/Barycentric_coordinate_system&quot;&gt;Barycentric coordinate method&lt;/a&gt;. I’m not very good at explaining (and understanding) math, so I’ll leave it to the wiki to explain.&lt;/p&gt;
&lt;p&gt;Tri-facta rating: 3/3&lt;/p&gt;
&lt;h2&gt;&lt;a href=&quot;https://codepen.io/Tzyinc/pen/poJbRzq?editors=1010&quot;&gt;2020 Issue 7: Speed Typing&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Build a typing speed test/game.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;My work was ramping up at this time, so I didn’t really want to do a whole game loop like I did with snake last year. I did, however feel that my dynamic programming skills were rusty, so to record ‘live’ errors like you would on any speed typing game, I wrote an implementation of the levenshtein distance algorithm from memory. Having written it from scratch also allowed me to easily return an array that corresponds to (one of) the most efficient path and use that to change the color of wrong characters.&lt;/p&gt;
&lt;p&gt;Speed rating: 10/10&lt;/p&gt;
&lt;h2&gt;&lt;a href=&quot;https://codepen.io/Tzyinc/pen/poJbRzq?editors=1010&quot;&gt;2020 Issue 8: Event Emitters&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Write an event emitter that has three methods: on, emit, and removeListener. The &lt;code class=&quot;language-text&quot;&gt;on&lt;/code&gt; function takes in an event name and a callback function, the &lt;code class=&quot;language-text&quot;&gt;emit&lt;/code&gt; function takes in an event name and data (which will be passed to the associated callback), and &lt;code class=&quot;language-text&quot;&gt;removeListener&lt;/code&gt; takes in an event name and a callback to remove from that event.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At the time of writing this post I haven’t had feedback whether I’m on the right path or not, but I assume it’s something like an event listener style data structure, so I wrote my own old-school javascript class, and see if I could call my own &lt;code class=&quot;language-text&quot;&gt;tick&lt;/code&gt; event. I decided to store the callbacks in an array as the question requires that &lt;code class=&quot;language-text&quot;&gt;removeListener&lt;/code&gt; takes in the callback itself, so it made sense for there to be more then one callback, and remove the callback by filtering.&lt;/p&gt;
&lt;p&gt;Eventfulness rating: 10/10&lt;/p&gt;</content:encoded><content:raw>
In case you don&apos;t already know, [@cassidoo](https://twitter.com/cassidoo) has a really fun weekly [newsletter](https://cassidoo.co/newsletter/). In it, she shares things she did that week, web links, an interview question and a joke of the week. It&apos;s definitely a lot of work to be so consistent (132 issues!), so I figured why not show my appreciation by attempting the interview questions every week? 

I&apos;ve been attempting the questions if I felt that I had an interesting take on the question, so I had a rough idea on the difficulty and how varied these questions are, but being consistent is much harder for me. I decided to see if I could last two months of every problem before I write a retrospective on some sort. To make sure everything is in one place, and also easily referenced,  I would only use codepen to do it. So here&apos;s my review on the questions:

## [2020 Issue 1: Array.filter](https://codepen.io/Tzyinc/pen/LYEeqOO)
- Implement array.filter() by hand (or whatever your language of choice uses to do this functionality).

This one was not very difficult technically, but I had to reference the polyfill on how to implement it. This question really tested my understanding on how my everyday tools work behind the abstraction, and sadly, I only had a rough understanding on the general case.

Educational rating: 10/10

## [2020 Issue 2: N palindromes](https://codepen.io/Tzyinc/pen/JjoZREZ)
- Given a number n, find the sum of all n-digit palindromes.

Deceptively difficult, this problem probably has a better solution out there. I didn&apos;t want to do a simple check if x to xxx is palindromic, so I tried to find a way to get the next palindrome given the current value. I managed to break it down into 3 generic cases, which was good enough for me. Really happy with how this solution came out.

Deceptiveness rating: 10/10

## [2020 Issue 3: is N factorial ](https://codepen.io/Tzyinc/pen/YzPRgzb)
- Given a number, return true if the input is a factorial of any natural number.

A very classic style of question I would expect in university, I had an inkling there was a significantly better solution. I thought that O(n) was good enough, but [@sophiebits](https://twitter.com/sophiebits/status/1219395327142219776)&apos;s solution blew my mind out of the water! As my colleague said: it&apos;s sophie, else what did you expect?

Classic-ness rating: 10/10

## [2020 Issue 4: Helo wrd](https://codepen.io/Tzyinc/pen/QWwPWPE)
- Write a function that prints &quot;Hello, world!&quot; but doesn&apos;t repeat any characters in the program. The program should not use *any* character more than once (except whitespace, I&apos;ll allow that)!

I&apos;m not sure if there&apos;s a proper solution in javascript for this. I don&apos;t think it&apos;s possible without the quotes or an external file. I did look around for inspiration but not before I already tried atob. I had to use some greek letters to at least keep the alphabet to one character each

Impossible-ness rating: 10/10

## [2020 Issue 5: Even Word](https://codepen.io/Tzyinc/pen/eYNOpvx?editors=0010)
- Given that an &quot;even word&quot; is a word in which each character appears an even number of times, write a function that takes in a string and returns the minimum number of letters to be removed to make that string an even word.

I found this question easy, but I was wondering if my solution was correct as I made the assumption that it&apos;s equivalent to &quot;how many letters are odd?&quot; it seems like that&apos;s the same question phrased differently, so I wonder why the original question was phrased as such.

Odd rating: 10/10

## [2020 Issue 6: Point in Triangle](https://codepen.io/Tzyinc/pen/RwPPQJJ?editors=0011)
- Given an array of points that represent the 3 vertices of a triangle, and a point K, return true if K is inside the triangle.

Such a simple yet difficult question. I&apos;m not sure if my solution is entirely correct, but I can&apos;t think of a counter example and I&apos;m too lazy to proof it. While looking for better solutions, I found that this was not a simple problem at all, especially when dealing with more than two dimensions.

The most intuitive solution was to check if the point is on the &quot;correct&quot; side of each line in the triangle. To do that, you calculate the vector from the side to the point, and do it for all 3 sides. if all the vectors point towards each other, the point is on the inside.

The more efficient and supposedly best solution is the [Barycentric coordinate method](https://en.wikipedia.org/wiki/Barycentric_coordinate_system). I&apos;m not very good at explaining (and understanding) math, so I&apos;ll leave it to the wiki to explain.

Tri-facta rating: 3/3

## [2020 Issue 7: Speed Typing](https://codepen.io/Tzyinc/pen/poJbRzq?editors=1010)
- Build a typing speed test/game.

My work was ramping up at this time, so I didn&apos;t really want to do a whole game loop like I did with snake last year. I did, however feel that my dynamic programming skills were rusty, so to record &apos;live&apos; errors like you would on any speed typing game, I wrote an implementation of the levenshtein distance algorithm from memory. Having written it from scratch also allowed me to easily return an array that corresponds to (one of) the most efficient path and use that to change the color of wrong characters.

Speed rating: 10/10

## [2020 Issue 8: Event Emitters](https://codepen.io/Tzyinc/pen/poJbRzq?editors=1010)
- Write an event emitter that has three methods: on, emit, and removeListener. The `on` function takes in an event name and a callback function, the `emit` function takes in an event name and data (which will be passed to the associated callback), and `removeListener` takes in an event name and a callback to remove from that event.

At the time of writing this post I haven&apos;t had feedback whether I&apos;m on the right path or not, but I assume it&apos;s something like an event listener style data structure, so I wrote my own old-school javascript class, and see if I could call my own `tick` event. I decided to store the callbacks in an array as the question requires that `removeListener` takes in the callback itself, so it made sense for there to be more then one callback, and remove the callback by filtering.

Eventfulness rating: 10/10</content:raw></item><item><title><![CDATA[Pitch me a scale]]></title><description><![CDATA[So I recently bought an electric guitar because… I’m impulsive. I’ve never played guitar before in my life, I can play very simple four…]]></description><link>https://blog.tenzhiyang.com/2020-02-03-pitch-me-a-scale/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2020-02-03-pitch-me-a-scale/</guid><pubDate>Mon, 03 Feb 2020 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;So I recently bought an electric guitar because… I’m impulsive. I’ve never played guitar before in my life, I can play very simple four chord songs on an ukulele, but guitar always seemed like such a step up from ukulele. In the end I justified to myself that since there are so much resources on guitar playing and in so many different styles, I could learn to be average at the guitar and then transfer those skills back into the ukulele.&lt;/p&gt;
&lt;p&gt;After practicing on the C major scale for a couple of weeks, as well as the “four chords” (C G Am F on ukulele, G, D, E, C on guitar) I decided it was time to actually practice more scales. I already casually watch &lt;a href=&quot;https://twitter.com/adamneelybass&quot;&gt;@adamneelybass&lt;/a&gt; on &lt;a href=&quot;https://www.youtube.com/channel/UCnkp4xDOwqqJD7sSM3xdUiQ&quot;&gt;youtube&lt;/a&gt; and have left his 5 hour practice video in the background while working.&lt;/p&gt;
&lt;p&gt;So I needed to find a way to learn and practice scales. I also bad at identifying tones or even notes on the neck. Splitting this problem up, I need 2 things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Identify what note I am playing&lt;/li&gt;
&lt;li&gt;Display what notes to play&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Of course I would have liked to write some solution that identifies chords, but after some research, I found that multi tonal pitch detection is a very difficult problem to solve, and JS likely isn’t the best tool for that job (I like writing “serverless” apps). I stumbled across this really &lt;a href=&quot;https://github.com/cwilso/PitchDetect&quot;&gt;short and sweet repo for guitar tuning&lt;/a&gt; by &lt;a href=&quot;https:twitter.com/cwilso&quot;&gt;@cwilso&lt;/a&gt; and found that it was really well written and easy to re-purpose.&lt;/p&gt;
&lt;p&gt;Playing around with it, I found that when playing a note on a guitar, it was fairly consistent in pitch, although the attack and decay might be messed up. My solution to remove noise from deliberate notes is to have a queue that I constantly check. If the entire queue is of that same note, I can assume that that’s a deliberate note. The next thing is generating scales. For this I wrote a &lt;a href=&quot;https://codepen.io/Tzyinc/pen/QWweQXa&quot;&gt;helper function&lt;/a&gt; to generate scales from a root note and a step pattern like &lt;code class=&quot;language-text&quot;&gt;4-H-W-4-H&lt;/code&gt; where W is a whole step and H is a half step (and numbers are just the number of steps).&lt;/p&gt;
&lt;p&gt;Here’s my &lt;a href=&quot;https://app.tenzhiyang.com/tuner/&quot;&gt;scale practicing prototype&lt;/a&gt;&lt;/p&gt;</content:encoded><content:raw>
So I recently bought an electric guitar because... I&apos;m impulsive. I&apos;ve never played guitar before in my life, I can play very simple four chord songs on an ukulele, but guitar always seemed like such a step up from ukulele. In the end I justified to myself that since there are so much resources on guitar playing and in so many different styles, I could learn to be average at the guitar and then transfer those skills back into the ukulele.

After practicing on the C major scale for a couple of weeks, as well as the &quot;four chords&quot; (C G Am F on ukulele, G, D, E, C on guitar) I decided it was time to actually practice more scales. I already casually watch [@adamneelybass](https://twitter.com/adamneelybass) on [youtube](https://www.youtube.com/channel/UCnkp4xDOwqqJD7sSM3xdUiQ) and have left his 5 hour practice video in the background while working.

So I needed to find a way to learn and practice scales. I also bad at identifying tones or even notes on the neck. Splitting this problem up, I need 2 things:

- Identify what note I am playing
- Display what notes to play

Of course I would have liked to write some solution that identifies chords, but after some research, I found that multi tonal pitch detection is a very difficult problem to solve, and JS likely isn&apos;t the best tool for that job (I like writing &quot;serverless&quot; apps). I stumbled across this really [short and sweet repo for guitar tuning](https://github.com/cwilso/PitchDetect) by [@cwilso](https:twitter.com/cwilso) and found that it was really well written and easy to re-purpose.

Playing around with it, I found that when playing a note on a guitar, it was fairly consistent in pitch, although the attack and decay might be messed up. My solution to remove noise from deliberate notes is to have a queue that I constantly check. If the entire queue is of that same note, I can assume that that&apos;s a deliberate note. The next thing is generating scales. For this I wrote a [helper function](https://codepen.io/Tzyinc/pen/QWweQXa) to generate scales from a root note and a step pattern like `4-H-W-4-H` where W is a whole step and H is a half step (and numbers are just the number of steps).

Here&apos;s my [scale practicing prototype](https://app.tenzhiyang.com/tuner/)</content:raw></item><item><title><![CDATA[Adding a bot to post updates to twitter]]></title><description><![CDATA[Since I had to write a middleware for twitter anyway, why not just create a bot that updates my twitter for me?]]></description><link>https://blog.tenzhiyang.com/2020-01-29-twitter-upgrade-again/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2020-01-29-twitter-upgrade-again/</guid><pubDate>Wed, 29 Jan 2020 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Since I had to write a middleware for twitter anyway, why not just create a bot that updates my twitter for me?&lt;/p&gt;</content:encoded><content:raw>
Since I had to write a middleware for twitter anyway, why not just create a bot that updates my twitter for me?</content:raw></item><item><title><![CDATA[Adding twitter feed to my blog]]></title><description><![CDATA[Last year I wrote down my telegram ramblings as a blog post, but it’s too much of a hassle to create a post every time I have some idea for…]]></description><link>https://blog.tenzhiyang.com/2020-01-29-twitter-feed/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2020-01-29-twitter-feed/</guid><pubDate>Wed, 29 Jan 2020 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Last year I wrote down my telegram ramblings as a blog post, but it’s too much of a hassle to create a post every time I have some idea for a pet project. This year I will write them down in a tweet so that it can be easily catalogued and quickly referenced. Here’s to a better blog layout!&lt;/p&gt;</content:encoded><content:raw>
Last year I wrote down my telegram ramblings as a blog post, but it&apos;s too much of a hassle to create a post every time I have some idea for a pet project. This year I will write them down in a tweet so that it can be easily catalogued and quickly referenced. Here&apos;s to a better blog layout!</content:raw></item><item><title><![CDATA[New section here!]]></title><description><![CDATA[Adding a new section for my half baked ideas so that I can post anything that pops into my mind without it being a full article!]]></description><link>https://blog.tenzhiyang.com/2020-01-28-half-baked/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2020-01-28-half-baked/</guid><pubDate>Tue, 28 Jan 2020 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Adding a new section for my half baked ideas so that I can post anything that pops into my mind without it being a full article!&lt;/p&gt;</content:encoded><content:raw>
Adding a new section for my half baked ideas so that I can post anything that pops into my mind without it being a full article!
</content:raw></item><item><title><![CDATA[Five months into Lip]]></title><link>https://blog.tenzhiyang.com/2019-12-13-five-months-into-lip/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2019-12-13-five-months-into-lip/</guid><pubDate>Fri, 13 Dec 2019 00:00:00 GMT</pubDate><content:encoded>&lt;div class=&quot;gatsby-resp-iframe-wrapper&quot; style=&quot;padding-bottom: 56.25%; position: relative; height: 0; overflow: hidden; margin-bottom: 1.0725rem&quot; &gt; &lt;iframe src=&quot;https://www.youtube.com/embed/0TUP5qEBYhQ&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen style=&quot; position: absolute; top: 0; left: 0; width: 100%; height: 100%; &quot;&gt;&lt;/iframe&gt; &lt;/div&gt;</content:encoded><content:raw>
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/0TUP5qEBYhQ&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen&gt;&lt;/iframe&gt;</content:raw></item><item><title><![CDATA[Synth til it hertz]]></title><description><![CDATA[This article is a complement to my presentation in React Knowledgable. Before we go into the specifics, I’d like to disclose that I am no…]]></description><link>https://blog.tenzhiyang.com/2019-11-15-synth-til-it-hertz/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2019-11-15-synth-til-it-hertz/</guid><pubDate>Fri, 15 Nov 2019 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;&lt;strong&gt;This article is a complement to my presentation in React Knowledgable.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Before we go into the specifics, I’d like to disclose that I am no musician. I make sounds on an ukulele and sometimes it sounds like music. Whatever music theory I know is from Youtube videos. I have a fascination with electric musical instruments, from things like my electric ukulele, to synthesizers like the theremin.&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 124.32432432432432%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAZABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAMEBQL/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAF/UsRvCwzV0oHjg//EAB0QAAEEAgMAAAAAAAAAAAAAAAIAARESAzIiMUP/2gAIAQEAAQUCGbGVEGmd4ADvnHW8uI87kydejdf/xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/AR//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/AR//xAAcEAEAAQUBAQAAAAAAAAAAAAABAAIQESExQWH/2gAIAQEABj8C5qUmdrCZPkoXzUJhhUPLlv/EABwQAQACAwADAAAAAAAAAAAAAAEAESExQRBxof/aAAgBAQABPyE4eG4SwKFPY4O603CgLtSODpj7MdmNF8VKgAM2YfPxf//aAAwDAQACAAMAAAAQEM4A/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAwEBPxAf/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAgEBPxAf/8QAIBABAAICAgEFAAAAAAAAAAAAAQARITGhsUFRcZHB0f/aAAgBAQABPxCz1BQ2vp3GITAWi1H+TuN5GpHWWN4Qit1tvmMFaY8e8UgCyy3T9RQ8o0VeSUiwbtzOWdTmvua5/9k=) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/26f567f493557b8052e85192be634e53/a80bd/Theramin-Alexandra-Stepanoff-1930.jpg 148w,
/static/26f567f493557b8052e85192be634e53/1c91a/Theramin-Alexandra-Stepanoff-1930.jpg 295w,
/static/26f567f493557b8052e85192be634e53/1c72d/Theramin-Alexandra-Stepanoff-1930.jpg 590w,
/static/26f567f493557b8052e85192be634e53/75474/Theramin-Alexandra-Stepanoff-1930.jpg 822w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/26f567f493557b8052e85192be634e53/1c72d/Theramin-Alexandra-Stepanoff-1930.jpg&quot;
        srcset=&quot;/static/26f567f493557b8052e85192be634e53/a80bd/Theramin-Alexandra-Stepanoff-1930.jpg 148w,
/static/26f567f493557b8052e85192be634e53/1c91a/Theramin-Alexandra-Stepanoff-1930.jpg 295w,
/static/26f567f493557b8052e85192be634e53/1c72d/Theramin-Alexandra-Stepanoff-1930.jpg 590w,
/static/26f567f493557b8052e85192be634e53/75474/Theramin-Alexandra-Stepanoff-1930.jpg 822w&quot;
        title=&quot;theremin&quot;
        alt=&quot;theremin&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;p&gt;I always wanted to build my own synthesizer but I don’t have the time nor the patience to learn the electronics to go behind one of those, So why not build one using software? I had a target instrument in mind, the &lt;code class=&quot;language-text&quot;&gt;otamatone&lt;/code&gt;. This instrument has a touch bar that determined what note you were playing, and you can vocalize things close to words with the silicone mouth. While I probably can’t mimic the mouth of otamatone with software, I can definitely do things like have a touch interface that plays certain sound waves depending on where you touch.&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 177.70270270270268%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAkABQDASIAAhEBAxEB/8QAGQABAQEAAwAAAAAAAAAAAAAAAAEDAgQG/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAAB9BL1zZRMucNQQFB//8QAHBAAAQQDAQAAAAAAAAAAAAAAAQACEBEDEiIg/9oACAEBAAEFAouMnRRNJo7ThZaNfP8A/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAwEBPwFf/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAgEBPwFf/8QAHBAAAAYDAAAAAAAAAAAAAAAAAAECEBEgIVGB/9oACAEBAAY/AqJRvLmo+MUiK//EAB4QAAICAgIDAAAAAAAAAAAAAAERABAhUTFxQWHw/9oACAEBAAE/IYSomxQjcG6HwiGoDlC4xnCeBQUDRY7gcAPJOfdpV//aAAwDAQACAAMAAAAQQwwA8A//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/EF//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/EF//xAAgEAEAAQQBBQEAAAAAAAAAAAABEQAQITGhQVFxgZGx/9oACAEBAAE/EKAS6pPf2spXEL3UY9tIuigCRlgzGakawJkwbPMzxbAgDNGGv2igwEqFVK8tkEhJKBoBb//Z) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/3b36257ff63367dfd34a3f71352c064a/a80bd/ota.jpg 148w,
/static/3b36257ff63367dfd34a3f71352c064a/1c91a/ota.jpg 295w,
/static/3b36257ff63367dfd34a3f71352c064a/1c72d/ota.jpg 590w,
/static/3b36257ff63367dfd34a3f71352c064a/80e3c/ota.jpg 720w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/3b36257ff63367dfd34a3f71352c064a/1c72d/ota.jpg&quot;
        srcset=&quot;/static/3b36257ff63367dfd34a3f71352c064a/a80bd/ota.jpg 148w,
/static/3b36257ff63367dfd34a3f71352c064a/1c91a/ota.jpg 295w,
/static/3b36257ff63367dfd34a3f71352c064a/1c72d/ota.jpg 590w,
/static/3b36257ff63367dfd34a3f71352c064a/80e3c/ota.jpg 720w&quot;
        title=&quot;drawing of an otamatone&quot;
        alt=&quot;drawing of an otamatone&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;h2&gt;The science of music&lt;/h2&gt;
&lt;p&gt;In our early science education, we have learnt that sounds are vibrations that is sent through some medium (usually air) to our eardrums. The vibrations in our eardrums are then converted into electrical pulses and sent through our nerves. Here’s a visualization of the vibration as it appears in real life.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/986aa36e7d7ef78d05b645b6c1abc760/soundvibration.gif&quot; alt=&quot;sound vibration gif&quot;&gt;&lt;/p&gt;
&lt;p&gt;However this isn’t very useful for analysis so we represent these vibrations in the form of waves like so:&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 51.35135135135135%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAABYlAAAWJQFJUiTwAAAA/klEQVQoz6WSQW/CMAyF43ZItNsaBGwaNEpuZUK99AjizpHtsv3/X2KeO2dKJyhCOzw1tf2+2K3Ntut4UdccQuDgPfs7JR7xCqMFyxzXa3bGsPmnPHRwNZsO9B1ePh5yfibqk7k8IboiyeVaK55PeIXRgmVqtCyJVyS+MuK53piNdBNzC0g8LwrvWUGBogL6RsFsBBpjc60t0rGF5RUYRyi10GpRnhjiefYHFr0DoHyXePuTjvJ2ocOV5h7Tji8BSYMRWhB+VJbxDuYl/WiP8wmxKQ3HpxTonBtdh3dZB9Xmxur0rKZpuCxLttZyVVW/sqoJVKgmSXxQC68whHUGJl7f4O+oenwAAAAASUVORK5CYII=) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/7cb75dd133c11c8b134ad324f9b548da/12f09/coswave.png 148w,
/static/7cb75dd133c11c8b134ad324f9b548da/e4a3f/coswave.png 295w,
/static/7cb75dd133c11c8b134ad324f9b548da/fcda8/coswave.png 590w,
/static/7cb75dd133c11c8b134ad324f9b548da/efc66/coswave.png 885w,
/static/7cb75dd133c11c8b134ad324f9b548da/eb3fa/coswave.png 1026w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/7cb75dd133c11c8b134ad324f9b548da/fcda8/coswave.png&quot;
        srcset=&quot;/static/7cb75dd133c11c8b134ad324f9b548da/12f09/coswave.png 148w,
/static/7cb75dd133c11c8b134ad324f9b548da/e4a3f/coswave.png 295w,
/static/7cb75dd133c11c8b134ad324f9b548da/fcda8/coswave.png 590w,
/static/7cb75dd133c11c8b134ad324f9b548da/efc66/coswave.png 885w,
/static/7cb75dd133c11c8b134ad324f9b548da/eb3fa/coswave.png 1026w&quot;
        title=&quot;cosine wave&quot;
        alt=&quot;cosine wave&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;p&gt;It should look familiar, that’s the cosine wave that we’ve seen in math so often.  A musical note is the same as any other sound but vibrating consistently(ish) at certain frequencies. Scientifically, we will measure these frequencies using &lt;code class=&quot;language-text&quot;&gt;hertz&lt;/code&gt;. One &lt;code class=&quot;language-text&quot;&gt;hertz&lt;/code&gt; is equivalent to one complete cycle per second. So the above wave in 440 hertz (Hz) is basically 440 times of the above graph happening in a second.&lt;/p&gt;
&lt;p&gt;So how do we define what is in tune and what is not? In fact, tuning is socially constructed and learnt. Things only sound in tune because we are trained to recognize the notes as being in tune. For the purpose of simplicity I’ll use western system of music with 12 equally spaced (semi)tones in an octave (doh re mi all the way back to doh) for the rest of this article. &lt;a href=&quot;https://www.youtube.com/watch?v=H4KIwA8O9LU&quot;&gt;Adam Neely on Youtube&lt;/a&gt; goes into deeper details of tones in between the 12 tones still present in the ever popular lo-fi hip hop tunes.&lt;/p&gt;
&lt;p&gt;Unless you have perfect pitch, many people are unable to identify what is in tune or not. In fact, we are so inconsistent that there’s no universally agreed list of frequencies that are considered in tune. Even in western music, the concept of 12 equally spaced tones has been recently contested multiple times. It is, however very obvious when a certain note is played off key in relation to the others.&lt;/p&gt;
&lt;p&gt;Where does that leave us? There is one universal truth though, that is given any root note, we can double the frequency and to us, it sounds like the same note, only higher. This is due to the wave start points and endpoints aligning every two cycles. In the case of 440Hz, we know that one octave higher is exactly 880Hz and one octave lower is 220Hz. Since we are using equally spaced tones, we can use &lt;a href=&quot;https://pages.mtu.edu/~suits/NoteFreqCalcs.html&quot;&gt;a formula I found from Michigan Technological University’s site:&lt;/a&gt;&lt;/p&gt;
&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;∗&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;f_n = f_0 * (a)^n&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.8888799999999999em;vertical-align:-0.19444em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.10764em;&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.151392em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.8888799999999999em;vertical-align:-0.19444em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.10764em;&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.30110799999999993em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;∗&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.7143919999999999em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;p&gt;where &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;f_0&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.8888799999999999em;vertical-align:-0.19444em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.10764em;&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.30110799999999993em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is a pre-defined root note and &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;n&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.43056em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is the nth note from the root note. To figure out the constant &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;a&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.43056em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;, we will use &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msup&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/mfrac&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;a = 2^{\frac{1}{N}}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.43056em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.9540200000000001em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.9540200000000001em;&quot;&gt;&lt;span style=&quot;top:-3.363em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mopen nulldelimiter sizing reset-size3 size6&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mfrac&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.8443142857142858em;&quot;&gt;&lt;span style=&quot;top:-2.656em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size3 size1 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.10903em;&quot;&gt;N&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.2255000000000003em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;frac-line mtight&quot; style=&quot;border-bottom-width:0.049em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.384em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size3 size1 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.344em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose nulldelimiter sizing reset-size3 size6&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; where &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;N&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.68333em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.10903em;&quot;&gt;N&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is the number of tones we want in an octave. Intuitively, we expect &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;a^n&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.664392em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.664392em;&quot;&gt;&lt;span style=&quot;top:-3.063em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; to be equal to 2 when &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;n = N&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.43056em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.68333em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.10903em;&quot;&gt;N&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;. Remember that an octave higher is just &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;∗&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;f_0 * 2&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.8888799999999999em;vertical-align:-0.19444em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.10764em;&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.30110799999999993em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;∗&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.64444em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;.&lt;/p&gt;
&lt;h2&gt;Notes in numbers&lt;/h2&gt;
&lt;p&gt;In the case of a physical musical instrument, like an electric ukulele for example, we can easily get the sound by recording vibrations through an electrical component like a pickup, there are many different type of pickups, and the one that’s on my ukulele is over what we call the bridge. We don’t have to worry about frequencies in such instruments as the pickup converts the vibrations into electrical pulses, these frequencies will be in tune as long as the instrument itself is in tune. &lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 97.2972972972973%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAATCAYAAACQjC21AAAACXBIWXMAABYlAAAWJQFJUiTwAAAEbElEQVQ4y1WU60/TZxTH+Sv2cia7xiV7MbMsW8zii73QMaPG4SVxOl3QqYiumzpQV7wUHaAwe3FgGCCCoNCKNxCZFS0O8FZxAgrYUqAolELFQu/97Pk9P9pkJ/ldnnOe8z3P+Z5znpR4PE4sFmNqNsDoyDDdljN4RodRJBaNEpuzy32Jf/HEhN3tneKxzcrksIOwWMfF/hTFOB0M8crloKlIx43833hSrMM7PqaCJsAiYQEUlbrZUJjnThe2urOYSwwMXjjFpDiEYk2Ji9eLgX4aTSewGY7y7ykdjbm/8qCqWG6IiqjhSBR7Qw39nW1S98Y/Q8NfxVwtL6F2Xwb2s0aGrtcSCIVIUSL2tlzBnJXB43I9D4q01B/Owtn9hJCIFonGmPH7uVthpPd+pzzh8/Y7nElfyY3TRdhrSyjVabl6rpopn08FdNnv8bRwP9bcPVjyDmNvbmJ06rUgJSYBXI4XVOoLk+tpzxjPjVqq0ldQXnScOpMJa3MrwXBY5VBJ2911n57zZdyymOlzuaVjJBKR3472DnK0B+V/OByW3wlnP60lhVj+LMXe1SuLpGClJEhXQL3+WSbezEgHxZgAbLXeorCgIBlE8VEkFAwy7nYTDMzOFVCpsgALiU1+UWnf1BQTExO4x8ZlRKUgitSdv4BRb/jfCc9XVmDQbKG9IItWQy4jz7qlPiUqooXjcRLS3tHJ/Pkf0dp4OakrKy2loqw8ubY/srNowad8/MGH/L59EzadhjZjLrMzfrUoVlsbK1etwX6zSRRFS+biz2k4oiEcVVPLz8un1GRMAlrE6RZ9soCV3yzn/XnvkLl6Bbfzs/GIXpaA1SUmPnv7LSp2ruPmwS1c16Rh1edIZ/+Ig0MZm/kjYxPTI4NSN9x1j7y1qaxeksqyxam8N+9dfliWyqxvUgX0ul3cPLqT+q1LqdzwFecy0hjp65HOzjvXsR7awSXNOkYfq304HQjwqOY0pZtXkfblQpZ8sZBL56pUDhMV8016efagHadw8r+eJBBTeR1ouUjL/s1Ytn3Ly/4eQnPjGBH2SUcf/1y9SNeTp8kxTQL6vR4xMZd5dK2BUYdDtpFSz676Mi7s2kDNtjV4h51JHpVW6b3bQu+NenyObhlA6RiZ8phzgPJt33HZdBzblQYMO7bSd09N78rJXLYvWyLSS8M/5k6CtZoO07hnDZf2rqdiaxo9zWY1ZeVlPnYQ7fq16ItP090/gK3xGhV7NASUpi7I5lr615h//h6PuIGUkz/ruEVT9nqemg5Qu387G5cuxnpUg8/zSgU8kb4Rve6IaF492pwcqkWLlO3LljzaKw2YBX/NB34k9MYnAR1tzVT9tIHMVcu5k7+b23m/YNXtYnxwQAWsM+gpyM6iu6eHixYLtr+tDA6NymkJicnwjI9LjmNzk/N6dIgGbQbH0tfSVrCbNl0mnWUnCCaur6Bog+L849RU1+IaGsI3EyCkOMdVohOi3tgq6NDDuzw05tB58gAPq0x4X45I/X9Px/OZmqpa9QAAAABJRU5ErkJggg==) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/459a98a27c007bc8d5483cb1f60ce98b/12f09/electricukulele.png 148w,
/static/459a98a27c007bc8d5483cb1f60ce98b/e4a3f/electricukulele.png 295w,
/static/459a98a27c007bc8d5483cb1f60ce98b/fcda8/electricukulele.png 590w,
/static/459a98a27c007bc8d5483cb1f60ce98b/efc66/electricukulele.png 885w,
/static/459a98a27c007bc8d5483cb1f60ce98b/0a867/electricukulele.png 986w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/459a98a27c007bc8d5483cb1f60ce98b/fcda8/electricukulele.png&quot;
        srcset=&quot;/static/459a98a27c007bc8d5483cb1f60ce98b/12f09/electricukulele.png 148w,
/static/459a98a27c007bc8d5483cb1f60ce98b/e4a3f/electricukulele.png 295w,
/static/459a98a27c007bc8d5483cb1f60ce98b/fcda8/electricukulele.png 590w,
/static/459a98a27c007bc8d5483cb1f60ce98b/efc66/electricukulele.png 885w,
/static/459a98a27c007bc8d5483cb1f60ce98b/0a867/electricukulele.png 986w&quot;
        title=&quot;the electric ukulele that I own&quot;
        alt=&quot;the electric ukulele that I own&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;p&gt;When making a synthesizer, I can do two solutions: get a sample of every possible note my instrument needs to play, or generate my own electrical pulses to send to the speakers. We know that sound is generated via waves, so for my first prototype I just needed to play some note based on the y-coordinate of the user’s touch event. The &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/AudioContext&quot;&gt;audio context api&lt;/a&gt; gives us gain and oscillator nodes to play with. So trying to just make a sound, let’s have something like this.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;// support for different browsers
let context = new (window.AudioContext || window.webkitAudioContext)();
let o, g;
let freq = 440;
let isPlaying = false;
function playNote() {
    // re-using an oscillator seems to result in noise being introduced into output
    o = context.createOscillator();
    g = context.createGain();

    // can be sine, square, sawtooth, triangle. defaults to sine
    o.type = sine;
    o.connect(g);
    g.connect(context.destination);

    // you can actually start in the middle of the wave
    // to manipulate the attack of the note
    // but this is not covered in the
    o.start(0);
    o.frequency.setValueAtTime(freq, context.currentTime);

    // flag to be used later
    isPlaying = true;
}

function stopNote() {
    // if a wave abruptly stops, there will be a &amp;quot;click&amp;quot; sound
    // even if we exponentially volume down for 40 ms it&amp;#39;s good enough
    g.gain.exponentialRampToValueAtTime(
        0.00001, // api doesn&amp;#39;t accept 0
        context.currentTime + 0.04,
    );
    
    setTimeout(function () {
        // if we don&amp;#39;t stop, the garbage collector will not clean it up
        o.stop();
        isPlaying = false;
    }, 41); // as long as it&amp;#39;s after the exponential ramp its ok
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If we go back to our understanding of waves in mathematics, gain is basically a coefficient to the amplitude of the generated waves. This helps control the volume of the sound being played. To play different notes, we need to manipulate the frequency. Right now our code will default to 440 Hz, so if we’re looking for 2 octaves range we need to find a way to map the y coordinate of the user between the range 440 and 1760. As value of hertz between notes do not scale linearly, we can make use of MTU’s formula which works well with frequencies in between the semi tones. This allows us to pass in some number between 0 to 24 and it should work for 2 complete octaves.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;const scaleHeight = (
        num,
        out_min = 0,
        out_max = 24, // semitones in 2 octaves
        in_min = 0,
        in_max = Math.max(document.documentElement.clientHeight, window.innerHeight || 0) //viewport height
    ) =&amp;gt; {
    const scaleMap = (num - in_min) * (out_max - out_min) / (in_max - in_min) + out_min;

    const hertz = ROOT_NOTE * Math.pow(1.059463094359, scaleMap);
    return hertz; 
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I found online that 440Hz is widely accepted as the frequency of a in the fourth octave. So I’ve sent the constant &lt;code class=&quot;language-text&quot;&gt;ROOT_NOTE = 440&lt;/code&gt; and the notes will be calculated in relation to that.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;function setNote(newFreq) {
    // we want oscillator to be initialized when we change it
    if (isPlaying) {
        o.frequency.setValueAtTime(newFreq, context.currentTime);
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now that we’ve got the notes playing, the resulting sine wave sounds quite like a recorder, so let’s add some way to customize how it sounds.&lt;/p&gt;
&lt;h2&gt;It’s going down, I’m telling timbre&lt;/h2&gt;
&lt;p&gt;From wikipedia, timbre is what makes a particular musical sound have a different sound from another. In order to change the timbre, we need to change how the waves look like. Web audio api provides us a function &lt;code class=&quot;language-text&quot;&gt;OscillatorNode.setPeriodicWave()&lt;/code&gt; which accepts a periodicWave object that can be &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/BaseAudioContext/createPeriodicWave&quot;&gt;created&lt;/a&gt; using &lt;code class=&quot;language-text&quot;&gt;AudioContext.createPeriodicWave(real, imag[, constraints]);&lt;/code&gt;. In order to understand the inputs, we need to have a rough understanding of fourier series. &lt;/p&gt;
&lt;p&gt;The main concept we need to know is that all waves is either sinusoidal (derived from sine) or can be approximated from the summation of sinusoidal waves. All these waves can be represented in the form of fourier series&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/0ba07fafcccac50d42d6167038c7f630/bartgif.gif&quot; alt=&quot;bart simpson drawn using epicycles&quot;&gt;&lt;/p&gt;
&lt;p&gt;Looking at how the (non-normalised) waveform is generated from &lt;a href=&quot;https://webaudio.github.io/web-audio-api/#waveform-generation&quot;&gt;the specifications&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;Let a and b represent the &lt;code class=&quot;language-text&quot;&gt;[real]&lt;/code&gt; and &lt;code class=&quot;language-text&quot;&gt;[imag]&lt;/code&gt; arrays of length &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;L&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.68333em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;L&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; respectively. then the basic time-domain waveform, &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;x(t)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; can be computed using:&lt;/p&gt;
&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;munderover&gt;&lt;mo&gt;∑&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/munderover&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;mi&gt;cos&lt;/mi&gt;&lt;mo&gt;⁡&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;mi&gt;sin&lt;/mi&gt;&lt;mo&gt;⁡&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;x(t) = \sum^{L-1}_{k=1} [a[k]\cos 2\pi kt + b[k]\sin 2\pi kt]&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:3.1304490000000005em;vertical-align:-1.302113em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mop op-limits&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.8283360000000002em;&quot;&gt;&lt;span style=&quot;top:-1.8478869999999998em;margin-left:0em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3.05em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.03148em;&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;mrel mtight&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.0500049999999996em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3.05em;&quot;&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;mop op-symbol large-op&quot;&gt;∑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-4.300005em;margin-left:0em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3.05em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;mbin mtight&quot;&gt;−&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.302113em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03148em;&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mop&quot;&gt;cos&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03588em;&quot;&gt;π&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03148em;&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03148em;&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mop&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03588em;&quot;&gt;π&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03148em;&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;p&gt;In english, what this means is that with &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;t&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.61508em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; from 0 to 1 (for one cycle), take &lt;code class=&quot;language-text&quot;&gt;[real]&lt;/code&gt; and &lt;code class=&quot;language-text&quot;&gt;[imag]&lt;/code&gt; of equal lengths and ignore the first value (for mathematical reasons I will not go through). We will then pass in all the other values in the array into the function above. To help myself visualize this function, I built &lt;a href=&quot;https://httpserve.tenzhiyang.com/fourierSeriesVis/&quot;&gt;a tool&lt;/a&gt; that draws the wave using this exact formula, and map out one complete cycle. We can also keep adding coefficients to the &lt;code class=&quot;language-text&quot;&gt;real&lt;/code&gt; and &lt;code class=&quot;language-text&quot;&gt;imag&lt;/code&gt; arrays and see how it affects the wave. I also added an audio context to play said wave that is being displayed.&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 79.05405405405406%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAYAAAAWGF8bAAAACXBIWXMAABYlAAAWJQFJUiTwAAABhElEQVQ4y5WT0WrCQBBFjYkaE6sGktgkGiMULURLfJGC4qOIf2B/zwf1wW/w027vLFqQKmQfLjO7m7mc2dlUKpUKXskwTRU3mw2u1yv2+/3D/gs9P3izbby3XBiWhfF4jB+afc1mqHLtOQ58SsswZEH6jMQwEDMGrqvy0oZes4mIhkPm7yzMmHuMEyqRDniuZWix4JPx4yYxzikxm1CurmGdBUWSIO12YTN32GKTMQ58fA8GcFotvTtUbQcBrHr9YU+Mk+FQb8q9Xg+j0QhpmqJPyhmnu1qtMJ/P0e/3kdEwyzIkPCtlWK1WlaRFk8Ook7LT6cDmU7rnBu9PvillGIahIhAJ0XQ6VYRFUai10A9JGcexHqEQ3QlbHIJEUbvd1iMMOAwhEAlRnudYLpf/CKMoKmdo8feq1WqKSmKj0VC5EIs8z1P7Ii3CAd/b/Q7X67WaskxWpi8qTWje/mExPZ1OOJ/POBwOOB6PuFwuWCwWf51oPWyXj3i73T5ot9vB9/2XNb/eP28qfZGdHwAAAABJRU5ErkJggg==) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/ed5824084d7a551bad7b7cefc774c7f4/12f09/periodicwave.png 148w,
/static/ed5824084d7a551bad7b7cefc774c7f4/e4a3f/periodicwave.png 295w,
/static/ed5824084d7a551bad7b7cefc774c7f4/fcda8/periodicwave.png 590w,
/static/ed5824084d7a551bad7b7cefc774c7f4/efc66/periodicwave.png 885w,
/static/ed5824084d7a551bad7b7cefc774c7f4/1ac29/periodicwave.png 1022w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/ed5824084d7a551bad7b7cefc774c7f4/fcda8/periodicwave.png&quot;
        srcset=&quot;/static/ed5824084d7a551bad7b7cefc774c7f4/12f09/periodicwave.png 148w,
/static/ed5824084d7a551bad7b7cefc774c7f4/e4a3f/periodicwave.png 295w,
/static/ed5824084d7a551bad7b7cefc774c7f4/fcda8/periodicwave.png 590w,
/static/ed5824084d7a551bad7b7cefc774c7f4/efc66/periodicwave.png 885w,
/static/ed5824084d7a551bad7b7cefc774c7f4/1ac29/periodicwave.png 1022w&quot;
        title=&quot;screenshot of my fourier series visualizer tool&quot;
        alt=&quot;screenshot of my fourier series visualizer tool&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;p&gt;Now with this tool, we can approximate how an otamatone’s waveform looks like from &lt;a href=&quot;http://www.windytan.com/2017/11/in-pursuit-of-otamas-tone.html&quot;&gt;this excellent audio analysis of the otamatone&lt;/a&gt; by &lt;a href=&quot;https://twitter.com/windyoona&quot;&gt;@windyoona&lt;/a&gt;. Of course by approximate I really mean making a wave, looking at it and then saying “ehh good enough” and that’s it.&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 121.62162162162163%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAYCAYAAAD6S912AAAACXBIWXMAABYlAAAWJQFJUiTwAAACwElEQVQ4y6VVy05iQRDl/Ua4BgXkKchDMSYoEiLqYuKC0YQVCSvXhL9wgwsXwAI1xMSNiRtY6R+Y+a8zdXq8E2EuDJMhKbq4ffv0qapThSmfzyMWi+H6+hrv7++YTCaYTqd4e3tDt9vF0dERarUajo+PUa/XcXh4iGw2i52dHUMzyYdfOD8/x+vrKx4eHjAej/Hy8oLLy0t43G5oWhB+vx+RSBg+nw/6GUMzm82gLXvp+9UVfnx8YDgcwmKxzOzp57/gzG5ytdlsiKytISQWsNtxcXqKm9tbdDod+AIBeD0e+IWpW9gbEPiTkcvpxL4ciov/TcATsmqfe74vETENBtEZA+ZdLoTF3zebkLOYURHgA6sVdQFwynOHmNvrXQ3QSYYC+Pu3mEUs/cn0QvKYJ6gAWlZlePAJOM/AJpYSyxBcQjatAmiXQpREIpFIROWJUvllXvVbk+clMU2KtlJRaG4BSCaThnsFaYbC7u4imc0+0DQNXsmNW0JeEwYuWSkPsmZu6WcyGWxtbcHhcGBjY2Nem7MabDQaKJfLqo0KhQLYmsViUR3c3t5Wz3TjO61Wa757FnfIog5iKoLB4PKQ9cPNZhOVSkXdTnZksiv5IkOGSj+Xyym/Wq0qhuyspQytImDmhzlkfniAq+7zIuZQV8TSopycnMjtWYTDYTXWotGoOkzwzc1N5ZMd987OzhT4XGpmAROJBEKhkKo2QQMyDOizugSlr8/QVCqltLoUkC+sr68rIOaNIPQpH1aTxeCALZVKirFHhghTtLAoHLRkwFDJlky4EpSX0eceJzknOC9lvv8qG17A240klE6nVRT/JBuypJDj8bjSHbtHZ8jn7XYbe3t7SlbsoIUMv7YRwUejEfr9Pu7u7pQNBgP0er1F09o4ZB2Uon1+fsbj4yPu7+/VH9jT05O6QGe10oD9H/sJ6/NKv9VfQigAAAAASUVORK5CYII=) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/f671bd6e0c83f4933eb1962da5256092/12f09/goodenough.png 148w,
/static/f671bd6e0c83f4933eb1962da5256092/e4a3f/goodenough.png 295w,
/static/f671bd6e0c83f4933eb1962da5256092/fcda8/goodenough.png 590w,
/static/f671bd6e0c83f4933eb1962da5256092/5d72a/goodenough.png 834w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/f671bd6e0c83f4933eb1962da5256092/fcda8/goodenough.png&quot;
        srcset=&quot;/static/f671bd6e0c83f4933eb1962da5256092/12f09/goodenough.png 148w,
/static/f671bd6e0c83f4933eb1962da5256092/e4a3f/goodenough.png 295w,
/static/f671bd6e0c83f4933eb1962da5256092/fcda8/goodenough.png 590w,
/static/f671bd6e0c83f4933eb1962da5256092/5d72a/goodenough.png 834w&quot;
        title=&quot;my good enough attempt&quot;
        alt=&quot;my good enough attempt&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;p&gt;So all I have left to do is to put the generated wave array into my otamatone and presto! We have something that plays and sounds like the actual instrument. I’ve added a few quality of life features such as the ability to switch waves, and pitch correction (think of it like autotune). I call it the &lt;a href=&quot;https://httpserve.tenzhiyang.com/otamaphone&quot;&gt;otamaphone&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 165.54054054054052%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAhCAYAAADZPosTAAAACXBIWXMAABYlAAAWJQFJUiTwAAADCUlEQVRIx62WvU5yQRCGFwEFRFEE/EOEmCioCETwL1hoYqfhJrwBO27AzivxFixIaCigJtZ09hYGipFndM9HFP0icJJhz9ndeXfmnZ/FVKtVeXp6ku3tbZmenpZgMCizs7N/lkAgINFoVMzj46P0ej05Pj4WY4y4XC4dRxG/3y8mm83K5eWlhEIhWVxcHFnQX19fFzM3N6foPp9vLIGucDgshp+ZmRkVJu34F0HH6/WqpcbvD4zM2VchMCYSiSiZo0R2UMAAy6ysrGiqzM/PjyVggGXUzEm6DJEQagMzqjhBicViygHpM46AAZahXDB11JJD0HVKT8tlQhwq1sQ5XFhYEI/H8+fq+CpggGVCoX+AnDJMfluz6w4gtczEsIKHE8hmHHz/tTkMS+z/9cSf1ocmNqdNTU2pJXt7e1IsFqVQKKjwvrOzo+u2y3wLyurqqtYi/jPBKVwHKJOoGxsbwp54PK61mkql5Pz8XHVoqughfLPPiTKn4AoK+/v7cnNzI7e3t+oKpzMCeHFxIZubm2ox+23/dIJClltOeD85OdH3Wq0mPIlEwuHo4eFBut2u0oEX2vL78263WzG0++Omte7g4EBsKTYaDXl9fVXXLSC3Iw8uA8LFBp/w/o1DPs7OzpQX+Hp+fpa3tzedwx2sabfbCnh9fa0GAMg8lqGnHFLcnM4kEbScNZtNeXl5+Sj4z7l6vS6dTuejq/TncFtz79MDxYJIzMfsfD7vBODo6EhOT0+doseira0tDZgF2N3dleXlZV1zgsIPUYILOEyn03J3d+cosXEwmRkPDw81gIy2SjBEAeEA/uARsKurK7m/v1drS6WScshBfGNRpVKRVqsl5XJZ+JMAVUtLSwqmUeckaw2gVIdNBaxmYzKZVCFH19bWdCQglh722bQzgDBhFwHE0t9qFssAtsGCFjDAMpgLD7aTkJO5XE6DQjRxiQrJZDLqNhRQKQBZHUYwwPrxCiAd4Axw0gl+bAr9fAX0uw3uUV5wxMkI7wAgJDkjLiJ23e6132Ck0xl5ByLDLRqxCH9yAAAAAElFTkSuQmCC) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/f5c5eb10e749d35029d79c5e95381f3d/12f09/otamascreen.png 148w,
/static/f5c5eb10e749d35029d79c5e95381f3d/e4a3f/otamascreen.png 295w,
/static/f5c5eb10e749d35029d79c5e95381f3d/fcda8/otamascreen.png 590w,
/static/f5c5eb10e749d35029d79c5e95381f3d/efc66/otamascreen.png 885w,
/static/f5c5eb10e749d35029d79c5e95381f3d/d9217/otamascreen.png 904w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/f5c5eb10e749d35029d79c5e95381f3d/fcda8/otamascreen.png&quot;
        srcset=&quot;/static/f5c5eb10e749d35029d79c5e95381f3d/12f09/otamascreen.png 148w,
/static/f5c5eb10e749d35029d79c5e95381f3d/e4a3f/otamascreen.png 295w,
/static/f5c5eb10e749d35029d79c5e95381f3d/fcda8/otamascreen.png 590w,
/static/f5c5eb10e749d35029d79c5e95381f3d/efc66/otamascreen.png 885w,
/static/f5c5eb10e749d35029d79c5e95381f3d/d9217/otamascreen.png 904w&quot;
        title=&quot;screenshot of otamaphone&quot;
        alt=&quot;screenshot of otamaphone&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;</content:encoded><content:raw>
**This article is a complement to my presentation in React Knowledgable.**

Before we go into the specifics, I&apos;d like to disclose that I am no musician. I make sounds on an ukulele and sometimes it sounds like music. Whatever music theory I know is from Youtube videos. I have a fascination with electric musical instruments, from things like my electric ukulele, to synthesizers like the theremin.

![theremin](https://upload.wikimedia.org/wikipedia/commons/1/11/Theramin-Alexandra-Stepanoff-1930.jpg)

I always wanted to build my own synthesizer but I don&apos;t have the time nor the patience to learn the electronics to go behind one of those, So why not build one using software? I had a target instrument in mind, the `otamatone`. This instrument has a touch bar that determined what note you were playing, and you can vocalize things close to words with the silicone mouth. While I probably can&apos;t mimic the mouth of otamatone with software, I can definitely do things like have a touch interface that plays certain sound waves depending on where you touch.

![drawing of an otamatone](https://httpserve.tenzhiyang.com/otamaphone/ota.jpg)

## The science of music

In our early science education, we have learnt that sounds are vibrations that is sent through some medium (usually air) to our eardrums. The vibrations in our eardrums are then converted into electrical pulses and sent through our nerves. Here&apos;s a visualization of the vibration as it appears in real life.

![sound vibration gif](./soundvibration.gif)

However this isn&apos;t very useful for analysis so we represent these vibrations in the form of waves like so:

![cosine wave](./coswave.png)

It should look familiar, that&apos;s the cosine wave that we&apos;ve seen in math so often.  A musical note is the same as any other sound but vibrating consistently(ish) at certain frequencies. Scientifically, we will measure these frequencies using `hertz`. One `hertz` is equivalent to one complete cycle per second. So the above wave in 440 hertz (Hz) is basically 440 times of the above graph happening in a second.

So how do we define what is in tune and what is not? In fact, tuning is socially constructed and learnt. Things only sound in tune because we are trained to recognize the notes as being in tune. For the purpose of simplicity I&apos;ll use western system of music with 12 equally spaced (semi)tones in an octave (doh re mi all the way back to doh) for the rest of this article. [Adam Neely on Youtube](https://www.youtube.com/watch?v=H4KIwA8O9LU) goes into deeper details of tones in between the 12 tones still present in the ever popular lo-fi hip hop tunes.

Unless you have perfect pitch, many people are unable to identify what is in tune or not. In fact, we are so inconsistent that there&apos;s no universally agreed list of frequencies that are considered in tune. Even in western music, the concept of 12 equally spaced tones has been recently contested multiple times. It is, however very obvious when a certain note is played off key in relation to the others.

Where does that leave us? There is one universal truth though, that is given any root note, we can double the frequency and to us, it sounds like the same note, only higher. This is due to the wave start points and endpoints aligning every two cycles. In the case of 440Hz, we know that one octave higher is exactly 880Hz and one octave lower is 220Hz. Since we are using equally spaced tones, we can use [a formula I found from Michigan Technological University&apos;s site:](https://pages.mtu.edu/~suits/NoteFreqCalcs.html)

$$
f_n = f_0 * (a)^n
$$

where $f_0$ is a pre-defined root note and $n$ is the nth note from the root note. To figure out the constant $a$, we will use $a = 2^{\frac{1}{N}}$ where $N$ is the number of tones we want in an octave. Intuitively, we expect $a^n$ to be equal to 2 when $n = N$. Remember that an octave higher is just $f_0 * 2$.

## Notes in numbers

In the case of a physical musical instrument, like an electric ukulele for example, we can easily get the sound by recording vibrations through an electrical component like a pickup, there are many different type of pickups, and the one that&apos;s on my ukulele is over what we call the bridge. We don&apos;t have to worry about frequencies in such instruments as the pickup converts the vibrations into electrical pulses, these frequencies will be in tune as long as the instrument itself is in tune. 

![the electric ukulele that I own](./electricukulele.png)

When making a synthesizer, I can do two solutions: get a sample of every possible note my instrument needs to play, or generate my own electrical pulses to send to the speakers. We know that sound is generated via waves, so for my first prototype I just needed to play some note based on the y-coordinate of the user&apos;s touch event. The [audio context api](https://developer.mozilla.org/en-US/docs/Web/API/AudioContext) gives us gain and oscillator nodes to play with. So trying to just make a sound, let&apos;s have something like this.

```
// support for different browsers
let context = new (window.AudioContext || window.webkitAudioContext)();
let o, g;
let freq = 440;
let isPlaying = false;
function playNote() {
    // re-using an oscillator seems to result in noise being introduced into output
    o = context.createOscillator();
    g = context.createGain();

    // can be sine, square, sawtooth, triangle. defaults to sine
    o.type = sine;
    o.connect(g);
    g.connect(context.destination);

    // you can actually start in the middle of the wave
    // to manipulate the attack of the note
    // but this is not covered in the
    o.start(0);
    o.frequency.setValueAtTime(freq, context.currentTime);

    // flag to be used later
    isPlaying = true;
}

function stopNote() {
    // if a wave abruptly stops, there will be a &quot;click&quot; sound
    // even if we exponentially volume down for 40 ms it&apos;s good enough
    g.gain.exponentialRampToValueAtTime(
        0.00001, // api doesn&apos;t accept 0
        context.currentTime + 0.04,
    );
    
    setTimeout(function () {
        // if we don&apos;t stop, the garbage collector will not clean it up
        o.stop();
        isPlaying = false;
    }, 41); // as long as it&apos;s after the exponential ramp its ok
}
```

If we go back to our understanding of waves in mathematics, gain is basically a coefficient to the amplitude of the generated waves. This helps control the volume of the sound being played. To play different notes, we need to manipulate the frequency. Right now our code will default to 440 Hz, so if we&apos;re looking for 2 octaves range we need to find a way to map the y coordinate of the user between the range 440 and 1760. As value of hertz between notes do not scale linearly, we can make use of MTU&apos;s formula which works well with frequencies in between the semi tones. This allows us to pass in some number between 0 to 24 and it should work for 2 complete octaves.

```
const scaleHeight = (
        num,
        out_min = 0,
        out_max = 24, // semitones in 2 octaves
        in_min = 0,
        in_max = Math.max(document.documentElement.clientHeight, window.innerHeight || 0) //viewport height
    ) =&gt; {
    const scaleMap = (num - in_min) * (out_max - out_min) / (in_max - in_min) + out_min;

    const hertz = ROOT_NOTE * Math.pow(1.059463094359, scaleMap);
    return hertz; 
}
```

I found online that 440Hz is widely accepted as the frequency of a in the fourth octave. So I&apos;ve sent the constant `ROOT_NOTE = 440` and the notes will be calculated in relation to that.

```
function setNote(newFreq) {
    // we want oscillator to be initialized when we change it
    if (isPlaying) {
        o.frequency.setValueAtTime(newFreq, context.currentTime);
    }
}
```

Now that we&apos;ve got the notes playing, the resulting sine wave sounds quite like a recorder, so let&apos;s add some way to customize how it sounds.

## It&apos;s going down, I&apos;m telling timbre

From wikipedia, timbre is what makes a particular musical sound have a different sound from another. In order to change the timbre, we need to change how the waves look like. Web audio api provides us a function `OscillatorNode.setPeriodicWave()` which accepts a periodicWave object that can be [created](https://developer.mozilla.org/en-US/docs/Web/API/BaseAudioContext/createPeriodicWave) using `AudioContext.createPeriodicWave(real, imag[, constraints]);`. In order to understand the inputs, we need to have a rough understanding of fourier series. 

The main concept we need to know is that all waves is either sinusoidal (derived from sine) or can be approximated from the summation of sinusoidal waves. All these waves can be represented in the form of fourier series

![bart simpson drawn using epicycles](./bartgif.gif)

Looking at how the (non-normalised) waveform is generated from [the specifications](https://webaudio.github.io/web-audio-api/#waveform-generation):

Let a and b represent the `[real]` and `[imag]` arrays of length $L$ respectively. then the basic time-domain waveform, $x(t)$ can be computed using:
$$
x(t) = \sum^{L-1}_{k=1} [a[k]\cos 2\pi kt + b[k]\sin 2\pi kt]
$$

In english, what this means is that with $t$ from 0 to 1 (for one cycle), take `[real]` and `[imag]` of equal lengths and ignore the first value (for mathematical reasons I will not go through). We will then pass in all the other values in the array into the function above. To help myself visualize this function, I built [a tool](https://httpserve.tenzhiyang.com/fourierSeriesVis/) that draws the wave using this exact formula, and map out one complete cycle. We can also keep adding coefficients to the `real` and `imag` arrays and see how it affects the wave. I also added an audio context to play said wave that is being displayed.

![screenshot of my fourier series visualizer tool](https://httpserve.tenzhiyang.com/fourierSeriesVis/periodicwave.png)

Now with this tool, we can approximate how an otamatone&apos;s waveform looks like from [this excellent audio analysis of the otamatone](http://www.windytan.com/2017/11/in-pursuit-of-otamas-tone.html) by [@windyoona](https://twitter.com/windyoona). Of course by approximate I really mean making a wave, looking at it and then saying &quot;ehh good enough&quot; and that&apos;s it.

![my good enough attempt](./goodenough.png)

So all I have left to do is to put the generated wave array into my otamatone and presto! We have something that plays and sounds like the actual instrument. I&apos;ve added a few quality of life features such as the ability to switch waves, and pitch correction (think of it like autotune). I call it the [otamaphone](https://httpserve.tenzhiyang.com/otamaphone)

![screenshot of otamaphone](./otamascreen.png)</content:raw></item><item><title><![CDATA[Wi is a good router so hard to Fi]]></title><description><![CDATA[In the past five years or so, I’ve been using the netgear orbi at my home. It gave us incredible speeds in a mesh network, but it costs…]]></description><link>https://blog.tenzhiyang.com/2019-10-12-wi-is-a-good-router-so-hard-to-fi/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2019-10-12-wi-is-a-good-router-so-hard-to-fi/</guid><pubDate>Sat, 12 Oct 2019 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;In the past five years or so, I’ve been using the netgear orbi at my home. It gave us incredible speeds in a mesh network, but it costs upwards of 600SGD for two units (one router and one satallite), and it just couldn’t provide the cover I needed, nor could it daisy chain. Every time there was a firmware update, I had to restore factory settings and set up everything all over again. Definitely not a great experience. When my setup started dropping wifi connections every day, I needed a replacement, with better bang for my buck.&lt;/p&gt;
&lt;p&gt;The solution seemed straight forward: research for a new consumer mesh setup, and buy one. I researched on many different brands and setups, and the one thing that came out consistently in all the reviews was: the orbi was the best product your money can buy (╯°□°）╯︵ ┻━┻&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.tomsguide.com/us/netgear-orbi,review-4263.html&quot;&gt;Every&lt;/a&gt; &lt;a href=&quot;https://www.lifewire.com/netgear-orbi-review-4589368&quot;&gt;one&lt;/a&gt; &lt;a href=&quot;https://www.expertreviews.co.uk/netgear/1405475/netgear-orbi-rbk50-review&quot;&gt;seemed&lt;/a&gt; &lt;a href=&quot;https://www.techspot.com/products/routers/netgear-rbk50-rbr50-orbi-ac3000-tri-band-wifi.153730/&quot;&gt;to&lt;/a&gt; &lt;a href=&quot;https://www.mbreviews.com/netgear-orbi-home-wifi-system-review/&quot;&gt;be&lt;/a&gt; &lt;a href=&quot;https://www.techradar.com/sg/reviews/netgear-orbi&quot;&gt;bought&lt;/a&gt; off by netgear and yes, I considered that I might have been the minority and received a faulty unit, but the &lt;a href=&quot;https://www.reddit.com/r/orbi/&quot;&gt;community seems to agree with me&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In the end I figured to just look for the cheapest mesh units money can buy. I found a chinese company called tenda, selling the m5 series with a set of &lt;a href=&quot;https://shopee.sg/Tenda-Nova-MW6-WiFi-Wireless-Router-and-Repeater-2.4G-5.0GHz-APP-Remote-Manage-i.41816358.2236310726&quot;&gt;3 units under 200SGD&lt;/a&gt; and read all the reviews for it. It seemed like it could output a maximum of 900Mbps which was sufficient for my needs, and there was little to no configurations for it. There’s only a max of 2 cat5 ports but that was sufficient for most of my house, and I could always buy a desktop switch for the living room. The reviews also promised a plug and play but warned of almost no configuration flexibility. At that time it was also on sale for about 150SGD for a set of 3, hell yea.&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 100%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAIBBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAe+nC2CgAf/EABgQAQADAQAAAAAAAAAAAAAAAAEAEBEg/9oACAEBAAEFArRmPP8A/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAwEBPwEf/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAgEBPwEf/8QAFBABAAAAAAAAAAAAAAAAAAAAMP/aAAgBAQAGPwIf/8QAGxAAAgEFAAAAAAAAAAAAAAAAABEBECAhMUH/2gAIAQEAAT8hrM0jJxENWf/aAAwDAQACAAMAAAAQ08AA/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAwEBPxAf/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAgEBPxAf/8QAGxABAQABBQAAAAAAAAAAAAAAAREAECAhQVH/2gAIAQEAAT8Q1oWHq4qOfTCIZs//2Q==) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/a4c6952dacc63ac092a696b1334b1e89/a80bd/tenda.jpg 148w,
/static/a4c6952dacc63ac092a696b1334b1e89/1c91a/tenda.jpg 295w,
/static/a4c6952dacc63ac092a696b1334b1e89/36dd4/tenda.jpg 512w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/a4c6952dacc63ac092a696b1334b1e89/36dd4/tenda.jpg&quot;
        srcset=&quot;/static/a4c6952dacc63ac092a696b1334b1e89/a80bd/tenda.jpg 148w,
/static/a4c6952dacc63ac092a696b1334b1e89/1c91a/tenda.jpg 295w,
/static/a4c6952dacc63ac092a696b1334b1e89/36dd4/tenda.jpg 512w&quot;
        title=&quot;the tenda m5&quot;
        alt=&quot;the tenda m5&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;p&gt;I bought it and a desktop switch (also tenda, because it’s cheap and just in case of compatibility issues), it arrived a week later. It did not work when connected with my modem. To be fair to tenda, connecting each mesh unit was as simple as starting up their proprietary app, and selecting each unit as they popped up on the screen. I found that I could get it to work if I connected my old router via lan to the tenda m5. This setup gave me about 600-900 Mbps but I had two different wifi endpoints, one working, one dying. &lt;/p&gt;
&lt;p&gt;This was good enough for me until my orbi started dropping lan too. Time to look for a gigabit router. This time, I wanted something that was tried and tested in Singapore. I looked through many different routers that promised gigabit speeds, but reading user reviews, it seemed like most cheap routers under a hundred had over inflated numbers. The WiFi could technically handle gigabit speed, but they were just using cheap rj45 connectors. WiFi was not my issue as I could continue to use the tenda m5 as my wifi access points.&lt;/p&gt;
&lt;p&gt;I then started to look into enterprise solutions. I figured if the machine did not have WiFi, at least the money I spent on would be for the hardware. In came the Edge Router X.&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 100%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGQABAAMBAQAAAAAAAAAAAAAAAAEEBQIG/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAAB1ua1E9CoDRgJB//EABwQAAIDAAMBAAAAAAAAAAAAAAIDAAEEEBESFP/aAAgBAQABBQI3rCDpUUq6uMydz5Gel5aAef/EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQMBAT8BH//EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQIBAT8BH//EAB0QAAIBBAMAAAAAAAAAAAAAAAARAQIgIZEiMnH/2gAIAQEABj8CzVo7L0wcZ2RCE7P/xAAbEAEAAwADAQAAAAAAAAAAAAABABEhIFFhQf/aAAgBAQABPyH7o9amNVdYgFoTyC1r8jQ57vJfDVbzh//aAAwDAQACAAMAAAAQ48cA/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAwEBPxAf/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAgEBPxAf/8QAHxABAAEEAQUAAAAAAAAAAAAAAREAITFBIFFhkbHR/9oACAEBAAE/EJIIe8pglWl97ULasKEqeOVdV2cnymaai4z2z03TOWBGAsEHjh//2Q==) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/fac4e61f2f1cf1273452414965df19f3/a80bd/erx.jpg 148w,
/static/fac4e61f2f1cf1273452414965df19f3/1c91a/erx.jpg 295w,
/static/fac4e61f2f1cf1273452414965df19f3/41099/erx.jpg 500w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/fac4e61f2f1cf1273452414965df19f3/41099/erx.jpg&quot;
        srcset=&quot;/static/fac4e61f2f1cf1273452414965df19f3/a80bd/erx.jpg 148w,
/static/fac4e61f2f1cf1273452414965df19f3/1c91a/erx.jpg 295w,
/static/fac4e61f2f1cf1273452414965df19f3/41099/erx.jpg 500w&quot;
        title=&quot;the edge router x&quot;
        alt=&quot;the edge router x&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;p&gt;At the comparatively low price of 85SGD, this little beast is rumored to be on the same level as gaming routers costing three times its price. It is essentially a network switch but with router software, and with hardware offloading introduced about 2 years ago in the firmware, it could handle gigabit speeds. Certain things were supposedly not accessible by the browser interface, but I felt I am fairly familiar with the Command Line at this point in my development career, what batter time than now to enter the world of enterprise routers? The only thing left was to see if it worked when paired with my modem.&lt;/p&gt;
&lt;p&gt;To my dismay, few people in Singapore used the edge router x, in favor of the edge router lite, which is a router built from the ground up. Do not be fooled by tha naming though, the lite is almost twice the price of the x, and could handle higher speeds than the ER-X out of the box. Shout out to &lt;a href=&quot;https://twitter.com/jacobtyq/status/1182166814861611009&quot;&gt;Jacob&lt;/a&gt; for letting me know his experience with the ER lite! However, I am a cheapskate. I bought the ER-X during shopee’s recent 10.10 sale.&lt;/p&gt;
&lt;p&gt;Like every other tech nerd, the first thing I did when using a new technology was to not read any documentation and use it. I connected my modem to the ER-X and connected my laptop to the ER-X, and typed in &lt;code class=&quot;language-text&quot;&gt;192.168.1.1&lt;/code&gt; into my browser. I was greeted by my good friend:&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 100%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsSAAALEgHS3X78AAAB8ElEQVQ4y72UTWsTURSGJ5OkfsQGFVsqVZAU2qKCiEgr1FaUIgHBZJLJZEige1eC4D8Q9/4FXfgf3AnZCN22uBBc6EYEXdXWD8bnDffCZXKDycaBh3Pn3HPfe879CoL/+UVRFLRarWEbW8iTj/nn54qN6S+4cZOK2kFnYQnOw0WoTi1GObasGgPfwh58hW+wCzVvBc1mc2TN2u22/ovGH+M/gvedTieL4zhL0zTjPzKCxZFsJOBZu9AI1iVETEb7O3yk7wDqXkFmHNputxskSRKqBPkYWLaCykqC9L2Bx3CZyvybYkvGnqTzkdqNRsNmdw3fQBliP/N/D9Zpnxi7KVbQCAwISkzwE/ih7LDiC7wkpuouiTfDfr9vBT8Q8AdeO2X+NKJau4c6QlbIm6GOBx0l036mHVSJtH/jF79YWwm+6/V6dkwJwhz+NcD3XBkRoExtloewNultWGbwXbgJt2EVUlPmJ3MGd1Qq/m3YgE3YglvaJLhj11bpH4cFBtyHVXa4jNgi7X24Ck/hgYm9oFiYh1n8N0BJnMPO2AxX4BKlLSI0g52DK/hemf5teGEuwCnjq8J1nd2Rg41DM1Wc/4rZqNOaVVcQewYx+ULdKuwx+dxHZGRTNMC9gpM+cc5V9TtdNGvuoQ18D+tUz9g031/5rxA6CRvmZAAAAABJRU5ErkJggg==) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/a4841ffc5664bdc74657d2bee6683b4e/12f09/chromerex.png 148w,
/static/a4841ffc5664bdc74657d2bee6683b4e/e4a3f/chromerex.png 295w,
/static/a4841ffc5664bdc74657d2bee6683b4e/5a46d/chromerex.png 300w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/a4841ffc5664bdc74657d2bee6683b4e/5a46d/chromerex.png&quot;
        srcset=&quot;/static/a4841ffc5664bdc74657d2bee6683b4e/12f09/chromerex.png 148w,
/static/a4841ffc5664bdc74657d2bee6683b4e/e4a3f/chromerex.png 295w,
/static/a4841ffc5664bdc74657d2bee6683b4e/5a46d/chromerex.png 300w&quot;
        title=&quot;chrome&apos;s no internet t rex game&quot;
        alt=&quot;chrome&apos;s no internet t rex game&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;p&gt;After actually reading some tutorials, I realized I had to connect my computer to eth0, set my laptop to request for a static IP (no default dhcp) and open the setup wizard (for noobs like me) to set up some basic configs. I applied all the default settings and changed the password of the default user. As part of the wizard and default settings, I had to disconnect my laptop from eth0 and connect to any other port, then connect my modem to eth0. I had some rx and tx going on the webgui, but I was not getting any internet. Dang. After some trial and error and about an hour of research, I found the solution to all things in tech support: turning everything off and on again. The key thing that made it work was restarting the modem, allowing my router to request a new IP from my ISP. Everything was working with minimal setup.&lt;/p&gt;
&lt;p&gt;The last thing I had to do was to enable hardware offloading. I do not know what hardware offloading does. I have read all the tutorials and all the explanations and like all tech documentations, they went over my head, but all I know is: turn on hardware offloading, you lose QoS but gain gigabit speed. (Note: Edgerouter lite doesn’t need to turn on hardware offloading to achieve gigabit speed) Activating these were simple enough: enter the CLI, log in, type &lt;code class=&quot;language-text&quot;&gt;command&lt;/code&gt; followed by &lt;code class=&quot;language-text&quot;&gt;set system offload hwnat enable&lt;/code&gt;, &lt;code class=&quot;language-text&quot;&gt;set system offload ipsec enable&lt;/code&gt; and &lt;code class=&quot;language-text&quot;&gt;commit ; save&lt;/code&gt;. Reboot the router and check from the cli with &lt;code class=&quot;language-text&quot;&gt;show ubnt offload&lt;/code&gt;. You can also do the same by fiddling with the GUI, but where’s the fun in that.&lt;/p&gt;
&lt;p&gt;Finally everything is up. Connecting my mesh routers to this router was seamless, as well as my smart tv and streaming boxes. Setting up port forwarding for my raspberry pi was as straight forward as any commercial router too. I haven’t really managed to get gigabit speeds, but it is also an internet peak hour as of writing this article, I will probably need to check again in the middle of the night, but I am optimistic about the results.&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 44.5945945945946%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAJABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAMBBAX/xAAVAQEBAAAAAAAAAAAAAAAAAAABAv/aAAwDAQACEAMQAAABhw2XKLJR/8QAHBAAAQMFAAAAAAAAAAAAAAAAAwABAhESMTIz/9oACAEBAAEFAhbHrKNpHQUTBOn/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAVEQEBAAAAAAAAAAAAAAAAAAAAEf/aAAgBAgEBPwFH/8QAGhABAQACAwAAAAAAAAAAAAAAAQARIUFxkf/aAAgBAQAGPwIjHFpfZnqb/8QAGhAAAgMBAQAAAAAAAAAAAAAAAREAITEgcf/aAAgBAQABPyEmAUPYxtom4GcFcQL/AP/aAAwDAQACAAMAAAAQXO//xAAWEQADAAAAAAAAAAAAAAAAAAABECH/2gAIAQMBAT8QNX//xAAVEQEBAAAAAAAAAAAAAAAAAAAQEf/aAAgBAgEBPxCj/8QAHRABAAICAgMAAAAAAAAAAAAAAQARITFxoVGx8f/aAAgBAQABPxARqJeFh8QVwSNo6+xhBFg0rHJNeBO9ncPRP//Z) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/f7e42143667e22fbd90711aba4fe3279/a80bd/raspierx.jpg 148w,
/static/f7e42143667e22fbd90711aba4fe3279/1c91a/raspierx.jpg 295w,
/static/f7e42143667e22fbd90711aba4fe3279/95118/raspierx.jpg 545w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/f7e42143667e22fbd90711aba4fe3279/95118/raspierx.jpg&quot;
        srcset=&quot;/static/f7e42143667e22fbd90711aba4fe3279/a80bd/raspierx.jpg 148w,
/static/f7e42143667e22fbd90711aba4fe3279/1c91a/raspierx.jpg 295w,
/static/f7e42143667e22fbd90711aba4fe3279/95118/raspierx.jpg 545w&quot;
        title=&quot;Raspberry pi, not much smaller than the edge router x next to it&quot;
        alt=&quot;Raspberry pi, not much smaller than the edge router x next to it&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;p&gt;All in all, ER-X is incredibly tiny for what it does and is comparatively cheap. Paired with the tenda m5, I have full coverage of my house, no unnecessary 2.4g or 5g noise from multiple routers and also reduce the clutter on my tv console. I cannot say that I am a network expert, but I think this setup is both affordable and performant. Having the flexibility to configure whatever the heck you want is a nice add on too. &lt;/p&gt;
&lt;p&gt;Special mention to &lt;a href=&quot;https://twitter.com/kenleesm&quot;&gt;Ken Lee&lt;/a&gt; and &lt;a href=&quot;https://twitter.com/jonathanlimsc&quot;&gt;Jonathan Lim&lt;/a&gt; who advised me on whether I really needed an enterprise grade router.&lt;/p&gt;
&lt;p&gt;Update on measurements taken during off peak timings:&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 70.94594594594594%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAABYlAAAWJQFJUiTwAAACZ0lEQVQ4y31TWU+aQRT9fqZ9MLW2sYnVJiLg1hdrpUAxtbaJGpcEIRiwYmMTRBMpYXmwgICyaeABBPOhljZABcNyOnMRMAR7kptvljvn3jlzPgFdUOdRr1NwlJ1uFNe0KFkPWmvNbyeEroScrFZrkNnsqDhciOkNyPY+x93ObiOH7XcjfZzwPrlgMNLXuvsdon4Tf5Qa1MrlR7sUupHUWHUebAEGrRZfFhawtr6O5dVVmI0myqlWq5TTKYHQrbuHCEcjsFgsFFarFelMBv87IzQ7qlQqFBxnZ2fweDyIx+PwHx8jkUggHAohweaBQID2/H4/YtFoq8tmCLV78R/i+voaqVQKZaYVJ42yg8lkEoVCgUhCp6dIp9MQRbG7hj6fD+8VCnzd2mpt8PHy0hKRcASDQcxpNDg5OaE5L8LH+Xwef4tFlEol6la4vMzgaW8vXUkqkeBgfx+bBgPezcwQ6eTEBNIXF3jW1we3y4VXg4NwOBwYk8lo7+PcHOV+mp9HhukrXF1d0TV4pYnxcdjtdshZcjabpU7G5HJ8UKuxxl6YY2lxEasrKyizjsSsiHAsjIA/QBKVbm/br2ze3saTnh5Y9/YgGRlBLpcja7ydnqZCJlPDLuvMPpyQQyyKSP1OgZmsreHPoyOYjA3z/rDZMDU5iTdTUzg/P6c16egodBsbUKtUNFcplfhm3qFxJB2B0+fETfmG/tdanWnIX+pFfz8+M/O+HBggW7jdbgwPDRG5XqcjO7weHoZidhYyqbT1UMVKEb/ucoyrbW66Mtfv8PCQdGgiFovB6/W25pyE69sk67Rb09z/AFAj5QU3V3VmAAAAAElFTkSuQmCC) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/ceecdae147aa5ba0d0b876e434dc15f0/12f09/fast.png 148w,
/static/ceecdae147aa5ba0d0b876e434dc15f0/e4a3f/fast.png 295w,
/static/ceecdae147aa5ba0d0b876e434dc15f0/fcda8/fast.png 590w,
/static/ceecdae147aa5ba0d0b876e434dc15f0/efc66/fast.png 885w,
/static/ceecdae147aa5ba0d0b876e434dc15f0/c83ae/fast.png 1180w,
/static/ceecdae147aa5ba0d0b876e434dc15f0/5df5d/fast.png 1572w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/ceecdae147aa5ba0d0b876e434dc15f0/fcda8/fast.png&quot;
        srcset=&quot;/static/ceecdae147aa5ba0d0b876e434dc15f0/12f09/fast.png 148w,
/static/ceecdae147aa5ba0d0b876e434dc15f0/e4a3f/fast.png 295w,
/static/ceecdae147aa5ba0d0b876e434dc15f0/fcda8/fast.png 590w,
/static/ceecdae147aa5ba0d0b876e434dc15f0/efc66/fast.png 885w,
/static/ceecdae147aa5ba0d0b876e434dc15f0/c83ae/fast.png 1180w,
/static/ceecdae147aa5ba0d0b876e434dc15f0/5df5d/fast.png 1572w&quot;
        title=&quot;300Mbps on wifi&quot;
        alt=&quot;300Mbps on wifi&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;p&gt;I am getting 300 Mbps on wifi while seated next to my first AP. Is this a stepdown from orbi’s max speed? yes. Is this still fast enough for me? yes.&lt;/p&gt;</content:encoded><content:raw>
In the past five years or so, I&apos;ve been using the netgear orbi at my home. It gave us incredible speeds in a mesh network, but it costs upwards of 600SGD for two units (one router and one satallite), and it just couldn&apos;t provide the cover I needed, nor could it daisy chain. Every time there was a firmware update, I had to restore factory settings and set up everything all over again. Definitely not a great experience. When my setup started dropping wifi connections every day, I needed a replacement, with better bang for my buck.

The solution seemed straight forward: research for a new consumer mesh setup, and buy one. I researched on many different brands and setups, and the one thing that came out consistently in all the reviews was: the orbi was the best product your money can buy (╯°□°）╯︵ ┻━┻

[Every](https://www.tomsguide.com/us/netgear-orbi,review-4263.html) [one](https://www.lifewire.com/netgear-orbi-review-4589368) [seemed](https://www.expertreviews.co.uk/netgear/1405475/netgear-orbi-rbk50-review) [to](https://www.techspot.com/products/routers/netgear-rbk50-rbr50-orbi-ac3000-tri-band-wifi.153730/) [be](https://www.mbreviews.com/netgear-orbi-home-wifi-system-review/) [bought](https://www.techradar.com/sg/reviews/netgear-orbi) off by netgear and yes, I considered that I might have been the minority and received a faulty unit, but the [community seems to agree with me](https://www.reddit.com/r/orbi/)

In the end I figured to just look for the cheapest mesh units money can buy. I found a chinese company called tenda, selling the m5 series with a set of [3 units under 200SGD](https://shopee.sg/Tenda-Nova-MW6-WiFi-Wireless-Router-and-Repeater-2.4G-5.0GHz-APP-Remote-Manage-i.41816358.2236310726) and read all the reviews for it. It seemed like it could output a maximum of 900Mbps which was sufficient for my needs, and there was little to no configurations for it. There&apos;s only a max of 2 cat5 ports but that was sufficient for most of my house, and I could always buy a desktop switch for the living room. The reviews also promised a plug and play but warned of almost no configuration flexibility. At that time it was also on sale for about 150SGD for a set of 3, hell yea.

![the tenda m5](./tenda.jpeg)

I bought it and a desktop switch (also tenda, because it&apos;s cheap and just in case of compatibility issues), it arrived a week later. It did not work when connected with my modem. To be fair to tenda, connecting each mesh unit was as simple as starting up their proprietary app, and selecting each unit as they popped up on the screen. I found that I could get it to work if I connected my old router via lan to the tenda m5. This setup gave me about 600-900 Mbps but I had two different wifi endpoints, one working, one dying. 

This was good enough for me until my orbi started dropping lan too. Time to look for a gigabit router. This time, I wanted something that was tried and tested in Singapore. I looked through many different routers that promised gigabit speeds, but reading user reviews, it seemed like most cheap routers under a hundred had over inflated numbers. The WiFi could technically handle gigabit speed, but they were just using cheap rj45 connectors. WiFi was not my issue as I could continue to use the tenda m5 as my wifi access points.

I then started to look into enterprise solutions. I figured if the machine did not have WiFi, at least the money I spent on would be for the hardware. In came the Edge Router X.

![the edge router x](./erx.jpeg)

At the comparatively low price of 85SGD, this little beast is rumored to be on the same level as gaming routers costing three times its price. It is essentially a network switch but with router software, and with hardware offloading introduced about 2 years ago in the firmware, it could handle gigabit speeds. Certain things were supposedly not accessible by the browser interface, but I felt I am fairly familiar with the Command Line at this point in my development career, what batter time than now to enter the world of enterprise routers? The only thing left was to see if it worked when paired with my modem.

To my dismay, few people in Singapore used the edge router x, in favor of the edge router lite, which is a router built from the ground up. Do not be fooled by tha naming though, the lite is almost twice the price of the x, and could handle higher speeds than the ER-X out of the box. Shout out to [Jacob](https://twitter.com/jacobtyq/status/1182166814861611009) for letting me know his experience with the ER lite! However, I am a cheapskate. I bought the ER-X during shopee&apos;s recent 10.10 sale.

Like every other tech nerd, the first thing I did when using a new technology was to not read any documentation and use it. I connected my modem to the ER-X and connected my laptop to the ER-X, and typed in `192.168.1.1` into my browser. I was greeted by my good friend:

![chrome&apos;s no internet t rex game](./chromerex.png)

After actually reading some tutorials, I realized I had to connect my computer to eth0, set my laptop to request for a static IP (no default dhcp) and open the setup wizard (for noobs like me) to set up some basic configs. I applied all the default settings and changed the password of the default user. As part of the wizard and default settings, I had to disconnect my laptop from eth0 and connect to any other port, then connect my modem to eth0. I had some rx and tx going on the webgui, but I was not getting any internet. Dang. After some trial and error and about an hour of research, I found the solution to all things in tech support: turning everything off and on again. The key thing that made it work was restarting the modem, allowing my router to request a new IP from my ISP. Everything was working with minimal setup.

The last thing I had to do was to enable hardware offloading. I do not know what hardware offloading does. I have read all the tutorials and all the explanations and like all tech documentations, they went over my head, but all I know is: turn on hardware offloading, you lose QoS but gain gigabit speed. (Note: Edgerouter lite doesn&apos;t need to turn on hardware offloading to achieve gigabit speed) Activating these were simple enough: enter the CLI, log in, type `command` followed by `set system offload hwnat enable`, `set system offload ipsec enable` and `commit ; save`. Reboot the router and check from the cli with `show ubnt offload`. You can also do the same by fiddling with the GUI, but where&apos;s the fun in that.

Finally everything is up. Connecting my mesh routers to this router was seamless, as well as my smart tv and streaming boxes. Setting up port forwarding for my raspberry pi was as straight forward as any commercial router too. I haven&apos;t really managed to get gigabit speeds, but it is also an internet peak hour as of writing this article, I will probably need to check again in the middle of the night, but I am optimistic about the results.

![Raspberry pi, not much smaller than the edge router x next to it](./raspierx.jpg)

All in all, ER-X is incredibly tiny for what it does and is comparatively cheap. Paired with the tenda m5, I have full coverage of my house, no unnecessary 2.4g or 5g noise from multiple routers and also reduce the clutter on my tv console. I cannot say that I am a network expert, but I think this setup is both affordable and performant. Having the flexibility to configure whatever the heck you want is a nice add on too. 

Special mention to [Ken Lee](https://twitter.com/kenleesm) and [Jonathan Lim](https://twitter.com/jonathanlimsc) who advised me on whether I really needed an enterprise grade router.

Update on measurements taken during off peak timings:

![300Mbps on wifi](./fast.png)

I am getting 300 Mbps on wifi while seated next to my first AP. Is this a stepdown from orbi&apos;s max speed? yes. Is this still fast enough for me? yes.</content:raw></item><item><title><![CDATA[AI for FE devs (Part 2)]]></title><description><![CDATA[Part 1 here This article is a complement to my presentation in React Knowledgable. Now that we know how to approach problems, we can look at…]]></description><link>https://blog.tenzhiyang.com/2019-08-01-ai-for-fe-2/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2019-08-01-ai-for-fe-2/</guid><pubDate>Thu, 01 Aug 2019 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;&lt;a href=&quot;https://blog.tenzhiyang.com/2019-07-31-ai-for-fe/&quot;&gt;Part 1 here&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;This article is a complement to my presentation in React Knowledgable.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Now that we know how to approach problems, we can look at what’s available. For this section I want to go through some big idea explanations of algorithms and what kind of input/output you can expect from and their implementation from the web. The goal here is that whenever you see a problem that you want to solve with AI, you have a rough idea what to Google, and how to transform your data to pass into these algorithms.&lt;/p&gt;
&lt;h2&gt;Fantastic algorithms and how to use them&lt;/h2&gt;
&lt;h3&gt;Markov Process (Markov Models)&lt;/h3&gt;
&lt;p&gt;Part 1 made use of a &lt;code class=&quot;language-text&quot;&gt;Markov Chain&lt;/code&gt;. The main idea for how Markov Processes work is that the future state is based on the current state and nothing more. We can define what is the “current” state like how we did with the text generation, where we defined the “current state” as the recent two words to predict the next word. Markov Models are great if you have lots of data with relatively few “states”. So how do we define what is a ‘state’? Basically the very thing that you want to be predicted from a Markov model. Since the English language has 171,476 unique words (according to a Google search), it is a relatively small number of states. This is why Markov models are used very often in text prediction, such as those in your android and iphone keyboards.&lt;/p&gt;
&lt;p&gt;Implementation details may vary, but the general idea is to take a series of &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;→&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;A \rightarrow B&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.68333em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;→&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.68333em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05017em;&quot;&gt;B&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; (A leads to B, or mathematically, A implies B) and passing it into a Markov Process. If you are dealing with something like a source text, where the states can be very long strings like &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;→&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo&gt;→&lt;/mo&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mo&gt;→&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;.&lt;/mi&gt;&lt;mo&gt;→&lt;/mo&gt;&lt;mi&gt;Z&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;A \rightarrow B \rightarrow C \rightarrow ... \rightarrow Z&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.68333em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;→&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.68333em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05017em;&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;→&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.68333em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.07153em;&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;→&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.36687em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;→&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.68333em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.07153em;&quot;&gt;Z&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;, you can just pass the whole data into some Markov chain library. Another example that isn’t text is something like weather prediction. If it has been raining today, it will be less likely to rain tomorrow. So you can just pass the weather over the past 10 years or so in the form of &lt;code class=&quot;language-text&quot;&gt;sunny, cloudy, rain, rain, sunny, ..., sunny&lt;/code&gt; into the Markov process. After the data transformation is done, given the current weather, you’ll get a prediction of what’s the next weather. &lt;/p&gt;
&lt;p&gt;As you might observe, real life is not so obvious that you can predict X given Y and get a correct prediction all the time. Hence Markov processes are very useful for problems that give you a list of what’s the probability of things happening after Y has happened, and a user makes an informed decision. Alternatively it can also be used for things where randomness is a bonus side effect, such as in the text generator, where I just chose a random word from the list of X predicted from Ys.&lt;/p&gt;
&lt;h3&gt;K Nearest Neighbours (KNN)&lt;/h3&gt;
&lt;p&gt;This algorithm is a very simple one. Going back to our 2-dimensional space of data, we plot all these points on the graph, and then we add a label to each one. There’s no calculations being done during the “training” time, it’s just plain data entry. So when we actually need to classify a new point, what we do is that we iterate through all the data, and then we find the K (some constant that you will input) nearest neighbors, using a simple straight-line (Euclidean) distance calculation. To use a KNN library, you should really only need to pass in the parameter and the label. Just note that some libraries do not accept negative parameter values.&lt;/p&gt;
&lt;p&gt;The great thing about KNN is that adding data really doesn’t cost anything at all, as there’s no computation. KNN scales linearly with large number of data, and large number of parameters, and this calculation is only done during the categorizing process.&lt;/p&gt;
&lt;h3&gt;Random Forest Classification&lt;/h3&gt;
&lt;p&gt;Random forests comes as a variant of &lt;code class=&quot;language-text&quot;&gt;decision trees&lt;/code&gt;. A decision tree is built using some source data set, split based on some rules based on the parameters. Each split that we make creates a “branch” with some probabilities on each branch. Eventually all branches have smaller branches until we form what looks like an upside down tree: &lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 100%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGAABAAMBAAAAAAAAAAAAAAAAAAECAwX/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAHuxQbAx1CQf//EABsQAAEEAwAAAAAAAAAAAAAAAAEAAhEhEDFB/9oACAEBAAEFAnaFFONzODa4v//EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQMBAT8BH//EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQIBAT8BH//EABcQAAMBAAAAAAAAAAAAAAAAAAAQEQL/2gAIAQEABj8CI6tP/8QAHBAAAQQDAQAAAAAAAAAAAAAAAQAQETEhQWHB/9oACAEBAAE/ISjpFIRbwqzbDBLmkANG/9oADAMBAAIAAwAAABBzyDz/xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/EB//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/EB//xAAeEAEAAgICAwEAAAAAAAAAAAABESEAMRBhUZGh0f/aAAgBAQABPxCmGFR73iSlIJ4OuJEOil9K/QxEEoIJ7v8AMGSTWWFSAQqKmcjBDITW+P/Z) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/d3e1067cf318eb8febb657cad57be757/a80bd/dectree.jpg 148w,
/static/d3e1067cf318eb8febb657cad57be757/1c91a/dectree.jpg 295w,
/static/d3e1067cf318eb8febb657cad57be757/1c72d/dectree.jpg 590w,
/static/d3e1067cf318eb8febb657cad57be757/4b190/dectree.jpg 800w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/d3e1067cf318eb8febb657cad57be757/1c72d/dectree.jpg&quot;
        srcset=&quot;/static/d3e1067cf318eb8febb657cad57be757/a80bd/dectree.jpg 148w,
/static/d3e1067cf318eb8febb657cad57be757/1c91a/dectree.jpg 295w,
/static/d3e1067cf318eb8febb657cad57be757/1c72d/dectree.jpg 590w,
/static/d3e1067cf318eb8febb657cad57be757/4b190/dectree.jpg 800w&quot;
        title=&quot;decision tree&quot;
        alt=&quot;decision tree&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;p&gt;A random forest is just the same process, but splitting the data into random subsets of parameters, and creating a separate tree for each of them, hence the term Random Forest Classification. The algorithm will then return a list of different classifications with some number from 0-1, this number is known as the &lt;code class=&quot;language-text&quot;&gt;confidence&lt;/code&gt; for the purpose of this blog post, you can think of confidence as exactly what it sounds like: how confident the algorithm is that this is the classification.&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 100%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAIBBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAe/ki0C8Cgf/xAAYEAACAwAAAAAAAAAAAAAAAAAAEAEhQf/aAAgBAQABBQJ6WoX/xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/AR//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/AR//xAAUEAEAAAAAAAAAAAAAAAAAAAAw/9oACAEBAAY/Ah//xAAbEAACAwADAAAAAAAAAAAAAAABEQAQIUFRsf/aAAgBAQABPyFxnXWyeeoAAxUHtf/aAAwDAQACAAMAAAAQI8gA/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAwEBPxAf/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAgEBPxAf/8QAHRABAAICAgMAAAAAAAAAAAAAAQARITFRYRBBcf/aAAgBAQABPxBo1t4gGhp9GoZ1Kb0Bk+QoMOD3CoKdrEEzAytuW3vx/9k=) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/6692c4276cc9790d3bf0b66d620f0c3b/a80bd/randomforest.jpg 148w,
/static/6692c4276cc9790d3bf0b66d620f0c3b/1c91a/randomforest.jpg 295w,
/static/6692c4276cc9790d3bf0b66d620f0c3b/1c72d/randomforest.jpg 590w,
/static/6692c4276cc9790d3bf0b66d620f0c3b/4b190/randomforest.jpg 800w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/6692c4276cc9790d3bf0b66d620f0c3b/1c72d/randomforest.jpg&quot;
        srcset=&quot;/static/6692c4276cc9790d3bf0b66d620f0c3b/a80bd/randomforest.jpg 148w,
/static/6692c4276cc9790d3bf0b66d620f0c3b/1c91a/randomforest.jpg 295w,
/static/6692c4276cc9790d3bf0b66d620f0c3b/1c72d/randomforest.jpg 590w,
/static/6692c4276cc9790d3bf0b66d620f0c3b/4b190/randomforest.jpg 800w&quot;
        title=&quot;random forest&quot;
        alt=&quot;random forest&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;p&gt;One great thing about Random Forest Classification is since you have a list of results of different confidences, if you have non-mutually exclusive groups to classify into (eg: it can be &lt;strong&gt;both&lt;/strong&gt; raining and sunny), you can choose to accept results above some level of confidence. Random Forest algorithms normally take in an array of parameters and an array of output. The parameters need not be the same length, but parameter order matters if you want fairly accurate (greater than 90 percent) results. The output order doesn’t matter for most implementations.&lt;/p&gt;
&lt;h3&gt;Neural Networks&lt;/h3&gt;
&lt;p&gt;The absolute coolest kid on the block, neural networks has already been explained in a previous talk, but the general idea is that we are trying to simulate how the brain works. Starting from a neuron, each neuron takes in a large number of inputs, multiply each input by some number (called weights, which define how important each input is), sums these inputs together, runs a type of mathematical function (called activation function) such that the result is between 0-1. The output of this neuron is then passed to another neuron, and so on and so forth. Each group of neurons that passes on to the next group of neurons is known as a “layer”. See how similar a NN neuron is to a brain neuron:&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 100%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAe7UNoJQA//EABYQAQEBAAAAAAAAAAAAAAAAACARIf/aAAgBAQABBQLRT//EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQMBAT8BH//EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQIBAT8BH//EABQQAQAAAAAAAAAAAAAAAAAAADD/2gAIAQEABj8CH//EABoQAAIDAQEAAAAAAAAAAAAAAAERABAhMUH/2gAIAQEAAT8hOsgfpolTnhpO/wD/2gAMAwEAAgADAAAAENDHPP/EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQMBAT8QH//EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQIBAT8QH//EAB0QAQACAgIDAAAAAAAAAAAAAAEAESExEEFRYYH/2gAIAQEAAT8QKvYD3uG6kjoDXFrS/J2dHiGohZzmUVVY4//Z) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/ac83c7e7d2ce969673ce8b48fb237ca1/a80bd/neuron.jpg 148w,
/static/ac83c7e7d2ce969673ce8b48fb237ca1/1c91a/neuron.jpg 295w,
/static/ac83c7e7d2ce969673ce8b48fb237ca1/1c72d/neuron.jpg 590w,
/static/ac83c7e7d2ce969673ce8b48fb237ca1/4b190/neuron.jpg 800w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/ac83c7e7d2ce969673ce8b48fb237ca1/1c72d/neuron.jpg&quot;
        srcset=&quot;/static/ac83c7e7d2ce969673ce8b48fb237ca1/a80bd/neuron.jpg 148w,
/static/ac83c7e7d2ce969673ce8b48fb237ca1/1c91a/neuron.jpg 295w,
/static/ac83c7e7d2ce969673ce8b48fb237ca1/1c72d/neuron.jpg 590w,
/static/ac83c7e7d2ce969673ce8b48fb237ca1/4b190/neuron.jpg 800w&quot;
        title=&quot;brain vs nn&quot;
        alt=&quot;brain vs nn&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;p&gt;The training algorithm will take in some input and pass it through the neural network, with all the weights randomized, and gets a prediction, which can be one or more numbers, depending on how many labels you want. It will then use the correct label and compare with the current label and tweak the weights such that the next time we pass the input, we are more likely to get a result closer to the correct label. We don’t alter the weights such that it definitely gives us the correct label because we do not want the neural network to only work on the training set, we want it to work in real life scenarios with ambiguous input that is similar but not exactly the same with the data set.&lt;/p&gt;
&lt;p&gt;I don’t recommend training your own neural network when you’re just beginning as you need a huge amount of data (at least 500 samples of each label) and creating a neural network is really more of an art than science. It takes experience and some intuition to really know how many layers and how big a layer you want for a neural network. However, there’s probably a pre-trained model that solves your problem, and using it should be easy enough, just that every model has different requirements. You’ll need to read their respective documentation to use them.&lt;/p&gt;
&lt;h3&gt;Convolutional Neural Networks&lt;/h3&gt;
&lt;p&gt;The idea of Convolutional Neural Networks is simple in implementation but not very intuitive to understand. Basically for an image, each pixel is a parameter (or rather, 3 or 4, with Red Green Blue and transparency values). You can &lt;strong&gt;technically&lt;/strong&gt; pass in the entire image into a Neural network, but it usually doesn’t work out well, as a normal neural network does not understand the relations between pixels. Another problem is that having each pixel as a parameter is too large an input and would take forever to train.&lt;/p&gt;
&lt;p&gt;This is where the convolutional layer and pooling layer comes in. Basically the convolutional layer applies a filter, which transforms &lt;code class=&quot;language-text&quot;&gt;n * n&lt;/code&gt;pixels (a square) into 1, using some matrix manipulation mathemagic. The pooling layer comes immediately after the convolutional layer, and its job is to reduce the input space further, by taking the max or the average value in &lt;code class=&quot;language-text&quot;&gt;n * n&lt;/code&gt; pixels. These are called &lt;code class=&quot;language-text&quot;&gt;Max Pooling&lt;/code&gt; and &lt;code class=&quot;language-text&quot;&gt;Average Pooling&lt;/code&gt;. Max pooling by nature tends to reduce noise in the data while Average pooling is a simple &lt;code class=&quot;language-text&quot;&gt;dimension reduction&lt;/code&gt; (reducing the input size by &lt;code class=&quot;language-text&quot;&gt;x&lt;/code&gt; dimensions). The two layers together will be inserted in between some layers of a neural network. It is possible to have more than one such convolution+pooling layer, but that increases computation time.&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 100%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGQABAAIDAAAAAAAAAAAAAAAAAAECAwQF/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAH/2gAMAwEAAhADEAAAAe8pijaQpULg/8QAGRABAAIDAAAAAAAAAAAAAAAAAQAQAiEx/9oACAEBAAEFAoNZcNNBX//EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQMBAT8BH//EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQIBAT8BH//EABQQAQAAAAAAAAAAAAAAAAAAADD/2gAIAQEABj8CH//EABkQAQADAQEAAAAAAAAAAAAAAAEAEBFRIf/aAAgBAQABPyFXOM0K94ZvoWBtf//aAAwDAQACAAMAAAAQNM8A/8QAFREBAQAAAAAAAAAAAAAAAAAAICH/2gAIAQMBAT8Qg//EABYRAQEBAAAAAAAAAAAAAAAAABEBIP/aAAgBAgEBPxBqY//EABsQAQACAwEBAAAAAAAAAAAAAAERMQAQQSFR/9oACAEBAAE/EJGD4LWEUovdG096ZGWlGkEhJMdRc91//9k=) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/073155acbd5405378a4882395a963ac7/a80bd/cnn.jpg 148w,
/static/073155acbd5405378a4882395a963ac7/1c91a/cnn.jpg 295w,
/static/073155acbd5405378a4882395a963ac7/1c72d/cnn.jpg 590w,
/static/073155acbd5405378a4882395a963ac7/4b190/cnn.jpg 800w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/073155acbd5405378a4882395a963ac7/1c72d/cnn.jpg&quot;
        srcset=&quot;/static/073155acbd5405378a4882395a963ac7/a80bd/cnn.jpg 148w,
/static/073155acbd5405378a4882395a963ac7/1c91a/cnn.jpg 295w,
/static/073155acbd5405378a4882395a963ac7/1c72d/cnn.jpg 590w,
/static/073155acbd5405378a4882395a963ac7/4b190/cnn.jpg 800w&quot;
        title=&quot;convolution and pooling layer&quot;
        alt=&quot;convolution and pooling layer&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;p&gt;There are plenty of pre-trained convolutional neural networks that recognizes objects, animals, drawings or even individual hand written characters, so if you just need to identify what is inside an image, you can leverage on the existing neural nets to classify what you need. For example, during the most recent hackathon I wanted to know if the user has drawn a circle, square or diamond, my team used Google Quickdraw’s net to identify what it was and re-draw a perfect circle square or diamond in its place. I did some additional neural net on top of that, which causes the lag, but you can try it &lt;a href=&quot;https://hackathon.flowdi.tenzhiyang.com/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Recurrent Neural network&lt;/h3&gt;
&lt;p&gt;As you might notice from the Neural networks and CNN sections, the way we simulate the human brain may be a bit simplified, and RNN aims to improve on one aspect. Recurrent Neural Networks aim to add a “short term memory” by making each neuron pass its output back to itself, for the next computation. This allows information to persist inside the network where the previously input data will affect the next few predictions. There is a commonly used variant of RNN called Long Short-Term Memory (&lt;code class=&quot;language-text&quot;&gt;LTSM&lt;/code&gt;) network which works differently but produces better results.&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 100%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAe/Lk2CAoP/EABcQAQADAAAAAAAAAAAAAAAAAAEAECD/2gAIAQEAAQUChZn/xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/AR//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/AR//xAAUEAEAAAAAAAAAAAAAAAAAAAAw/9oACAEBAAY/Ah//xAAZEAADAAMAAAAAAAAAAAAAAAABEBEAICH/2gAIAQEAAT8hyu1EXSBF/9oADAMBAAIAAwAAABDQCAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/EB//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/EB//xAAbEAEAAgMBAQAAAAAAAAAAAAABEBEAMUEhUf/aAAgBAQABPxDOh3yDJfGzBQm6d/ZDQj//2Q==) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/eccf8bf44a10fd21843ce203fd146772/a80bd/recc.jpg 148w,
/static/eccf8bf44a10fd21843ce203fd146772/1c91a/recc.jpg 295w,
/static/eccf8bf44a10fd21843ce203fd146772/1c72d/recc.jpg 590w,
/static/eccf8bf44a10fd21843ce203fd146772/4b190/recc.jpg 800w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/eccf8bf44a10fd21843ce203fd146772/1c72d/recc.jpg&quot;
        srcset=&quot;/static/eccf8bf44a10fd21843ce203fd146772/a80bd/recc.jpg 148w,
/static/eccf8bf44a10fd21843ce203fd146772/1c91a/recc.jpg 295w,
/static/eccf8bf44a10fd21843ce203fd146772/1c72d/recc.jpg 590w,
/static/eccf8bf44a10fd21843ce203fd146772/4b190/recc.jpg 800w&quot;
        title=&quot;Recurrent Neural Network&quot;
        alt=&quot;Recurrent Neural Network&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;p&gt;The nature of having some form of short term memory makes RNN especially useful for things like speech recognition, language modeling, image captioning or even some time-based data (known as &lt;code class=&quot;language-text&quot;&gt;time-series&lt;/code&gt;) such as stock price of a company. I haven’t really used RNN yet, but it’s good to know what its capable of.&lt;/p&gt;
&lt;h3&gt;Transfer Learning&lt;/h3&gt;
&lt;p&gt;Earlier I mentioned about not training your own neural network because it (probably) already exists, but here’s something we can do to make a neural network solve more domain specific problems. Transfer learning is basically using an existing neural net, and training the top (few) layers of the neural net, so that you retain the pattern-recognition capabilities of your neural network, but optimised to your specific problem. There are plenty of tutorials and methods differ between various libraries, so I won’t go into the details of its implementation.&lt;/p&gt;
&lt;p&gt;However, one interesting take on transfer learning was something I learnt from the &lt;a href=&quot;https://www.tensorflow.org/js/tutorials/transfer/image_classification&quot;&gt;tensorflowjs transfer learning tutorial&lt;/a&gt;. Essentially what this method does is that it takes a representation (they call it an &lt;code class=&quot;language-text&quot;&gt;activation&lt;/code&gt;) of the neural network, and uses it as the parameter of a K-Nearest Neighbour. I asked some data scientist friends of mine and they have confirmed that this is not really a traditional implementation of transfer learning, although it’s a fascinating idea.&lt;/p&gt;
&lt;p&gt;The idea behind this concept is perhaps best explained in an example. &lt;a href=&quot;https://httpserve.tenzhiyang.com/imageRecognition/&quot;&gt;This Project&lt;/a&gt; uses image net, which is trained to recognize object from images. Even if the net is not trained to recognize something, for example which direction my head is facing, when the image changes drastically, there are some neurons in the network that will have a high value and some neurons that won’t change at all. Therefore knowing which are the “triggered” and “non-triggered” neurons as parameters, we are able to categorize new objects using KNN, using a model that learnt from another data set.&lt;/p&gt;
&lt;h2&gt;Example Projects&lt;/h2&gt;
&lt;p&gt;Here are a few projects that I’ve been doing in the past couple of weeks, where each project takes about a couple of hours to build, I do try to add something on top of just consuming the API, so that you can catch a glimpse of how I make use of existing tools to do something else instead of following tutorials or documentation to solve a problem that someone has already solved before.&lt;/p&gt;
&lt;p&gt;All of these projects are running entirely on the front end, they are all static sites served off a simple HTTP server.&lt;/p&gt;
&lt;h3&gt;&lt;a href=&quot;https://httpserve.tenzhiyang.com/gumshoos/&quot;&gt;Gumshoos&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Time taken: 45 mins, of which maybe 30 was looking for a super simple no frills implementation of markov chains.&lt;/li&gt;
&lt;li&gt;Libraries: &lt;code class=&quot;language-text&quot;&gt;nlp_compromise&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a href=&quot;https://httpserve.tenzhiyang.com/imageRecognition/&quot;&gt;Image Recognition&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Time taken: 1.5 hours, half of the time spent following the google codelab tutorial&lt;/li&gt;
&lt;li&gt;Libraries/models: &lt;code class=&quot;language-text&quot;&gt;tensorflowjs&lt;/code&gt; &lt;code class=&quot;language-text&quot;&gt;mobilenet&lt;/code&gt; &lt;code class=&quot;language-text&quot;&gt;knn-classifier&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a href=&quot;https://httpserve.tenzhiyang.com/greenScreen/&quot;&gt;Green Screen&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Time taken: 1.5 hours&lt;/li&gt;
&lt;li&gt;Libraries/models: &lt;code class=&quot;language-text&quot;&gt;tensorflowjs&lt;/code&gt; &lt;code class=&quot;language-text&quot;&gt;body-pix&lt;/code&gt; &lt;code class=&quot;language-text&quot;&gt;jscolor&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Body-pix is a model that is used for segmenting body parts in an image. I made use of a function &lt;code class=&quot;language-text&quot;&gt;toMaskImageData&lt;/code&gt; which basically gives me a “silhouette” of a person in the image. I use a few composite methods available from the canvas context api (webcam input, overlay silhouette with &lt;code class=&quot;language-text&quot;&gt;destination-in&lt;/code&gt;) to remove the background. Then green screen in the background is really just setting a background color. Theoretically we can overlay the green screen effect over anything, as long as they’re both in the same webpage.&lt;/p&gt;
&lt;h3&gt;&lt;a href=&quot;https://httpserve.tenzhiyang.com/mocap/&quot;&gt;Mocap&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Time taken: 1 hour&lt;/li&gt;
&lt;li&gt;Libraries/models: &lt;code class=&quot;language-text&quot;&gt;tensorflowjs&lt;/code&gt; &lt;code class=&quot;language-text&quot;&gt;posenet&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I really didn’t do anything for this. Passing in the webcam-feed into &lt;code class=&quot;language-text&quot;&gt;posenet&lt;/code&gt;, I receive a list of body parts followed by their x and y coordinates and a confidence score. Next, I drew red squares where each body part was. I can go a step further to remove those body parts with low confidence, but that’s just from analyzing the input and output and using some constant value that works well enough.&lt;/p&gt;
&lt;h3&gt;&lt;a href=&quot;https://httpserve.tenzhiyang.com/jojoPose/&quot;&gt;Jojo’s Bizarre Poses&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Time taken: 1 hour (excluding the time required to build mocap)&lt;/li&gt;
&lt;li&gt;Libraries/models: &lt;code class=&quot;language-text&quot;&gt;tensorflowjs&lt;/code&gt; &lt;code class=&quot;language-text&quot;&gt;posenet&lt;/code&gt; &lt;code class=&quot;language-text&quot;&gt;knn-classifier&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is like a combination of &lt;code class=&quot;language-text&quot;&gt;mocap&lt;/code&gt; and &lt;code class=&quot;language-text&quot;&gt;image recognition&lt;/code&gt; projects above, but since the KNN classifier I used was from the tensorflow libraries, it takes in a certain data type &lt;code class=&quot;language-text&quot;&gt;tensors&lt;/code&gt; as input. I had to modify the data to fit the KNN classifier.&lt;/p&gt;
&lt;h2&gt;Some useful tools&lt;/h2&gt;
&lt;p&gt;What I went through in the past two blog posts cannot possibly cover all the use cases you might want to work on, so I’ve decided to compile a list of useful libraries and data sets that you can use in your own personal projects.&lt;/p&gt;
&lt;h3&gt;Some famous Datasets&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Brown Corpus&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Known formally as the &lt;strong&gt;Brown University Standard Corpus of Present-Day American English&lt;/strong&gt; this data set contains about 500 samples of English-language text and is used frequently in NLP projects.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Quick draw&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Remember &lt;a href=&quot;https://quickdraw.withgoogle.com/?locale=en_US&quot;&gt;this game&lt;/a&gt;? It was a data collection exercise, and they’ve open sourced all the drawings together with the draw order!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ImageNet&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A database of pictures that are labeled by crowd-sourcing, this data set contains more than 20,000 categories, with bounding boxes to highlight the objects being labeled.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MS-COCO&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Common Objects in Context&lt;/strong&gt;, this is a data set of common objects are taken from every day scenes. Instead of bounding boxes like in ImageNet, they have object segmentation, just like my green-screen example, but for objects.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MNIST&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;MNIST database (&lt;strong&gt;Modified National Institute of Standards and Technology&lt;/strong&gt; database) is a database of handwritten digits and is used very frequently to practice creating handwritten character recognition algorithms.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Free Spoken Digit&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is the MNIST of Speech recognition basically.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Free Music Archive&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Just an archive of royalty free music!&lt;/p&gt;
&lt;h3&gt;Some famous Libraries&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;ML.js&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The scikit AI tool set, now replicated in js, has lots of learning algorithms and some useful data transforming utilities.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;compromise&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A fast NLP library which helps format text. Uses some outdated techniques in favour of speed over accuracy, aims to solve 90% of use-cases.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tensorflowjs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A re-write of the famous tensorflow in js. There’s quite an established community supporting and I can find very good models written for or compatible with Tensorflowjs&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Kerasjs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A fairly popular neural network library, the models produced by Keras can be imported into Tensorflowjs also.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ML5&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Another Nerual Network library. It is actually a high-level interface for Tensorflowjs. I’ve heard that ML 5 has more beginner friendly jargon and documentation, but I don’t have experience with it yet.&lt;/p&gt;</content:encoded><content:raw>
## [Part 1 here](https://blog.tenzhiyang.com/2019-07-31-ai-for-fe/)

**This article is a complement to my presentation in React Knowledgable.**

Now that we know how to approach problems, we can look at what&apos;s available. For this section I want to go through some big idea explanations of algorithms and what kind of input/output you can expect from and their implementation from the web. The goal here is that whenever you see a problem that you want to solve with AI, you have a rough idea what to Google, and how to transform your data to pass into these algorithms.

## Fantastic algorithms and how to use them

### Markov Process (Markov Models)

Part 1 made use of a `Markov Chain`. The main idea for how Markov Processes work is that the future state is based on the current state and nothing more. We can define what is the &quot;current&quot; state like how we did with the text generation, where we defined the &quot;current state&quot; as the recent two words to predict the next word. Markov Models are great if you have lots of data with relatively few &quot;states&quot;. So how do we define what is a &apos;state&apos;? Basically the very thing that you want to be predicted from a Markov model. Since the English language has 171,476 unique words (according to a Google search), it is a relatively small number of states. This is why Markov models are used very often in text prediction, such as those in your android and iphone keyboards.

Implementation details may vary, but the general idea is to take a series of $A \rightarrow B$ (A leads to B, or mathematically, A implies B) and passing it into a Markov Process. If you are dealing with something like a source text, where the states can be very long strings like $A \rightarrow B \rightarrow C \rightarrow ... \rightarrow Z$, you can just pass the whole data into some Markov chain library. Another example that isn&apos;t text is something like weather prediction. If it has been raining today, it will be less likely to rain tomorrow. So you can just pass the weather over the past 10 years or so in the form of `sunny, cloudy, rain, rain, sunny, ..., sunny` into the Markov process. After the data transformation is done, given the current weather, you&apos;ll get a prediction of what&apos;s the next weather. 

As you might observe, real life is not so obvious that you can predict X given Y and get a correct prediction all the time. Hence Markov processes are very useful for problems that give you a list of what&apos;s the probability of things happening after Y has happened, and a user makes an informed decision. Alternatively it can also be used for things where randomness is a bonus side effect, such as in the text generator, where I just chose a random word from the list of X predicted from Ys.

### K Nearest Neighbours (KNN)

This algorithm is a very simple one. Going back to our 2-dimensional space of data, we plot all these points on the graph, and then we add a label to each one. There&apos;s no calculations being done during the &quot;training&quot; time, it&apos;s just plain data entry. So when we actually need to classify a new point, what we do is that we iterate through all the data, and then we find the K (some constant that you will input) nearest neighbors, using a simple straight-line (Euclidean) distance calculation. To use a KNN library, you should really only need to pass in the parameter and the label. Just note that some libraries do not accept negative parameter values.

The great thing about KNN is that adding data really doesn&apos;t cost anything at all, as there&apos;s no computation. KNN scales linearly with large number of data, and large number of parameters, and this calculation is only done during the categorizing process.

### Random Forest Classification

Random forests comes as a variant of `decision trees`. A decision tree is built using some source data set, split based on some rules based on the parameters. Each split that we make creates a &quot;branch&quot; with some probabilities on each branch. Eventually all branches have smaller branches until we form what looks like an upside down tree: 

![decision tree](./dectree.jpg)

A random forest is just the same process, but splitting the data into random subsets of parameters, and creating a separate tree for each of them, hence the term Random Forest Classification. The algorithm will then return a list of different classifications with some number from 0-1, this number is known as the `confidence` for the purpose of this blog post, you can think of confidence as exactly what it sounds like: how confident the algorithm is that this is the classification.

![random forest](./randomforest.jpg)

One great thing about Random Forest Classification is since you have a list of results of different confidences, if you have non-mutually exclusive groups to classify into (eg: it can be **both** raining and sunny), you can choose to accept results above some level of confidence. Random Forest algorithms normally take in an array of parameters and an array of output. The parameters need not be the same length, but parameter order matters if you want fairly accurate (greater than 90 percent) results. The output order doesn&apos;t matter for most implementations.

### Neural Networks

The absolute coolest kid on the block, neural networks has already been explained in a previous talk, but the general idea is that we are trying to simulate how the brain works. Starting from a neuron, each neuron takes in a large number of inputs, multiply each input by some number (called weights, which define how important each input is), sums these inputs together, runs a type of mathematical function (called activation function) such that the result is between 0-1. The output of this neuron is then passed to another neuron, and so on and so forth. Each group of neurons that passes on to the next group of neurons is known as a &quot;layer&quot;. See how similar a NN neuron is to a brain neuron:

![brain vs nn](./neuron.jpg)

The training algorithm will take in some input and pass it through the neural network, with all the weights randomized, and gets a prediction, which can be one or more numbers, depending on how many labels you want. It will then use the correct label and compare with the current label and tweak the weights such that the next time we pass the input, we are more likely to get a result closer to the correct label. We don&apos;t alter the weights such that it definitely gives us the correct label because we do not want the neural network to only work on the training set, we want it to work in real life scenarios with ambiguous input that is similar but not exactly the same with the data set.

I don&apos;t recommend training your own neural network when you&apos;re just beginning as you need a huge amount of data (at least 500 samples of each label) and creating a neural network is really more of an art than science. It takes experience and some intuition to really know how many layers and how big a layer you want for a neural network. However, there&apos;s probably a pre-trained model that solves your problem, and using it should be easy enough, just that every model has different requirements. You&apos;ll need to read their respective documentation to use them.

### Convolutional Neural Networks

The idea of Convolutional Neural Networks is simple in implementation but not very intuitive to understand. Basically for an image, each pixel is a parameter (or rather, 3 or 4, with Red Green Blue and transparency values). You can **technically** pass in the entire image into a Neural network, but it usually doesn&apos;t work out well, as a normal neural network does not understand the relations between pixels. Another problem is that having each pixel as a parameter is too large an input and would take forever to train.

This is where the convolutional layer and pooling layer comes in. Basically the convolutional layer applies a filter, which transforms `n * n`pixels (a square) into 1, using some matrix manipulation mathemagic. The pooling layer comes immediately after the convolutional layer, and its job is to reduce the input space further, by taking the max or the average value in `n * n` pixels. These are called `Max Pooling` and `Average Pooling`. Max pooling by nature tends to reduce noise in the data while Average pooling is a simple `dimension reduction` (reducing the input size by `x` dimensions). The two layers together will be inserted in between some layers of a neural network. It is possible to have more than one such convolution+pooling layer, but that increases computation time.

![convolution and pooling layer](./cnn.jpg)

There are plenty of pre-trained convolutional neural networks that recognizes objects, animals, drawings or even individual hand written characters, so if you just need to identify what is inside an image, you can leverage on the existing neural nets to classify what you need. For example, during the most recent hackathon I wanted to know if the user has drawn a circle, square or diamond, my team used Google Quickdraw&apos;s net to identify what it was and re-draw a perfect circle square or diamond in its place. I did some additional neural net on top of that, which causes the lag, but you can try it [here](https://hackathon.flowdi.tenzhiyang.com/).

### Recurrent Neural network

As you might notice from the Neural networks and CNN sections, the way we simulate the human brain may be a bit simplified, and RNN aims to improve on one aspect. Recurrent Neural Networks aim to add a &quot;short term memory&quot; by making each neuron pass its output back to itself, for the next computation. This allows information to persist inside the network where the previously input data will affect the next few predictions. There is a commonly used variant of RNN called Long Short-Term Memory (`LTSM`) network which works differently but produces better results.

![Recurrent Neural Network](./recc.jpg)

The nature of having some form of short term memory makes RNN especially useful for things like speech recognition, language modeling, image captioning or even some time-based data (known as `time-series`) such as stock price of a company. I haven&apos;t really used RNN yet, but it&apos;s good to know what its capable of.

### Transfer Learning

Earlier I mentioned about not training your own neural network because it (probably) already exists, but here&apos;s something we can do to make a neural network solve more domain specific problems. Transfer learning is basically using an existing neural net, and training the top (few) layers of the neural net, so that you retain the pattern-recognition capabilities of your neural network, but optimised to your specific problem. There are plenty of tutorials and methods differ between various libraries, so I won&apos;t go into the details of its implementation.

However, one interesting take on transfer learning was something I learnt from the [tensorflowjs transfer learning tutorial](https://www.tensorflow.org/js/tutorials/transfer/image_classification). Essentially what this method does is that it takes a representation (they call it an `activation`) of the neural network, and uses it as the parameter of a K-Nearest Neighbour. I asked some data scientist friends of mine and they have confirmed that this is not really a traditional implementation of transfer learning, although it&apos;s a fascinating idea.

The idea behind this concept is perhaps best explained in an example. [This Project](https://httpserve.tenzhiyang.com/imageRecognition/) uses image net, which is trained to recognize object from images. Even if the net is not trained to recognize something, for example which direction my head is facing, when the image changes drastically, there are some neurons in the network that will have a high value and some neurons that won&apos;t change at all. Therefore knowing which are the &quot;triggered&quot; and &quot;non-triggered&quot; neurons as parameters, we are able to categorize new objects using KNN, using a model that learnt from another data set.

## Example Projects

Here are a few projects that I&apos;ve been doing in the past couple of weeks, where each project takes about a couple of hours to build, I do try to add something on top of just consuming the API, so that you can catch a glimpse of how I make use of existing tools to do something else instead of following tutorials or documentation to solve a problem that someone has already solved before.

All of these projects are running entirely on the front end, they are all static sites served off a simple HTTP server.

### [Gumshoos](https://httpserve.tenzhiyang.com/gumshoos/)
- Time taken: 45 mins, of which maybe 30 was looking for a super simple no frills implementation of markov chains.
- Libraries: `nlp_compromise`

### [Image Recognition](https://httpserve.tenzhiyang.com/imageRecognition/)
- Time taken: 1.5 hours, half of the time spent following the google codelab tutorial
- Libraries/models: `tensorflowjs` `mobilenet` `knn-classifier`

### [Green Screen](https://httpserve.tenzhiyang.com/greenScreen/)
- Time taken: 1.5 hours
- Libraries/models: `tensorflowjs` `body-pix` `jscolor`

Body-pix is a model that is used for segmenting body parts in an image. I made use of a function `toMaskImageData` which basically gives me a &quot;silhouette&quot; of a person in the image. I use a few composite methods available from the canvas context api (webcam input, overlay silhouette with `destination-in`) to remove the background. Then green screen in the background is really just setting a background color. Theoretically we can overlay the green screen effect over anything, as long as they&apos;re both in the same webpage.

### [Mocap](https://httpserve.tenzhiyang.com/mocap/)
- Time taken: 1 hour
- Libraries/models: `tensorflowjs` `posenet`

I really didn&apos;t do anything for this. Passing in the webcam-feed into `posenet`, I receive a list of body parts followed by their x and y coordinates and a confidence score. Next, I drew red squares where each body part was. I can go a step further to remove those body parts with low confidence, but that&apos;s just from analyzing the input and output and using some constant value that works well enough.

### [Jojo&apos;s Bizarre Poses](https://httpserve.tenzhiyang.com/jojoPose/)
- Time taken: 1 hour (excluding the time required to build mocap)
- Libraries/models: `tensorflowjs` `posenet` `knn-classifier`

This is like a combination of `mocap` and `image recognition` projects above, but since the KNN classifier I used was from the tensorflow libraries, it takes in a certain data type `tensors` as input. I had to modify the data to fit the KNN classifier.

## Some useful tools

What I went through in the past two blog posts cannot possibly cover all the use cases you might want to work on, so I&apos;ve decided to compile a list of useful libraries and data sets that you can use in your own personal projects.

### Some famous Datasets

- Brown Corpus

Known formally as the **Brown University Standard Corpus of Present-Day American English** this data set contains about 500 samples of English-language text and is used frequently in NLP projects.

- Quick draw

Remember [this game](https://quickdraw.withgoogle.com/?locale=en_US)? It was a data collection exercise, and they&apos;ve open sourced all the drawings together with the draw order!

- ImageNet

A database of pictures that are labeled by crowd-sourcing, this data set contains more than 20,000 categories, with bounding boxes to highlight the objects being labeled.

- MS-COCO

**Common Objects in Context**, this is a data set of common objects are taken from every day scenes. Instead of bounding boxes like in ImageNet, they have object segmentation, just like my green-screen example, but for objects.

- MNIST

MNIST database (**Modified National Institute of Standards and Technology** database) is a database of handwritten digits and is used very frequently to practice creating handwritten character recognition algorithms.

- Free Spoken Digit

This is the MNIST of Speech recognition basically.

- Free Music Archive

Just an archive of royalty free music!

### Some famous Libraries

- ML.js

The scikit AI tool set, now replicated in js, has lots of learning algorithms and some useful data transforming utilities.

- compromise

A fast NLP library which helps format text. Uses some outdated techniques in favour of speed over accuracy, aims to solve 90% of use-cases.

- Tensorflowjs

A re-write of the famous tensorflow in js. There&apos;s quite an established community supporting and I can find very good models written for or compatible with Tensorflowjs

- Kerasjs

A fairly popular neural network library, the models produced by Keras can be imported into Tensorflowjs also.

- ML5

Another Nerual Network library. It is actually a high-level interface for Tensorflowjs. I&apos;ve heard that ML 5 has more beginner friendly jargon and documentation, but I don&apos;t have experience with it yet.
</content:raw></item><item><title><![CDATA[AI for FE devs (Part 1)]]></title><description><![CDATA[This article is a complement to my presentation in React Knowledgable. Introduction Artificial Intelligence is all the rage now, with the…]]></description><link>https://blog.tenzhiyang.com/2019-07-31-ai-for-fe/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2019-07-31-ai-for-fe/</guid><pubDate>Wed, 31 Jul 2019 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;&lt;strong&gt;This article is a complement to my presentation in React Knowledgable.&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Artificial Intelligence is all the rage now, with the craze starting from Deepmind’s alpha go. Although I hate people for misusing the terms “artificial intelligence” and “machine learning” for things that do not need AI and ML to solve, I do think that using AI reduces the time taken to solve certain problems, and also can add some “WoW factor” to an idea. I hope with this article (and subsequent presentations) people will understand what kind of problems that AI can solve, and maybe make AI more approachable so that the overall quality of hackathon projects improve.&lt;/p&gt;
&lt;p&gt;First off, a disclaimer: &lt;strong&gt;I am by no means an expert in AI. I do have an undergrad level understanding of artificial intelligence, but I was never great at it.&lt;/strong&gt; Feel free to correct me on any wrong concepts that I write in this article. I will also try to explain AI in English and not technobable, so for the real AI masters out there, you might cringe at me using wrong analogies or even butchering terminologies in an attempt to make AI easier to understand.&lt;/p&gt;
&lt;p&gt;My motivation for this article stems from two comments that irks me. These (paraphrased) comments come from people who I think are smarter and better engineers than me. We are all front end engineers, and I can understand why they said it, but all these were in the context of Hackathons, and I feel that it’s a shame for people to be limited in implementation just because AI seems so daunting.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;You can use my idea because I don’t know how to build it&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This came from a very creative person whose idea not only allowed me to win the second prize, they also won a consolation prize in their idea. People say ideas are cheap. That’s half true. Yes, there is likely someone else who stumbled across the same idea and has the skills to implement it, but really most of the time we already have the capacity to build this idea, we just don’t know it yet. &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I wish I did more AI related things in University, I feel like I missed out&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is &lt;strong&gt;the&lt;/strong&gt; comment that prompted me to come up with this article. I always wanted to present something about AI to my team, given that I do have &lt;em&gt;some&lt;/em&gt; understanding of AI, but someone else did an introduction to Neural Networks that was more detailed than what I could come up with and I felt that that person would be more suited to carry on doing AI related talks. However from this comment I realized that &lt;strong&gt;because&lt;/strong&gt; I am kinda shit in AI, but yet I know how to &lt;strong&gt;use&lt;/strong&gt; AI libraries, I can add value to this topic. &lt;/p&gt;
&lt;p&gt;So here’s what I hope people will gain from this article:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Approaching Problems with AI&lt;/li&gt;
&lt;li&gt;What algorithms are good to google&lt;/li&gt;
&lt;li&gt;What can we achieve with just a surface level knowledge of AI&lt;/li&gt;
&lt;li&gt;Famous APIs that we can use for the next hackathon/prototype of things that we wanna work on&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here’s what I will &lt;strong&gt;not&lt;/strong&gt; go through&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How Neural networks work&lt;/li&gt;
&lt;li&gt;How to build an AI from scratch&lt;/li&gt;
&lt;li&gt;How to beat the no.1 go player with AI&lt;/li&gt;
&lt;li&gt;How famous algorithms work&lt;/li&gt;
&lt;li&gt;How to win a hackathon with AI&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Mostly because I don’t know the answers to any of the above.&lt;/p&gt;
&lt;p&gt;Now this article will be written with FE developers in mind, with introductions to Javascript libraries. Many people would say that there are a lot of better languages for AI development and I entirely agree. There are some benefits to do AI in Javascript. Firstly, there’s always the Nodes argument: your entire stack can be the same language. Whatever flavour of JS you are using, you can easily switch over from one to another. This is great for a quick prototype and/or proof of concept to show that your idea even works in the first place. Secondly for the users, you can have the entire script running on the browser. You can write some application once and run it anywhere, you don’t have to worry about scaling as all the computation is running on the user’s device. This also means you can have your application running offline, with PWAs. I think this is one of the strongest points we have for AI running on browsers. Finally, in terms of performance, JS is not much behind python, in some cases it might even been faster. It’s really only a matter of time before the tools available for JS catches up to Python as the JS community grows larger and larger.&lt;/p&gt;
&lt;h2&gt;What is AI&lt;/h2&gt;
&lt;p&gt;There are a few definitions of what AI is, and many of us get confused about the terminology. What is Artificial Intelligence and what is Machine Learning? Are they even different? The most sensible definition I found is that Artificial Intelligence is &lt;code class=&quot;language-text&quot;&gt;Simulation of human thought processes in machines.&lt;/code&gt; I find this to be very accurate. AI can be as simple as a bunch of if-else statements (that’s essentially a &lt;code class=&quot;language-text&quot;&gt;decision tree&lt;/code&gt;) or something as complicated as simulating a brain (&lt;code class=&quot;language-text&quot;&gt;neural nets&lt;/code&gt;). Machine learning is a subset of artificial intelligence, and basically what ML does is to write a program to find patterns in data, without being explicitly written which pattern to recognize.&lt;/p&gt;
&lt;p&gt;Now in my own understanding, we really just want to solve three different types of problems:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Categorize things&lt;/li&gt;
&lt;li&gt;Make Decisions&lt;/li&gt;
&lt;li&gt;Generate things&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These groups of problems are actually not how actual AI-savvy people group them, but I find these approach of grouping problems easier to use to visualize solving some problem with AI.&lt;/p&gt;
&lt;p&gt;These problems have to be represented by some form of data, so that’s something that usually requires some level of intuition and experience, but after a while you might start recognizing certain methods people use to represent different data. For now, let’s assume that all real world data come in the form of numbers stored in some variables.&lt;/p&gt;
&lt;h2&gt;Categorising problem&lt;/h2&gt;
&lt;p&gt;For the first type of problems, we can imagine a mathematical function. Suppose we want to guess: given a Merge Request (Pull Request) how many people will actually do a MR vs giving a “free” &lt;code class=&quot;language-text&quot;&gt;LGTM&lt;/code&gt;? In this case, maybe a point of interest would be the length of the MR by lines of code changed. We can expect that with more lines, the more likely people will &lt;code class=&quot;language-text&quot;&gt;LGTM&lt;/code&gt; it without reading it. Now maybe a second point of interest that we want to do is how many files have been changed. Now if there’s very few file changes, the code change is easier to understand, and people will tend to actually review the code compared to MRs with lots of file change. So we end up with something like this:&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 62.83783783783784%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsSAAALEgHS3X78AAABU0lEQVQ4y41SW5KCMBD0/ufa9QB+gnygFoIQ5JkXJL1JlCgg1qYqYYBJT/dM72BW13UQQtgQWmv/fI+ntRFPQbOzZxzHqKpqBbRZgPNlsTmgBaOU+gRV3aH7HlquWdulmhpaqW1AC1aW5fyyaYEexzd26n+SoyhC27YoiuJ12YIZBh7QxCq/zVhtSj4cDgiC4AVoJZUEmlG3ncR7acCHh9TF8D4OhXGGIi/mv166HmyfTFfsPvVQcIFTdoHhADYKn7ia+KzOF4YToOXRjwyZJGBK+GyhJEb97KeUzgGLXi4lc5CCeIDRQNs9mJNqDg4JoeXDUla2Ut+NPQiJ4HJETVvQnqJjPRrRQprvtr9VV6M277XuXCFX9M1SM8CpSm0mmOe5M/kxPGL/84swDHE+nZ0DstsNaZq6HGs1Qsi2sRcNRm96dL1ekSSJN7xTMgx+b/nwDzp2/Uh5kGazAAAAAElFTkSuQmCC) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/ac238eb1b7ab61a0f7f2463db59bb051/12f09/datapoint.png 148w,
/static/ac238eb1b7ab61a0f7f2463db59bb051/e4a3f/datapoint.png 295w,
/static/ac238eb1b7ab61a0f7f2463db59bb051/fcda8/datapoint.png 590w,
/static/ac238eb1b7ab61a0f7f2463db59bb051/efc66/datapoint.png 885w,
/static/ac238eb1b7ab61a0f7f2463db59bb051/c83ae/datapoint.png 1180w,
/static/ac238eb1b7ab61a0f7f2463db59bb051/05428/datapoint.png 2541w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/ac238eb1b7ab61a0f7f2463db59bb051/fcda8/datapoint.png&quot;
        srcset=&quot;/static/ac238eb1b7ab61a0f7f2463db59bb051/12f09/datapoint.png 148w,
/static/ac238eb1b7ab61a0f7f2463db59bb051/e4a3f/datapoint.png 295w,
/static/ac238eb1b7ab61a0f7f2463db59bb051/fcda8/datapoint.png 590w,
/static/ac238eb1b7ab61a0f7f2463db59bb051/efc66/datapoint.png 885w,
/static/ac238eb1b7ab61a0f7f2463db59bb051/c83ae/datapoint.png 1180w,
/static/ac238eb1b7ab61a0f7f2463db59bb051/05428/datapoint.png 2541w&quot;
        title=&quot;datapoint&quot;
        alt=&quot;datapoint&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;p&gt;So what we want our algorithm to do is to draw some line such that everything above the line belongs to &lt;code class=&quot;language-text&quot;&gt;LGTM&lt;/code&gt;-ed category, and everything below the line belongs to the &lt;code class=&quot;language-text&quot;&gt;actually been reviewed&lt;/code&gt; category. So we pass these data into some categorizing function and it will generate a best-fit line. Now whenever we want to categorize a new MR, we just plot it on the graph and check its relation to the said line like so:&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 62.83783783783784%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsSAAALEgHS3X78AAABfElEQVQ4y41T2XKDMAzs/39X2/fmEZK0ORoCGAIGX2B7K5PA5ICZmpHRGLGsdsUbaLVtC2NMSOG9n+73+bgW8jHhb2Hf7XaoquoFaPEDWj9/7BEwgAkhpwJXXeCFgO9eWYfleA3v3DKglBLVpbwWByahgiTw1t6xc/9rebvdgPMG2wMjsNsxMQsMJkDKXZ49sFps+Wu1QhRF+D0zlC1QCkBlDNCKQg6Vjth7219bfTJv1hRFL5eMDSfKeBQNReuh7VjvrjL4GXZzGhptsE+PIA4w3gzPTR+AHRiFMqMU9RXwwSgsAwYewiqkprgBA0HGtDFIuYXmBYGSFErete3nWtYoWDEJYgk6RE+7gqZ7B9F3gxR5bSGVvcH4eYa96RAd16hlA0nz2CoBbhoyuxv0vbQ1eNegpUuR0zUR1J2dd3nUoiYH8zwfhnwdr/H5/oE4jnHYH8DIsDTLkJzPlOf4+d6gLIvlwX4aAfprBJIkwel0ohfL6bzv+ymW5vAPCiv7dow0Wf0AAAAASUVORK5CYII=) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/f8c3ca700bab95a2c5dd2607e5c5499a/12f09/newdatapoint.png 148w,
/static/f8c3ca700bab95a2c5dd2607e5c5499a/e4a3f/newdatapoint.png 295w,
/static/f8c3ca700bab95a2c5dd2607e5c5499a/fcda8/newdatapoint.png 590w,
/static/f8c3ca700bab95a2c5dd2607e5c5499a/efc66/newdatapoint.png 885w,
/static/f8c3ca700bab95a2c5dd2607e5c5499a/c83ae/newdatapoint.png 1180w,
/static/f8c3ca700bab95a2c5dd2607e5c5499a/05428/newdatapoint.png 2541w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/f8c3ca700bab95a2c5dd2607e5c5499a/fcda8/newdatapoint.png&quot;
        srcset=&quot;/static/f8c3ca700bab95a2c5dd2607e5c5499a/12f09/newdatapoint.png 148w,
/static/f8c3ca700bab95a2c5dd2607e5c5499a/e4a3f/newdatapoint.png 295w,
/static/f8c3ca700bab95a2c5dd2607e5c5499a/fcda8/newdatapoint.png 590w,
/static/f8c3ca700bab95a2c5dd2607e5c5499a/efc66/newdatapoint.png 885w,
/static/f8c3ca700bab95a2c5dd2607e5c5499a/c83ae/newdatapoint.png 1180w,
/static/f8c3ca700bab95a2c5dd2607e5c5499a/05428/newdatapoint.png 2541w&quot;
        title=&quot;new datapoint&quot;
        alt=&quot;new datapoint&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;p&gt;But that is just two variables, what if we want to have a third variable? Like for example, how near is the deadline? The nearer the deadline, the more likely someone will skim through it, the further it is, the more likely someone will read it through. Well for 3 parameters, we can actually visualize it as a point in a 3-dimensional space. Instead of a line, we will separate the data set with what we call a plane (that is, a 2-d surface that extends indefinitely), like so:&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 100%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGQABAAIDAAAAAAAAAAAAAAAAAAEDAgQF/8QAFgEBAQEAAAAAAAAAAAAAAAAAAAID/9oADAMBAAIQAxAAAAHuxXTWe8hOjALAf//EABoQAAICAwAAAAAAAAAAAAAAAAARAQIQITH/2gAIAQEAAQUCZFnJdm3jlj//xAAXEQEAAwAAAAAAAAAAAAAAAAABAhEg/9oACAEDAQE/AWVOP//EABURAQEAAAAAAAAAAAAAAAAAAAEg/9oACAECAQE/AQj/xAAWEAADAAAAAAAAAAAAAAAAAAAAETD/2gAIAQEABj8CFD//xAAaEAACAwEBAAAAAAAAAAAAAAABEQAQQVEh/9oACAEBAAE/IdNQNAPfIAldtAC2v//aAAwDAQACAAMAAAAQlMgA/8QAFhEBAQEAAAAAAAAAAAAAAAAAEQEg/9oACAEDAQE/ELAY/8QAFhEBAQEAAAAAAAAAAAAAAAAAAREg/9oACAECAQE/EBS4/8QAHxABAAEEAQUAAAAAAAAAAAAAASEAEBExUUFhcYGR/9oACAEBAAE/EBDGBjximPZDz6tnY7zvcVMiIGOrxRqd0yTRiXAHJ8t//9k=) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/b06ebc757eb5b3db32071b04750708fd/a80bd/plane.jpg 148w,
/static/b06ebc757eb5b3db32071b04750708fd/1c91a/plane.jpg 295w,
/static/b06ebc757eb5b3db32071b04750708fd/1c72d/plane.jpg 590w,
/static/b06ebc757eb5b3db32071b04750708fd/4b190/plane.jpg 800w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/b06ebc757eb5b3db32071b04750708fd/1c72d/plane.jpg&quot;
        srcset=&quot;/static/b06ebc757eb5b3db32071b04750708fd/a80bd/plane.jpg 148w,
/static/b06ebc757eb5b3db32071b04750708fd/1c91a/plane.jpg 295w,
/static/b06ebc757eb5b3db32071b04750708fd/1c72d/plane.jpg 590w,
/static/b06ebc757eb5b3db32071b04750708fd/4b190/plane.jpg 800w&quot;
        title=&quot;hyperplaneplane&quot;
        alt=&quot;hyperplaneplane&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;p&gt;If we add another variable? Easy! Make it four dimensional, or five, or six or however many variables you need. In ML we call these variables &lt;code class=&quot;language-text&quot;&gt;parameters&lt;/code&gt; and we call the thing separating the different categories the &lt;code class=&quot;language-text&quot;&gt;hyperplane&lt;/code&gt; (subspace whose dimension is one less than that of its ambient space). Not all categorizing algorithms work like this, but this is a way to visualize your problem that you want to solve.&lt;/p&gt;
&lt;h2&gt;Decision making problem&lt;/h2&gt;
&lt;p&gt;Next kind of problem, we have decision making. Essentially, given some number of choices, we want to be able to choose the most desirable option. A case study for this kind of problem would be something like a Tetris playing bot. Let’s establish some rules of the Tetris that we’re going to analyse. This will keep our problem scope smaller and easier to analyse.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;your score is how many lines you clear (one line, one point)&lt;/li&gt;
&lt;li&gt;how fast you make the move doesn’t matter&lt;/li&gt;
&lt;li&gt;you only know the current piece, and the current state of the game&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So let’s think, how we would want &lt;em&gt;a robot&lt;/em&gt; to play this game. I added the words &lt;em&gt;a robot&lt;/em&gt; there for one simple reason. We don’t want to care about things that will affect us emotionally. We are aware that the game gives us four points if we clear four lines in one go, and four points if we clear four lines individually, but for us it will feel so much more satisfying if we were clearing four lines at one go. Similarly, we don’t want the robot to care if making the optimal move makes the state of the game look “ugly”, we only care if its the best move at the current point in time.&lt;/p&gt;
&lt;p&gt;What we’ll do is given a current state of the game, we want to place the moves in every single possible(legal) ways and then use some method to gauge if a move is good or not. So what is this method? We will take the state of the game, and then come up with some numbers to represent a desirable trait or an undesirable trait. We will then sum up the desirable traits, and minus the undesirable traits to get a score. These traits are known as &lt;code class=&quot;language-text&quot;&gt;heuristics&lt;/code&gt;. Heuristics give us some interpretation of how good a decision is, and more importantly, they are usually fast to calculate. Of course, some traits are more important than others, so we need to multiply them by some constant value. These constant values are called &lt;code class=&quot;language-text&quot;&gt;weights&lt;/code&gt;. We can throw the weights into some classification algorithm to optimise what number is better, so we don’t need to care about what the numbers are for the sake of this article.&lt;/p&gt;
&lt;p&gt;Let’s think of the first heuristic we care about. Of course we want to clear lines, and even though clearing more lines doesn’t give us more points, but it makes the game last a little bit longer, so let’s just count if there are lines cleared or not this turn:&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 100%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGQABAAMBAQAAAAAAAAAAAAAAAAIDBQEE/8QAFgEBAQEAAAAAAAAAAAAAAAAAAgAB/9oADAMBAAIQAxAAAAHcq74QtUMxgZWjb//EABoQAAIDAQEAAAAAAAAAAAAAAAECAAMTEBL/2gAIAQEAAQUCdvIW0Ny4gLWx1hUNM0Bn/8QAFhEBAQEAAAAAAAAAAAAAAAAAESAh/9oACAEDAQE/ATGP/8QAGBEAAgMAAAAAAAAAAAAAAAAAEBEBAiH/2gAIAQIBAT8Bm2oIf//EABkQAAIDAQAAAAAAAAAAAAAAAAAhARARYf/aAAgBAQAGPwLRUyI7TNx1/8QAHBAAAgIDAQEAAAAAAAAAAAAAAREAECExYVFx/9oACAEBAAE/IeGi9nqmMXnA7GKvjylCNFiASOLRr//aAAwDAQACAAMAAAAQR8j8/8QAGBEBAAMBAAAAAAAAAAAAAAAAARAR8SH/2gAIAQMBAT8QL8s1Itj/xAAXEQEBAQEAAAAAAAAAAAAAAAARARBR/9oACAECAQE/EAnvBamf/8QAHBABAQEAAwADAAAAAAAAAAAAAREhABBBMWGB/9oACAEBAAE/EKDFFoFeYSCj7346Oy/BbDDkBHDiDGfpvRRyW0ie8Moe4s6//9k=) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/b5b202697ba2915bed68d75bad0c7596/a80bd/linesclear.jpg 148w,
/static/b5b202697ba2915bed68d75bad0c7596/1c91a/linesclear.jpg 295w,
/static/b5b202697ba2915bed68d75bad0c7596/1c72d/linesclear.jpg 590w,
/static/b5b202697ba2915bed68d75bad0c7596/4b190/linesclear.jpg 800w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/b5b202697ba2915bed68d75bad0c7596/1c72d/linesclear.jpg&quot;
        srcset=&quot;/static/b5b202697ba2915bed68d75bad0c7596/a80bd/linesclear.jpg 148w,
/static/b5b202697ba2915bed68d75bad0c7596/1c91a/linesclear.jpg 295w,
/static/b5b202697ba2915bed68d75bad0c7596/1c72d/linesclear.jpg 590w,
/static/b5b202697ba2915bed68d75bad0c7596/4b190/linesclear.jpg 800w&quot;
        title=&quot;linescleared&quot;
        alt=&quot;linescleared&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;p&gt;Next thing, we want the robot to play as many moves as possible, so that it has the most chances to clear lines, we don’t want the bot to make an optimal move it that ends the game right now. So let’s take something like, the current height of the game like so:&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 100%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGAABAAMBAAAAAAAAAAAAAAAAAAIDBQT/xAAWAQEBAQAAAAAAAAAAAAAAAAACAAH/2gAMAwEAAhADEAAAAdutwhawZjAytG3/xAAbEAACAgMBAAAAAAAAAAAAAAABAgADEBITI//aAAgBAQABBQJ21C2hsXEKlbesKhpzQGf/xAAWEQEBAQAAAAAAAAAAAAAAAAARICH/2gAIAQMBAT8BMY//xAAXEQADAQAAAAAAAAAAAAAAAAABEBEh/9oACAECAQE/ASdii//EABoQAAICAwAAAAAAAAAAAAAAAAARECEBEmH/2gAIAQEABj8CZUPJr2LGrj//xAAbEAACAgMBAAAAAAAAAAAAAAABEQAhEDFRcf/aAAgBAQABPyHQKnfawuLuh0wqkvGFCNFiASNWjj//2gAMAwEAAgADAAAAEPfI/P/EABoRAQABBQAAAAAAAAAAAAAAAAEQETFBsfH/2gAIAQMBAT8QMbltpFWP/8QAFxEBAQEBAAAAAAAAAAAAAAAAAREQQf/aAAgBAgEBPxBZPchbM//EABwQAQEBAAMAAwAAAAAAAAAAAAERIQAQQTFhcf/aAAgBAQABPxBXSRaBXkCykfe/HQiLiFwYchw5cQSYfpvRRyW0ie8Moe4s6//Z) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/ba095da270fa5c0e70f815fcd35a149c/a80bd/height.jpg 148w,
/static/ba095da270fa5c0e70f815fcd35a149c/1c91a/height.jpg 295w,
/static/ba095da270fa5c0e70f815fcd35a149c/1c72d/height.jpg 590w,
/static/ba095da270fa5c0e70f815fcd35a149c/4b190/height.jpg 800w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/ba095da270fa5c0e70f815fcd35a149c/1c72d/height.jpg&quot;
        srcset=&quot;/static/ba095da270fa5c0e70f815fcd35a149c/a80bd/height.jpg 148w,
/static/ba095da270fa5c0e70f815fcd35a149c/1c91a/height.jpg 295w,
/static/ba095da270fa5c0e70f815fcd35a149c/1c72d/height.jpg 590w,
/static/ba095da270fa5c0e70f815fcd35a149c/4b190/height.jpg 800w&quot;
        title=&quot;height&quot;
        alt=&quot;height&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;p&gt;Now this is good, but suppose we have just one line that’s really tall but doesn’t lose immediately, that’s not entirely bad right? So maybe we can do something better. instead of just height, let’s sum up the height of each individual column, like this:&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 100%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGAABAAMBAAAAAAAAAAAAAAAAAAIDBQT/xAAWAQEBAQAAAAAAAAAAAAAAAAACAAH/2gAMAwEAAhADEAAAAdypwhawZjAytG3/xAAbEAACAgMBAAAAAAAAAAAAAAABAgADEBITI//aAAgBAQABBQJ21C2hsXEKlbe0KhpzQGf/xAAWEQEBAQAAAAAAAAAAAAAAAAARICH/2gAIAQMBAT8BMY//xAAXEQADAQAAAAAAAAAAAAAAAAABEBES/9oACAECAQE/ASTqKL//xAAZEAACAwEAAAAAAAAAAAAAAAAAEQEQIWH/2gAIAQEABj8CZlOSI7WjW1//xAAcEAACAgIDAAAAAAAAAAAAAAABEQAQIVExYXH/2gAIAQEAAT8h6JF+ypcXnA2YRleNUoRosQCRxcGv/9oADAMBAAIAAwAAABBnyPz/xAAaEQEAAQUAAAAAAAAAAAAAAAABEBEhMbHx/9oACAEDAQE/EA3jmNpFWP/EABcRAQEBAQAAAAAAAAAAAAAAABEBEEH/2gAIAQIBAT8QEnuC1M//xAAcEAEBAQADAAMAAAAAAAAAAAABESEAEEExYXH/2gAIAQEAAT8QosUVQK80kaH3vx0Ii4hcGHIiLDiGMP03oo5LaRPeGUPcWdf/2Q==) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/2cc87472321eb3eb7805522ad7be660e/a80bd/colheight.jpg 148w,
/static/2cc87472321eb3eb7805522ad7be660e/1c91a/colheight.jpg 295w,
/static/2cc87472321eb3eb7805522ad7be660e/1c72d/colheight.jpg 590w,
/static/2cc87472321eb3eb7805522ad7be660e/4b190/colheight.jpg 800w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/2cc87472321eb3eb7805522ad7be660e/1c72d/colheight.jpg&quot;
        srcset=&quot;/static/2cc87472321eb3eb7805522ad7be660e/a80bd/colheight.jpg 148w,
/static/2cc87472321eb3eb7805522ad7be660e/1c91a/colheight.jpg 295w,
/static/2cc87472321eb3eb7805522ad7be660e/1c72d/colheight.jpg 590w,
/static/2cc87472321eb3eb7805522ad7be660e/4b190/colheight.jpg 800w&quot;
        title=&quot;colheight&quot;
        alt=&quot;colheight&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;p&gt;Finally the biggest bane of Tetris is to have a “hole” right? it’s bound to happen but we want to reduce the number of holes. Lets count the number of holes and then multiply it by a some negative weight:&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 100%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGAABAAMBAAAAAAAAAAAAAAAAAAIDBQT/xAAVAQEBAAAAAAAAAAAAAAAAAAACAP/aAAwDAQACEAMQAAAB3KnCFrBmMA1oV//EABsQAQEAAgMBAAAAAAAAAAAAAAIBAAMQEhMj/9oACAEBAAEFAmusO2LjdYSF9cplzzEuf//EABYRAQEBAAAAAAAAAAAAAAAAABEgIf/aAAgBAwEBPwExj//EABcRAAMBAAAAAAAAAAAAAAAAABAREiH/2gAIAQIBAT8BrUEP/8QAGhAAAgIDAAAAAAAAAAAAAAAAABEQIQESYf/aAAgBAQAGPwJlQ8mvYsauP//EABwQAAICAgMAAAAAAAAAAAAAAAERACEQMVFhcf/aAAgBAQABPyHo0Xs9YWVh0OTDqS8QUIpRosQCRq0cf//aAAwDAQACAAMAAAAQV8D8/8QAGREBAAIDAAAAAAAAAAAAAAAAARAxQbHw/9oACAEDAQE/EDtitpCsf//EABgRAQEAAwAAAAAAAAAAAAAAAAEQESEx/9oACAECAQE/EFayA7if/8QAHRABAQACAwADAAAAAAAAAAAAAREAIRAxQVFhgf/aAAgBAQABPxCgxRaBXNEgo+99cCBa0KwYZIhodISa/TBAPMXu9V0/OGUPcWcf/9k=) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/b4f9d1896a761a1cd7acfb2667b239bd/a80bd/holes.jpg 148w,
/static/b4f9d1896a761a1cd7acfb2667b239bd/1c91a/holes.jpg 295w,
/static/b4f9d1896a761a1cd7acfb2667b239bd/1c72d/holes.jpg 590w,
/static/b4f9d1896a761a1cd7acfb2667b239bd/4b190/holes.jpg 800w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/b4f9d1896a761a1cd7acfb2667b239bd/1c72d/holes.jpg&quot;
        srcset=&quot;/static/b4f9d1896a761a1cd7acfb2667b239bd/a80bd/holes.jpg 148w,
/static/b4f9d1896a761a1cd7acfb2667b239bd/1c91a/holes.jpg 295w,
/static/b4f9d1896a761a1cd7acfb2667b239bd/1c72d/holes.jpg 590w,
/static/b4f9d1896a761a1cd7acfb2667b239bd/4b190/holes.jpg 800w&quot;
        title=&quot;holes&quot;
        alt=&quot;holes&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;p&gt;But it’s not necessarily just holes, overhanging piece will eventually create holes (assume no T-spins and no “sliding” at the bottom) so we want to count that as well. And a hole with more overhang is worse than a piece that just overhangs. So let’s do something like this:&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 100%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGAABAAMBAAAAAAAAAAAAAAAAAAIDBQT/xAAXAQADAQAAAAAAAAAAAAAAAAAAAQID/9oADAMBAAIQAxAAAAHbrcOd6w0iMBFoZ//EABsQAQADAAMBAAAAAAAAAAAAAAIAAQMQEhMj/9oACAEBAAEFAkusOtLjayTmvrLNKeYq5//EABYRAQEBAAAAAAAAAAAAAAAAABEgIf/aAAgBAwEBPwExj//EABYRAQEBAAAAAAAAAAAAAAAAABEQIf/aAAgBAgEBPwF0hP/EABoQAAICAwAAAAAAAAAAAAAAAAARECEBEmH/2gAIAQEABj8CZUPJr2LGrj//xAAbEAACAwEBAQAAAAAAAAAAAAABEQAhMRBhcf/aAAgBAQABPyFU6EXs84sruhCqS+IPYoRosQCRqw8//9oADAMBAAIAAwAAABBbCPz/xAAaEQACAgMAAAAAAAAAAAAAAAABEBEhMbHx/9oACAEDAQE/EL1cxshSV//EABcRAQEBAQAAAAAAAAAAAAAAABEBEEH/2gAIAQIBAT8Qtw+4FM//xAAeEAEBAAICAgMAAAAAAAAAAAABEQAhEDFBYXGBkf/aAAgBAQABPxB3BDaBX6/M0SCj3vrgBpYhVYwyBAwwQSaPk3lTpfWFdZbJE84ZQ84s4//Z) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/5780c3d471812030d953998ea2c1733f/a80bd/overhang.jpg 148w,
/static/5780c3d471812030d953998ea2c1733f/1c91a/overhang.jpg 295w,
/static/5780c3d471812030d953998ea2c1733f/1c72d/overhang.jpg 590w,
/static/5780c3d471812030d953998ea2c1733f/4b190/overhang.jpg 800w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/5780c3d471812030d953998ea2c1733f/1c72d/overhang.jpg&quot;
        srcset=&quot;/static/5780c3d471812030d953998ea2c1733f/a80bd/overhang.jpg 148w,
/static/5780c3d471812030d953998ea2c1733f/1c91a/overhang.jpg 295w,
/static/5780c3d471812030d953998ea2c1733f/1c72d/overhang.jpg 590w,
/static/5780c3d471812030d953998ea2c1733f/4b190/overhang.jpg 800w&quot;
        title=&quot;overhang&quot;
        alt=&quot;overhang&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;p&gt;If we look at the previous two, isn’t the hole count really some subset of the overhang count? So maybe we can do something better. How about if starting from bottom, we add a count every time we go from “solid” to “gap” this way we can actually detect when there are a lot of small gaps, as small gaps take more moves to solve but big gaps could be solved easier.&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 100%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGAABAAMBAAAAAAAAAAAAAAAAAAIDBQT/xAAWAQEBAQAAAAAAAAAAAAAAAAACAAH/2gAMAwEAAhADEAAAAdutwhawZjAytG3/xAAbEAACAgMBAAAAAAAAAAAAAAABAgADEBITI//aAAgBAQABBQJ21C2hsXEKlbesKhpzQGf/xAAWEQEBAQAAAAAAAAAAAAAAAAARICL/2gAIAQMBAT8BMsf/xAAXEQADAQAAAAAAAAAAAAAAAAABEBEi/9oACAECAQE/ASdRRf/EABoQAAICAwAAAAAAAAAAAAAAAAARECEBEmH/2gAIAQEABj8CZUPJr2LGrj//xAAbEAACAgMBAAAAAAAAAAAAAAABEQAQITFhcf/aAAgBAQABPyHhovZ6pcWHgdhVJeKUI0WIBI4tGv/aAAwDAQACAAMAAAAQ98j8/8QAGhEBAAEFAAAAAAAAAAAAAAAAARARMUGx8f/aAAgBAwEBPxAxOW2kVY//xAAXEQEBAQEAAAAAAAAAAAAAAAABERBB/9oACAECAQE/EFg9yFsz/8QAHRABAQABBAMAAAAAAAAAAAAAAREhABAxQXGBkf/aAAgBAQABPxDiKi0CvrWIAUfeNhXCELYYahw4uEJMHkzsUcSzSJ3oyh3izb//2Q==) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/2f51a4fccdefb0b72239ebc5ecff6e8d/a80bd/bumpiness.jpg 148w,
/static/2f51a4fccdefb0b72239ebc5ecff6e8d/1c91a/bumpiness.jpg 295w,
/static/2f51a4fccdefb0b72239ebc5ecff6e8d/1c72d/bumpiness.jpg 590w,
/static/2f51a4fccdefb0b72239ebc5ecff6e8d/4b190/bumpiness.jpg 800w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/2f51a4fccdefb0b72239ebc5ecff6e8d/1c72d/bumpiness.jpg&quot;
        srcset=&quot;/static/2f51a4fccdefb0b72239ebc5ecff6e8d/a80bd/bumpiness.jpg 148w,
/static/2f51a4fccdefb0b72239ebc5ecff6e8d/1c91a/bumpiness.jpg 295w,
/static/2f51a4fccdefb0b72239ebc5ecff6e8d/1c72d/bumpiness.jpg 590w,
/static/2f51a4fccdefb0b72239ebc5ecff6e8d/4b190/bumpiness.jpg 800w&quot;
        title=&quot;bumpiness&quot;
        alt=&quot;bumpiness&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;p&gt;But I think we can do better. This heuristics takes care of how many gaps there are in the same column, but it doesn’t really have a big picture representation of how sever a gap is. A gap with many bends is much harder to solve than a ‘smooth’ gap. A heuristic that can take this into consideration could be something like how many 90 degree bends there are in the state.&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 100%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGAABAAMBAAAAAAAAAAAAAAAAAAIDBQT/xAAXAQADAQAAAAAAAAAAAAAAAAAAAQID/9oADAMBAAIQAxAAAAHcplwZ3rDSIwEWhn//xAAbEAEBAAIDAQAAAAAAAAAAAAACAQADEBITI//aAAgBAQABBQJrrDti43WE619cpizzEWf/xAAWEQEBAQAAAAAAAAAAAAAAAAARICL/2gAIAQMBAT8BMsf/xAAXEQADAQAAAAAAAAAAAAAAAAABEBEi/9oACAECAQE/ASdRRf/EABoQAAIDAQEAAAAAAAAAAAAAAAARARAhEmH/2gAIAQEABj8CZk05Ofa0a2v/xAAdEAACAQQDAAAAAAAAAAAAAAABEQAQITFxQVFh/9oACAEBAAE/IcAeor5qLqw7D2FUlp1RQjRYgEDawaf/2gAMAwEAAgADAAAAEFPI/P/EABkRAQACAwAAAAAAAAAAAAAAAAEQMRGx8f/aAAgBAwEBPxAFHK2kZY//xAAXEQEBAQEAAAAAAAAAAAAAAAABERAh/9oACAECAQE/EGg5C2dz/8QAGxABAAIDAQEAAAAAAAAAAAAAAREhADGBEFH/2gAIAQEAAT8QS+BMgl5lgGQHdYavBOkIJmDBkBCxYEFK6X4Ua1dpNOGE+4sef//Z) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/b3e97bff0c717846a1295184fc097d67/a80bd/bends.jpg 148w,
/static/b3e97bff0c717846a1295184fc097d67/1c91a/bends.jpg 295w,
/static/b3e97bff0c717846a1295184fc097d67/1c72d/bends.jpg 590w,
/static/b3e97bff0c717846a1295184fc097d67/4b190/bends.jpg 800w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/b3e97bff0c717846a1295184fc097d67/1c72d/bends.jpg&quot;
        srcset=&quot;/static/b3e97bff0c717846a1295184fc097d67/a80bd/bends.jpg 148w,
/static/b3e97bff0c717846a1295184fc097d67/1c91a/bends.jpg 295w,
/static/b3e97bff0c717846a1295184fc097d67/1c72d/bends.jpg 590w,
/static/b3e97bff0c717846a1295184fc097d67/4b190/bends.jpg 800w&quot;
        title=&quot;bends&quot;
        alt=&quot;bends&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;p&gt;Summing up the heuristics and then multiplying by some constant weights to them, we have something like:&lt;/p&gt;
&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;∗&lt;/mo&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;∗&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;∗&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;H&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mi&gt;h&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;∗&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;∗&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;c_1 * linesCleared + (-1 * c_2) * sumColHeight + (-1 * c_3) * numBends&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.61528em;vertical-align:-0.15em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.30110799999999993em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;∗&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.77777em;vertical-align:-0.08333em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.01968em;&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.07153em;&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.01968em;&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.02778em;&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;−&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;∗&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.30110799999999993em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;∗&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.8888799999999999em;vertical-align:-0.19444em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.07153em;&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.01968em;&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.08125em;&quot;&gt;H&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03588em;&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;−&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;∗&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.30110799999999993em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;3&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;∗&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.69444em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05017em;&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;s&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;p&gt;So now we have a bot that analyses Tetris like how an almost perfect human would, except the analysis needs to be weighted. All details aside, we can look for some algorithm that takes in &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;c_1, c_2, c_3&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.625em;vertical-align:-0.19444em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.30110799999999993em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.30110799999999993em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.30110799999999993em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;3&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;, runs a game of Tetris, gets the score, modifies &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;c_1, c_2, c_3&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.625em;vertical-align:-0.19444em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.30110799999999993em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.30110799999999993em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.30110799999999993em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;3&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; a little bit and runs the game again. rinse and repeat until &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;c_1, c_2, c_3&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.625em;vertical-align:-0.19444em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.30110799999999993em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.30110799999999993em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.30110799999999993em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;3&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is fairly stagnant, or you don’t have time to train anymore. In university my teammates used a library which provided something called &lt;code class=&quot;language-text&quot;&gt;particle swarm optimization&lt;/code&gt; which brought my team’s AI score up from ten thousands to millions just by running a optimization algorithm on the weights.&lt;/p&gt;
&lt;h2&gt;Content Generation Problem&lt;/h2&gt;
&lt;p&gt;For the final type of problem, unfortunately there are too many different ways for different domains. Generating an Image is quite different from generating sounds or text. There is some headway being made in the form of neural networks which pit two neural networks against each other, but that’s a whole new article and presentation. However for text generation, there are some probability-based state machines (known as &lt;code class=&quot;language-text&quot;&gt;Markov model&lt;/code&gt; or &lt;code class=&quot;language-text&quot;&gt;Markov process&lt;/code&gt;) that is easy to program, and also gives us reasonable results.&lt;/p&gt;
&lt;p&gt;I won’t go through the process of writing a &lt;code class=&quot;language-text&quot;&gt;Markov model&lt;/code&gt; but the general idea for text generation will be something like. “What is the most likely word to appear next, given that the words before are &lt;code class=&quot;language-text&quot;&gt;a&lt;/code&gt; and &lt;code class=&quot;language-text&quot;&gt;b&lt;/code&gt; (and &lt;code class=&quot;language-text&quot;&gt;c&lt;/code&gt; and &lt;code class=&quot;language-text&quot;&gt;d&lt;/code&gt; etc etc etc..)?” So what we will do is to find a markov model, and find sufficiently big data set. An example that I want to use is something like a Donald Trump text generator. &lt;/p&gt;
&lt;p&gt;First things first, I need a data set. In the domain of Natural Language Processing, we call a file with lots of sentences a corpus, so I found &lt;a href=&quot;https://github.com/ryanmcdermott/trump-speeches&quot;&gt;1mb worth of trump speeches&lt;/a&gt; from &lt;a href=&quot;https://twitter.com/ryconoclast&quot;&gt;@ryconoclast&lt;/a&gt;. We can do some cleaning up of the data, like changing all text to lowercase, and grouping words that come from the same word together(&lt;code class=&quot;language-text&quot;&gt;stemming&lt;/code&gt;, eg: consultant, consulting, consults -&gt; consult) but I won’t be using it for my example, just to showcase how decent the results are without much effort.&lt;/p&gt;
&lt;p&gt;After finding &lt;a href=&quot;https://medium.com/@corrigan1247/how-to-imitate-trump-with-markov-chains-8224877dcf69&quot;&gt;a tutorial on how to do exactly trump speech generators&lt;/a&gt;, I passed in the entire text file into the function, added some checks to make my generated content at least 20 words long, and this is my result:&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 181.75675675675677%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAkCAYAAACJ8xqgAAAACXBIWXMAABYlAAAWJQFJUiTwAAAFC0lEQVRIx6VUa1CUVRjeC8Gik6uwzrDtsos5IZgyKFPamOaVi6AGIq6mbq7shkuCXEQgMDFzmG6oIeJtsrBax+I2NTnkNNm0ImmIIHJT5I7IRX8BXvDpe8+6yAqfUH0zz7znvOec5zzv5XwCgUCAoqIi/N+vtbUVDg4OEBBhbm4uc5aXl6OhoQG1tbUMNK+srGT25s2bqKurQ1lZGW7duoVr166hpKSEzR8/fozr16/D3t7eQlhQUMAIa2pq0NPTg66uLkZ448YNNDc3s3F7eztTQWOyTU1NjJgsfdXV1U8J8/PzmfPKlSuoqqpih4icVJECIqA1UkEXkGrrheTjJezs7MTt27fR0dHBSFpaWpgC8lMqSD35SdmdO3dQX1+P3t5edpaEDBIWFhYyJyki0O2UI9pEKtra2gbz2dfXx9TTnPbRfBihVWFpaSkLjVQ0Njayg0RIxSBLeSQiUtbf329TZZuQ8/LymJNUUWgUNpESKHwCqSRLOSTQHirecxVSAeh2Cq2iooKNSRVtpjUC5ZHUFxcXw2w2s/zyEhKBNelkKUxSQnMiJoVENlQZ9SBvlakF6DAVhjYQrHmkAly6dIntsZLS9+jRI35CCoOkU+KvXr3KCnTv3j3e50bqrIQjtg3devfuXUbS3d3N8ODBA17CgYGBwZCpEwbfck5ODnPev3+f3TgU5KMWeRYPHz5kZ6y5pHSIxWILoVQqhUqlgkKhGAalUmkDtVoNR0dHpKam4PRpE5ycJjGfTCYjMgvhf4F0ojNEohdGWhNAKBSOGbRfbCeCq2ICVEopRypiPqv9VwqFHKa5KZD8/jKU/x6FKnMMCnM2wWu6i4XUcuEYiJ4om+3phhjtSmQkaHEiXYfy81For0yC+ecITJaNH5tCiUQCRwlrByydOwPZqXocTtbiQIoRhz6LRs7+UBT/tBXrgr1HJxwnscf8173g7OwEO7EIaZFrcGyXHl8k6fH10Uzs3xGLPZpg7I5fhRnuLvyEQqHFujhLsXebBrNnekAln4yPItfBdFCHC79E449zh/Cj6Riy9iRi/tzZz8/hkwUWoumTKBg1fljr/yZ0wX4oMulRfzkO505vwMWi7QgL9YXETmTbNnyI0wYhZ58R0RtWYH3gEoT5LcJZUziayhJQ8NVmGDQLMctDPbwP+ZBiCMbhFD2nbiEiwgIRsmwBzudHoLUiEb+e0SPUdxHmzZrB9eAohMIn1mPKS1zY3tgVsQaZSVsQrwtCyVkjWsp34lSmFt7TPAbzPapCkciSR43/G/g2PZIR5h4NR91fcWj4ewd2x67g1sUjPz2+RnZXy3F8twGZyZuRZgzDn4VG1JbEorF0J0ICfGwu5iUUi4QsDLLJ4W/jG64okWuXQ69ZgpriWNRdjMPloijM8/G06Yhnfg4CTJI62iy89upUnNy7FUdSt8AQGoAEgz9+O2NA9YUYfJ+l5dY9+YppGQQu9cC+D3wRH7kAq4NmIu7dAJxIew9HuJeRHqPBwQ9DcDxdg5Ofa7B1vT8Wz/EZqSBPCf0WTMcP2TqY87bDlKVDRuIGTp0eXyZy4+QwnMp4B98d2MgpXY7VyxZjqkph0xEj5vDFcePxiqsr1HIlYjcGcT0Yjm0blyL74zX4NGkl3przMtzdVNi0yh9TlPLRCYfCy12FLat9oZTLMHGCBA72doNraoUcMu7X/9wcWm+jlrGtnHDYGx8FY/nBjv2v/g+nrD/wgl5F4gAAAABJRU5ErkJggg==) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/493d544d615b06d81ba9320aa313b80e/12f09/2gram.png 148w,
/static/493d544d615b06d81ba9320aa313b80e/e4a3f/2gram.png 295w,
/static/493d544d615b06d81ba9320aa313b80e/a07a7/2gram.png 534w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/493d544d615b06d81ba9320aa313b80e/a07a7/2gram.png&quot;
        srcset=&quot;/static/493d544d615b06d81ba9320aa313b80e/12f09/2gram.png 148w,
/static/493d544d615b06d81ba9320aa313b80e/e4a3f/2gram.png 295w,
/static/493d544d615b06d81ba9320aa313b80e/a07a7/2gram.png 534w&quot;
        title=&quot;bigram&quot;
        alt=&quot;bigram&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;p&gt;Not too bad, but a little bit random right? If you did read through the tutorial on building Markov chains, you might guess why. If not, the general idea is that we are only looking at some word &lt;code class=&quot;language-text&quot;&gt;a&lt;/code&gt; and getting a list of words that come after &lt;code class=&quot;language-text&quot;&gt;a&lt;/code&gt;, and choosing a word randomly from there. This is kinda funny but not really as fluent as we like it to be. So I did some modifications and made it such that we get a sequence of &lt;code class=&quot;language-text&quot;&gt;x&lt;/code&gt; number of words to generate the next one. So here’s one where we look at the previous 2 words:&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 179.05405405405406%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAkCAYAAACJ8xqgAAAACXBIWXMAABYlAAAWJQFJUiTwAAAE/0lEQVRIx6VUaUxUVxSehWVYOoOIEKkLIdKGpESWgqSCKQFbpKIghgxSBqYMywxDy65UFoOhlMZdqFhp41JN+rclJf3TJtYqVUonIpuy78iqEWX/+s6VxxJmgLY3Oe/ed+493/2+c857ArFYjIiICCQmJkKlUiEuLm7Blr6vtk5KSoKjoyMEAgEEVlZWmJubw/8dycnJi4AvXrzA8PAwHj58iLa2NnR0dKCvrw8NDQ1oaWlhvqamJuan9/r6eramuMnJSQao0WgWAV++fInR0VE8fvwYnZ2dDOzp06fo7e1l7wRC8+DgIJvpHJ159eoVpqenVwLSxsDAADv45MkTdHd3Q6fTMVY8Y/4yUkFrfszMzKwEHB8fZ6AU0NXVxW7v6elZAOvv72c+2m9tbWUz+YaGhpgyvZLHxsbw6NEjVFVVMQYU2NzczOSSn183NjYyBQRKCurq6vQDUlFokw5RIIHSTEyoOLW1tQtFI1AenFJFQ61WL5dMxleRbqeCkHy6iPzt7e0MnJdNjMmoUHoZPn/+nEkhlgRKYLxUyhWxI2AqGs3ErqamRn/bELuJiYmFliEZVBQKIonEli8OXyxiSXEG+/DZs2eMHUkjdhREbMhHTMlHYOTj+5CG3j6km3hACiSmtKbmJmBKAV1E0pcO+mSnpqb0NzYZSSKQkZERBkQzySfJxG4p4OzsLDO+sbVa7WtAmUy24ubVBknkWdGgdNGgPw8DpIezszM8PDzg5ua2qrm7u8PV1RWenp6orn6AhIR4FkvvUql0EfC/2Pbtjob2BBAKhRCJRGuaQCBkQeZmxrCxlkAmNQMfT/avGVpITOHj4YRrF8LReC8NdyoSka7xXclwvRa21xvZ8WEoy4tFxfU4dOoyMdiYg5SE3WxfJBKuDWhpYcHJeb3OiAnGpVwVSrKicKYgHeXnlKi4EYWfbyphJjE2zFA4PzvYb8Iut3fY2sVpK74rUON8lgIlhUdx5eJpFEcrcCLuIDQxeyAWrZJD0XyCA3fvRJYqDDYbrbHXeyfHLhaV36tw55dc3P7tFq6e/wo5GgWkVtL54qyRwyzlAVw9qcYBPy8ogv1xND4YbdWZ+LMyAfcrY3GjXAsXZ6fVi8Lna4udNS5z+fr6+CdQHAiAfJ8/0mKD0HQvFfW/p+FUTihCAt7FRpnlWoDCBcCbRVquECFQhn4AeSDHUP0Rmu+no+PvTBRlH+JS4gOHN23X1zbGRmJ4uezgWmU3LmYrUaCJwNn8MCa54W4qtIpA2Fht0P+lGKqykViEL1MiWB5Lj8dwudOitToDul9T4Ony1jJFqwPOH4ra74tbxck4mSRHSX4kGv5IQdtfmai8peLYyZblXC8gbRIrWr/tsBnlJ+JR8rkSh/x9UfpFOLp0WWh9kIGyYjkkJuaGfw4SUyNs3LD8QHLEh7heqMHpjChE7vfD5aJw3P1Jg9rbnyFFGQj7TTaGGZqaiPGp6j3ucwpCbpo/osO9UJx6BFfy43ApR4XC1FB8wzG8euoIio+FQB4UgB3b7A3nUGJiDHXkHvz4bQIqryWhtOBjnM1UoIzrwzPcd3ulSI4fSqI5/2FEhwQg0McbJsZGhiXz9oaZBbbY2sFp6zZcOBaDvMTDSFf541xeKJKjfbHZVgY/Lw8c5HJqYmK8NuBS2+fjhvd3uUJqKYH54p+E+7lKYG9nuz5Aof6cLCTf0N5S+wdMYE9fb0Mn7wAAAABJRU5ErkJggg==) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/f73270bd07bba4e4b81803120f474bcf/12f09/3gram.png 148w,
/static/f73270bd07bba4e4b81803120f474bcf/e4a3f/3gram.png 295w,
/static/f73270bd07bba4e4b81803120f474bcf/c0388/3gram.png 542w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/f73270bd07bba4e4b81803120f474bcf/c0388/3gram.png&quot;
        srcset=&quot;/static/f73270bd07bba4e4b81803120f474bcf/12f09/3gram.png 148w,
/static/f73270bd07bba4e4b81803120f474bcf/e4a3f/3gram.png 295w,
/static/f73270bd07bba4e4b81803120f474bcf/c0388/3gram.png 542w&quot;
        title=&quot;trigram&quot;
        alt=&quot;trigram&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;p&gt;Pretty good! increasing the number of words we reference:&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 195.2702702702703%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAnCAYAAAAPZ2gOAAAACXBIWXMAABYlAAAWJQFJUiTwAAAE7UlEQVRIx61VaUycVRSdgalWkmqlWkmQGBvElIIWxJKqlNIhSkGkoYZCayk4MGVRWQttWkWMSUOqDQydWkjBH4IYt0bTH9YFWaKWCfu+l71shSaUEGjhOOfZb9hmmGr9kpv7vvu9d+655943I5PJZPifTQa1Wo3a2lqUlpairKxslZWXlxtd00pKSlBZWQmtVrsImJOTg/t9WltbFwEzMzNFsK6uDtXV1ejs7BS+qakJOp1ObK6vrxexjo4OEauqqhK+pqZGnCVLA6BGoxHBmzdv4vr16xgZGcHo6KhYDw8PY2BgANeuXRN+bGwMQ0NDuHHjBm7duoWpqSlxlskMgFlZWSLIj83NzRgcHER3dzdaWlqEb2xsFCzb2trEt/b2dkxOTooz8/PzqwElhiyZh1leV1cXent7BSjXfX19gjnBKAXXs7OzuH37tmlAsunv7xeeB6anpwUTlkgJGKMMfKc8MzMzxgGzs7NFkAKzJIJSZDaAzMi8oaFBMCU7Mlv5GGXIcig+GZIFS2YjCMQkZMeE9GTMZHyXyBjVkAzoubGnp8egGw8wAUHInAkZZ7MWFhbExVgFyA5zA1mRpQTKg2wUy+aM0qRpYMwkIDcwM1mRDcuSZo5rxjiX9JSAjeFekyUzKzNys9Rtgkma0ksjxXGSZtBkUwgoNYUmMWHJBGH5jNFTGt6aNQebYnMzbwQZUQJJBgJJ15IsCcg19TM5h7wlUjlsDDtKIwCNd3flc+fOHdMM2T1p9lg6jaxYNr9NTEyI+z4+Pi482a0JyBlk+1k6S5LmksCUgXKQKeOMmWUo/aoQhE0x95hlSBbMTB1ZKjebMnaXNjc3J87yB3cV4P08lMIAaGdnB6VSiV27dsHT09Ngu3fvXmXc5+LigtzcXBQXF8Pd3R3e3t5wdnZeBPwvZm//DDY8/Ijxv1G5XA4LCwuzZmlpYTiosJRh3Tq54X3Jt3/HzHazNaIO70TFlRhU/BSD7NNvwGbzBvxD7B4B5Xf91i22iD3oC82JMBRpVGi/moDxtlP4sSAU6x9U3BtDhUIBq4fWi/UrLs9Ce1IF7fEj+DRVjYvZCfjqQhDqf4+Dzx4H84AKvS7u2x3x2KZN4v24KgB5aWp8kqJC3rkzOJscj/Rgf2ScCoSTg415wI0brHBSHQi357fB5vFH8fE7ISg8G46SH95D8c85+O7LfGSdiIfHTldIzTUKePcD3LZtQVHGu4gN9kHAHndEBPrgSpEa3ZWJKP3+CHTFKTh88HVYPaBYPjamAGMOvIqC07FIDgvAIT8lQnyVuFzwNnprUnApLwxRhzzhZG+7tMNrAx4L80deehQO+u1B5Jt7sU/pgZJLRzFQn4pfvolEoLeXvlFO+hmVm2G4ZEx8XnZFSvg+nDuhQkKYH/64HI3BhlR8oQmFm6MjLORGbooxk7L6emxHob5sAn77mX72KhJFyelJ/vrvFsavnqmSn3zCGhfej8D5UyqkRweh7FI0OnVJ6NIdw37fF5YlNgloaSk3bIo7tFc0Jf4tf4Tv90LrnwnouJqE6l/jsOM5h5XNWA5ovdHKoJ3Q72lb5H8Uhdy0CEQH+SIp4jX89rUabX8lolAbihe3bTUGBpkUfMntKaQleyM5xhMHAlwQHazExQ+PIveDSGQkhiArLRD5GSH4/EwwokJ84LXD1aj2fwO6mqMjrTcRjwAAAABJRU5ErkJggg==) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/2b8d20ea7d6509aeda829807440bb282/12f09/4gram.png 148w,
/static/2b8d20ea7d6509aeda829807440bb282/e4a3f/4gram.png 295w,
/static/2b8d20ea7d6509aeda829807440bb282/07484/4gram.png 540w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/2b8d20ea7d6509aeda829807440bb282/07484/4gram.png&quot;
        srcset=&quot;/static/2b8d20ea7d6509aeda829807440bb282/12f09/4gram.png 148w,
/static/2b8d20ea7d6509aeda829807440bb282/e4a3f/4gram.png 295w,
/static/2b8d20ea7d6509aeda829807440bb282/07484/4gram.png 540w&quot;
        title=&quot;ngram&quot;
        alt=&quot;ngram&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    

      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 166.8918918918919%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAhCAYAAADZPosTAAAACXBIWXMAABYlAAAWJQFJUiTwAAAE9ElEQVRIx61UCVCUZRhelmNZnJZlWVjM0XIcygmDmSI1B0FBORJRlE3kZoFFQR1WWKAEiYkEC4iVZNRsDNF0KmSy6Z6ymCJB4xJh5BJIBPEAEUEEfPrfDxflWhinb+aZ7/jf7/mf9/p4ZmZm6O/vx/8xsrKywJNIJIyQ0N3djd7eXvT19bH13bt32f7evXtsff/+fban+c6dO2PfBwcHGWF2djZ4pHBgYAAdHR2oqalBSUkJamtrUVlZierqaoaKigpcunQJDQ0NKC8vx7Vr19g52RGGhoaeKNS6/ODBA7S2tjJjutjT04P29nZ21tnZyc4J169fx40bN3Dz5k0G+k52kxSSW1euXGFkLS0t7Ky5uZkpuXXrFiO5evUqU0Qz4fLly6irq2N3JhHS3+rr6xlJW1sbqqqqmJt0kdykENAZ/Yzi29jYyMgpHHR3XFIoyOQyBZlw+/ZtZtTU1MSUkZvkNq21NpQUsunq6mLhGaeQskouk0L6I7lQXFzMVJAqco2UXbx4cUwVnZeWlrJ7jx49Gq/w4cOH7GB4eBgjIyNsTTOBSoKyqN0/Pch1bcnQ0Gg04IlEIuaa1g0ymjhPPNNCK4JKjlQmJSWBxw2YmprC0tISUqkUFhYWOkF2YrEYNjavcC6fh4ODA0iUTCaDoaHhKOGzwMhIAKmFbKpvows9PT2d4HHg0/zY3lhgAKnEGEJjo7H74whni+dMhPBwskFRfgAqzu3Cz18poAxaOlnhbGBuOgfhPmuREiVHfkYE/jwbiY6aRHTV7kFU6LLZEZIrQmMBW8+zlCBD5Q9NQjDyEkORk6FGUYECvxaGofibSJiKjHUT6nF4dfEiSM0lbL/R2R75aVHIUYfgYOpu5GYkIy1Ajvej1yEndSPEIqFuwjlCAWICPfGarQ0EAiMkKDbgaGoETueF4GxhDr49ewaHk/bgvehgWFsvmN5lbcYWL3wen6dth8LbGW/avYxgr7X47MNAtFbGofTHSFT+EY9TX6TD12sN80YH4egcunEVTmbsQJLSB2GbXBHo6QpNqhz/ViXg3JlIFGi2YKdiJfh8/dllOWXbZpxIj8b2LW/Bx80J650ccTRzK1or1Ggqi0NchDvWcZ1i/YKVbkKtfIX3KiRHyiHnyParAiB3XY2CXH+0Vcaj9q8YqMI8sdx2CUweF/eMCimWNovmIyc+CJ+mKJGu8sXvRUpOYTz+/i4aHo5vTN9602HnVjcU7ItCbqICpzQKNF6IRUu5Gt+fjIBEJJ7Ydk/18lMk2p5dYfcSqzsq5Bh/L/zAkdSf342Wf9Q4uE8OPs9gZoV8vt7jnjXG/hg/VjYxAevhvWYFyn7agaYLcWgsi4Uq3BX6fMOpCY0M9bFgntm4D85Ll+D4B1E4lBwGdYg3YkLc8PXhIBa73wqV8PNcDalYNDWhgT4fu8JX4NiBzfgkfQNU21biXaUXjnCJOJISgY9iuf7duwlH032Rz5XN7jB3LvMukJmbTafQAIHey/BlXhh+ObEDxzKDkRnnz6kLxwEuGR+/swXHs/1wOjcIabFe8PVwgaO93XSJfLIRGgmxQGaFeRZzoeJ6+FByBLZvdUHOXm8GHw9bWEjEeNvdGS7LX5+YXd1lY2+zEEq5G16cbwWpmQn3hD1JgEwq4WI+F4YGs8jy2JNPaz6fW/PH9bjezA/xzC+19rGYDf4DwzN0ktjzAhMAAAAASUVORK5CYII=) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/56da2c78e8a0a94c2008364c859f63c1/12f09/5gram.png 148w,
/static/56da2c78e8a0a94c2008364c859f63c1/e4a3f/5gram.png 295w,
/static/56da2c78e8a0a94c2008364c859f63c1/29f4e/5gram.png 506w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/56da2c78e8a0a94c2008364c859f63c1/29f4e/5gram.png&quot;
        srcset=&quot;/static/56da2c78e8a0a94c2008364c859f63c1/12f09/5gram.png 148w,
/static/56da2c78e8a0a94c2008364c859f63c1/e4a3f/5gram.png 295w,
/static/56da2c78e8a0a94c2008364c859f63c1/29f4e/5gram.png 506w&quot;
        title=&quot;ngram&quot;
        alt=&quot;ngram&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    

      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 188.51351351351352%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAmCAYAAADEO7urAAAACXBIWXMAABYlAAAWJQFJUiTwAAAFMUlEQVRIx51WC1CUVRhlWRUWDaTBQETlJVKmppFoPvCVEuoWsK4DwvLGRWkBF8VHpCBpk04zqKGgWFPpZOrUNDnZjJJNzuRUvEUReYiA4HvQGR8jcNpz138V3V3If+bj3vvde8/9znfP/RYbGxsbKBQKeHt7w8vL66XM19cXbm5uIJYN/yQnJ4Pfw4cP0dXVJezx48e9WnN+2v3798XesrIy2NnZGQEzMjKE886dO7h+/Tpu374t+rdu3cLdu3dFS7tx44bJ39nZiXv37kH66urqMGTIECNgWlqacF68eBHV1dUoLS1FW1ubGFdVVQlfRUUFzp07J8bss21oaDABXrhwAYMHD+4NWFtbi0uXLqG9vV2A0VpaWkTLufPnz6O5uVmsaW1tRU1NjZi3CNjU1CQ2Xr161QRCAG5mxGxJmweS8pUrV3Dz5k3rgDyVdJgTGgH78/HwFwDr6+vR2NgoQBgRqbHPiC9fviyiop9j5o8R9vT0WAZk0gnCSQIwWo5Jp7Ky0pQ/poNjzpuNUKfTCSdzRD1du3YN5eXlYoN0GQSRGHR0dIg55tMqZWpQokxapESKbHmbnGdLIDLgGurU4qUwEl4EoyMwN0t0CcyWF8c5SY88xCIgARg6ZUF6PIA+UmR+GRHTQv+jR4/Enu7ubsuUJR0yh6TNUxkZKTKH7EtC5zvmx3dtEZBPjCDSK2EklId046RMkwoCJSMBc60JUK/Xm8J/8OCBoMPFbFmBpMoijSXtSdHxY15NxUGj0QjRMj/MF415NNenkTorEj/mldWnpKTkafmSy+UYNmyYMBcXF2HP96Wxq6ur2JiSosX+/fvg5OQofI6Ojk8L7MuYfIDC0pyxI5PJ+mVca68YgMkT3DBlkgdedXYQPltb2f+PUC63xYQxo7ExNRjVp9PRUrEWZ39diZB5Y42gxgP7BnqyEGM9h0Mf+wE+z4jG7uxY/Hk8FU1lmag5kw4/H5f+RejgoIDjK0IOmDbRD0WbklGwPhY7P9Zix5YM7N6kxO9HkxCtmtw/wPdnBcDbc5Tob0wKRfHmZORnJ+Cb4j0oytuCbRFqpK9YhNEjnPsGtB80ENvSIhC2YDo8PVyhi1yCw7sSUHFah7OnPsWp34qRn7cO0wPGW8+hdJvvjPPBoc9SsT4hFBrlHCwPmYejRbFoLl+DEwejcPJIHMKUM83LxhxgjDJIAK6JC4VqQRDUC+fgcKEGbdVZOHUkGRGLZ2L6W/79B1y2cBp2b0jAsuDZWBsfBtV7QTj+XTzaqrLwx09aqIPnYpL/mGc1aD2HDvaDMN6gu9xVauwz3G7OR+E487MWrQbAQwUxeN3L2/JLeUF7T05duiAQBw20d2bF48fCJNT/o0drZRZyM5cY18qsAMpkvYXsO8oNxTkrkJ8VC73GoLdjWtSdXY2Gv9cgKmzq80/OeoQEz4pX4tutq5C2fDHUITNQUaJD47+ZKD2pQ9CUN60XhxFujvAY7mSIzlaM/UYPx4FcLQo/ScSGRBXWaUPwQ4EGf/2yEvt3RGL+1ABz0RlS8ITmxDfccexANE58H4+v8tXISVNib3aSuIzt+kjs2hyOr7dHYm+eGjEfzsfcwLf7iPA1ZyQtm4kvNqiRt1qF7JRwA2CiASwae3IicOTLGBRuXYq48FmIXLQQPiPde+XdYg5tZXLIbAZgdsA47NushSo4EClR7yJOFYiR7kMNUlJAOXcG/H08+yiwzwha/N9tNxAB4/3gPNTphU2DDG/c3vj70T8dmqEhpGTO/7z9B43MudFRObyhAAAAAElFTkSuQmCC) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/66c7aab144b3ab93b80b8514581923b4/12f09/6gram.png 148w,
/static/66c7aab144b3ab93b80b8514581923b4/e4a3f/6gram.png 295w,
/static/66c7aab144b3ab93b80b8514581923b4/76aed/6gram.png 546w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/66c7aab144b3ab93b80b8514581923b4/76aed/6gram.png&quot;
        srcset=&quot;/static/66c7aab144b3ab93b80b8514581923b4/12f09/6gram.png 148w,
/static/66c7aab144b3ab93b80b8514581923b4/e4a3f/6gram.png 295w,
/static/66c7aab144b3ab93b80b8514581923b4/76aed/6gram.png 546w&quot;
        title=&quot;ngram&quot;
        alt=&quot;ngram&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;p&gt;Woah, that last one seems a bit too on the nose doesn’t it? That’s because it’s directly lifted from the source.&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 15.54054054054054%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAjElEQVQI1z2NXQ7CMAyDd6Y2vytIjIF4AcYQ97+KSYLEg2X7s5pOIgJ3h6iCiJCdmX8scu+9PLfkZg4KJ+LqrbXa1az6RGOBXN/g9Yl+Tm3lcnkF3ytz5Ha6oy2PYrxuwXZQeCo3vX3QD2sczJ/UYfOAjyPUZ0iI1UCitamPUubkFlls/rN8Q8F73PoCZr5kuAU2wA8AAAAASUVORK5CYII=) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/f9c9fdd09306e8d0b8efe0ccf6d8b99b/12f09/corpus.png 148w,
/static/f9c9fdd09306e8d0b8efe0ccf6d8b99b/e4a3f/corpus.png 295w,
/static/f9c9fdd09306e8d0b8efe0ccf6d8b99b/fcda8/corpus.png 590w,
/static/f9c9fdd09306e8d0b8efe0ccf6d8b99b/efc66/corpus.png 885w,
/static/f9c9fdd09306e8d0b8efe0ccf6d8b99b/c83ae/corpus.png 1180w,
/static/f9c9fdd09306e8d0b8efe0ccf6d8b99b/49b61/corpus.png 1756w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/f9c9fdd09306e8d0b8efe0ccf6d8b99b/fcda8/corpus.png&quot;
        srcset=&quot;/static/f9c9fdd09306e8d0b8efe0ccf6d8b99b/12f09/corpus.png 148w,
/static/f9c9fdd09306e8d0b8efe0ccf6d8b99b/e4a3f/corpus.png 295w,
/static/f9c9fdd09306e8d0b8efe0ccf6d8b99b/fcda8/corpus.png 590w,
/static/f9c9fdd09306e8d0b8efe0ccf6d8b99b/efc66/corpus.png 885w,
/static/f9c9fdd09306e8d0b8efe0ccf6d8b99b/c83ae/corpus.png 1180w,
/static/f9c9fdd09306e8d0b8efe0ccf6d8b99b/49b61/corpus.png 1756w&quot;
        title=&quot;corpus extract&quot;
        alt=&quot;corpus extract&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;p&gt;So here lies a decision we must make. The more fluent we want our robot to be, the more previous words we want to use to predict the next words. However the more words we use, the more we directly lift from the source text. I find that a good number of previous words to look back on is between 1 to 3. You can try the &lt;a href=&quot;https://httpserve.tenzhiyang.com/gumshoos/&quot;&gt;gumshoos speech generator&lt;/a&gt; with 2 previous words (bi-gram).&lt;/p&gt;
&lt;p&gt;That’s three different case studies of analyzing three different AI solvable problems, (mis)quoting portal: now you’re thinking in AI, with this Part 1 I hope you manage to gain some insight on how people approach real world problems and breaking them down into numbers, then trying to solve it in one of the three above methods. It comes with practice and there are definitely more than one way to categorize, make decisions or generate problems, so keep at it, get to know more AI tools available and you can eventually make great AI applications in a short period of time!&lt;/p&gt;</content:encoded><content:raw>
**This article is a complement to my presentation in React Knowledgable.**

## Introduction

Artificial Intelligence is all the rage now, with the craze starting from Deepmind&apos;s alpha go. Although I hate people for misusing the terms &quot;artificial intelligence&quot; and &quot;machine learning&quot; for things that do not need AI and ML to solve, I do think that using AI reduces the time taken to solve certain problems, and also can add some &quot;WoW factor&quot; to an idea. I hope with this article (and subsequent presentations) people will understand what kind of problems that AI can solve, and maybe make AI more approachable so that the overall quality of hackathon projects improve.

First off, a disclaimer: **I am by no means an expert in AI. I do have an undergrad level understanding of artificial intelligence, but I was never great at it.** Feel free to correct me on any wrong concepts that I write in this article. I will also try to explain AI in English and not technobable, so for the real AI masters out there, you might cringe at me using wrong analogies or even butchering terminologies in an attempt to make AI easier to understand.

My motivation for this article stems from two comments that irks me. These (paraphrased) comments come from people who I think are smarter and better engineers than me. We are all front end engineers, and I can understand why they said it, but all these were in the context of Hackathons, and I feel that it&apos;s a shame for people to be limited in implementation just because AI seems so daunting.

&gt; You can use my idea because I don&apos;t know how to build it

This came from a very creative person whose idea not only allowed me to win the second prize, they also won a consolation prize in their idea. People say ideas are cheap. That&apos;s half true. Yes, there is likely someone else who stumbled across the same idea and has the skills to implement it, but really most of the time we already have the capacity to build this idea, we just don&apos;t know it yet. 

&gt; I wish I did more AI related things in University, I feel like I missed out

This is **the** comment that prompted me to come up with this article. I always wanted to present something about AI to my team, given that I do have *some* understanding of AI, but someone else did an introduction to Neural Networks that was more detailed than what I could come up with and I felt that that person would be more suited to carry on doing AI related talks. However from this comment I realized that **because** I am kinda shit in AI, but yet I know how to **use** AI libraries, I can add value to this topic. 

So here&apos;s what I hope people will gain from this article:
- Approaching Problems with AI
- What algorithms are good to google
- What can we achieve with just a surface level knowledge of AI
- Famous APIs that we can use for the next hackathon/prototype of things that we wanna work on

Here&apos;s what I will **not** go through
- How Neural networks work
- How to build an AI from scratch
- How to beat the no.1 go player with AI
- How famous algorithms work
- How to win a hackathon with AI

Mostly because I don&apos;t know the answers to any of the above.

Now this article will be written with FE developers in mind, with introductions to Javascript libraries. Many people would say that there are a lot of better languages for AI development and I entirely agree. There are some benefits to do AI in Javascript. Firstly, there&apos;s always the Nodes argument: your entire stack can be the same language. Whatever flavour of JS you are using, you can easily switch over from one to another. This is great for a quick prototype and/or proof of concept to show that your idea even works in the first place. Secondly for the users, you can have the entire script running on the browser. You can write some application once and run it anywhere, you don&apos;t have to worry about scaling as all the computation is running on the user&apos;s device. This also means you can have your application running offline, with PWAs. I think this is one of the strongest points we have for AI running on browsers. Finally, in terms of performance, JS is not much behind python, in some cases it might even been faster. It&apos;s really only a matter of time before the tools available for JS catches up to Python as the JS community grows larger and larger.

## What is AI

There are a few definitions of what AI is, and many of us get confused about the terminology. What is Artificial Intelligence and what is Machine Learning? Are they even different? The most sensible definition I found is that Artificial Intelligence is `Simulation of human thought processes in machines.` I find this to be very accurate. AI can be as simple as a bunch of if-else statements (that&apos;s essentially a `decision tree`) or something as complicated as simulating a brain (`neural nets`). Machine learning is a subset of artificial intelligence, and basically what ML does is to write a program to find patterns in data, without being explicitly written which pattern to recognize.

Now in my own understanding, we really just want to solve three different types of problems:
- Categorize things
- Make Decisions
- Generate things

These groups of problems are actually not how actual AI-savvy people group them, but I find these approach of grouping problems easier to use to visualize solving some problem with AI.

These problems have to be represented by some form of data, so that&apos;s something that usually requires some level of intuition and experience, but after a while you might start recognizing certain methods people use to represent different data. For now, let&apos;s assume that all real world data come in the form of numbers stored in some variables.

## Categorising problem

For the first type of problems, we can imagine a mathematical function. Suppose we want to guess: given a Merge Request (Pull Request) how many people will actually do a MR vs giving a &quot;free&quot; `LGTM`? In this case, maybe a point of interest would be the length of the MR by lines of code changed. We can expect that with more lines, the more likely people will `LGTM` it without reading it. Now maybe a second point of interest that we want to do is how many files have been changed. Now if there&apos;s very few file changes, the code change is easier to understand, and people will tend to actually review the code compared to MRs with lots of file change. So we end up with something like this:

![datapoint](./datapoint.png)

So what we want our algorithm to do is to draw some line such that everything above the line belongs to `LGTM`-ed category, and everything below the line belongs to the `actually been reviewed` category. So we pass these data into some categorizing function and it will generate a best-fit line. Now whenever we want to categorize a new MR, we just plot it on the graph and check its relation to the said line like so:

![new datapoint](./newdatapoint.png)

But that is just two variables, what if we want to have a third variable? Like for example, how near is the deadline? The nearer the deadline, the more likely someone will skim through it, the further it is, the more likely someone will read it through. Well for 3 parameters, we can actually visualize it as a point in a 3-dimensional space. Instead of a line, we will separate the data set with what we call a plane (that is, a 2-d surface that extends indefinitely), like so:

![hyperplaneplane](./plane.jpg)

If we add another variable? Easy! Make it four dimensional, or five, or six or however many variables you need. In ML we call these variables `parameters` and we call the thing separating the different categories the `hyperplane` (subspace whose dimension is one less than that of its ambient space). Not all categorizing algorithms work like this, but this is a way to visualize your problem that you want to solve.

## Decision making problem

Next kind of problem, we have decision making. Essentially, given some number of choices, we want to be able to choose the most desirable option. A case study for this kind of problem would be something like a Tetris playing bot. Let&apos;s establish some rules of the Tetris that we&apos;re going to analyse. This will keep our problem scope smaller and easier to analyse.

- your score is how many lines you clear (one line, one point)
- how fast you make the move doesn&apos;t matter
- you only know the current piece, and the current state of the game

So let&apos;s think, how we would want *a robot* to play this game. I added the words *a robot* there for one simple reason. We don&apos;t want to care about things that will affect us emotionally. We are aware that the game gives us four points if we clear four lines in one go, and four points if we clear four lines individually, but for us it will feel so much more satisfying if we were clearing four lines at one go. Similarly, we don&apos;t want the robot to care if making the optimal move makes the state of the game look &quot;ugly&quot;, we only care if its the best move at the current point in time.

What we&apos;ll do is given a current state of the game, we want to place the moves in every single possible(legal) ways and then use some method to gauge if a move is good or not. So what is this method? We will take the state of the game, and then come up with some numbers to represent a desirable trait or an undesirable trait. We will then sum up the desirable traits, and minus the undesirable traits to get a score. These traits are known as `heuristics`. Heuristics give us some interpretation of how good a decision is, and more importantly, they are usually fast to calculate. Of course, some traits are more important than others, so we need to multiply them by some constant value. These constant values are called `weights`. We can throw the weights into some classification algorithm to optimise what number is better, so we don&apos;t need to care about what the numbers are for the sake of this article.

Let&apos;s think of the first heuristic we care about. Of course we want to clear lines, and even though clearing more lines doesn&apos;t give us more points, but it makes the game last a little bit longer, so let&apos;s just count if there are lines cleared or not this turn:

![linescleared](./linesclear.jpg)

Next thing, we want the robot to play as many moves as possible, so that it has the most chances to clear lines, we don&apos;t want the bot to make an optimal move it that ends the game right now. So let&apos;s take something like, the current height of the game like so:

![height](./height.jpg)

Now this is good, but suppose we have just one line that&apos;s really tall but doesn&apos;t lose immediately, that&apos;s not entirely bad right? So maybe we can do something better. instead of just height, let&apos;s sum up the height of each individual column, like this:

![colheight](./colheight.jpg)

Finally the biggest bane of Tetris is to have a &quot;hole&quot; right? it&apos;s bound to happen but we want to reduce the number of holes. Lets count the number of holes and then multiply it by a some negative weight:

![holes](./holes.jpg)

But it&apos;s not necessarily just holes, overhanging piece will eventually create holes (assume no T-spins and no &quot;sliding&quot; at the bottom) so we want to count that as well. And a hole with more overhang is worse than a piece that just overhangs. So let&apos;s do something like this:

![overhang](./overhang.jpg)

If we look at the previous two, isn&apos;t the hole count really some subset of the overhang count? So maybe we can do something better. How about if starting from bottom, we add a count every time we go from &quot;solid&quot; to &quot;gap&quot; this way we can actually detect when there are a lot of small gaps, as small gaps take more moves to solve but big gaps could be solved easier.

![bumpiness](./bumpiness.jpg)

But I think we can do better. This heuristics takes care of how many gaps there are in the same column, but it doesn&apos;t really have a big picture representation of how sever a gap is. A gap with many bends is much harder to solve than a &apos;smooth&apos; gap. A heuristic that can take this into consideration could be something like how many 90 degree bends there are in the state.

![bends](./bends.jpg)

Summing up the heuristics and then multiplying by some constant weights to them, we have something like:

$$
c_1 * linesCleared + (-1 * c_2) * sumColHeight + (-1 * c_3) * numBends
$$

So now we have a bot that analyses Tetris like how an almost perfect human would, except the analysis needs to be weighted. All details aside, we can look for some algorithm that takes in $c_1, c_2, c_3$, runs a game of Tetris, gets the score, modifies $c_1, c_2, c_3$ a little bit and runs the game again. rinse and repeat until $c_1, c_2, c_3$ is fairly stagnant, or you don&apos;t have time to train anymore. In university my teammates used a library which provided something called `particle swarm optimization` which brought my team&apos;s AI score up from ten thousands to millions just by running a optimization algorithm on the weights.

## Content Generation Problem

For the final type of problem, unfortunately there are too many different ways for different domains. Generating an Image is quite different from generating sounds or text. There is some headway being made in the form of neural networks which pit two neural networks against each other, but that&apos;s a whole new article and presentation. However for text generation, there are some probability-based state machines (known as `Markov model` or `Markov process`) that is easy to program, and also gives us reasonable results.

I won&apos;t go through the process of writing a `Markov model` but the general idea for text generation will be something like. &quot;What is the most likely word to appear next, given that the words before are `a` and `b` (and `c` and `d` etc etc etc..)?&quot; So what we will do is to find a markov model, and find sufficiently big data set. An example that I want to use is something like a Donald Trump text generator. 

First things first, I need a data set. In the domain of Natural Language Processing, we call a file with lots of sentences a corpus, so I found [1mb worth of trump speeches](https://github.com/ryanmcdermott/trump-speeches) from [@ryconoclast](https://twitter.com/ryconoclast). We can do some cleaning up of the data, like changing all text to lowercase, and grouping words that come from the same word together(`stemming`, eg: consultant, consulting, consults -&gt; consult) but I won&apos;t be using it for my example, just to showcase how decent the results are without much effort.

After finding [a tutorial on how to do exactly trump speech generators](https://medium.com/@corrigan1247/how-to-imitate-trump-with-markov-chains-8224877dcf69), I passed in the entire text file into the function, added some checks to make my generated content at least 20 words long, and this is my result:

![bigram](./2gram.png)

Not too bad, but a little bit random right? If you did read through the tutorial on building Markov chains, you might guess why. If not, the general idea is that we are only looking at some word `a` and getting a list of words that come after `a`, and choosing a word randomly from there. This is kinda funny but not really as fluent as we like it to be. So I did some modifications and made it such that we get a sequence of `x` number of words to generate the next one. So here&apos;s one where we look at the previous 2 words:

![trigram](./3gram.png)

Pretty good! increasing the number of words we reference:

![ngram](./4gram.png)
![ngram](./5gram.png)
![ngram](./6gram.png)

Woah, that last one seems a bit too on the nose doesn&apos;t it? That&apos;s because it&apos;s directly lifted from the source.

![corpus extract](./corpus.png)

So here lies a decision we must make. The more fluent we want our robot to be, the more previous words we want to use to predict the next words. However the more words we use, the more we directly lift from the source text. I find that a good number of previous words to look back on is between 1 to 3. You can try the [gumshoos speech generator](https://httpserve.tenzhiyang.com/gumshoos/) with 2 previous words (bi-gram).

That&apos;s three different case studies of analyzing three different AI solvable problems, (mis)quoting portal: now you&apos;re thinking in AI, with this Part 1 I hope you manage to gain some insight on how people approach real world problems and breaking them down into numbers, then trying to solve it in one of the three above methods. It comes with practice and there are definitely more than one way to categorize, make decisions or generate problems, so keep at it, get to know more AI tools available and you can eventually make great AI applications in a short period of time!
</content:raw></item><item><title><![CDATA[A race condition in react-redux]]></title><description><![CDATA[TLDR: file that used to be on code base became an API, listen to value changes on redux and send another fetch if neccessary  Recently I…]]></description><link>https://blog.tenzhiyang.com/2019-07-19-a-race-cond-in-react-redux/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2019-07-19-a-race-cond-in-react-redux/</guid><pubDate>Fri, 19 Jul 2019 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;&lt;strong&gt;TLDR: file that used to be on code base became an API, listen to value changes on redux and send another fetch if neccessary&lt;/strong&gt; &lt;/p&gt;
&lt;p&gt;Recently I faced some problems with a component not appearing on live, despite no changes in the component’s code for maybe months! It was very frustrating as this bug only happened in live, and not in staging, not in test, not in UAT. In fact even when I ran the code locally using live data, I could only reproduce the bug maybe once every ten tries. Now this blog post is something I’m trying so maybe it will be too vague because I can’t reveal company code, but I want to try to explain big picture concept without too much details.&lt;/p&gt;
&lt;p&gt;The major problem I had was due to a site-wide refactor. We had a list of constants that we would use to decide what to show, depending on which locale it was in. Super useful! Naturally, in order to turn some features on and off, we had to change that constant via some tool, and then re-deploy to production. It works, there’s no need to touch the code base,  and now we don’t need software engineers to turn on and off features. Natural progression led us to improve this design. Of course, we want to turn features on and off without waiting for another deployment, so therefore this file should just be deployed as an api! We can fetch this file as and when we need it! Brilliant!&lt;/p&gt;
&lt;p&gt;Except we just created a race condition. Turns out, some logic requires us to alter our fetch in some way due to said toggles. This resulted in my component not displaying anything. Now there were several problems in the component design, either due to legacy reasons, or maybe lack of experience. If we had the time and (mostly QA) resources, we might have wrote this component some other way, but that’s not really the root problem. We need a fix quickly, and then maybe down the road we can fix the architectural problems.&lt;/p&gt;
&lt;p&gt;Some issues with the implementation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;we used the fetch parameters as keys in our redux store so that we could store multiple results from the same api&lt;/li&gt;
&lt;li&gt;fetch parameters was generated using the value from the file, which became the API&lt;/li&gt;
&lt;li&gt;the result from the file value would go through some util and would fail gracefully, when the params were to go into the fetch, we would assume nothing is wrong&lt;/li&gt;
&lt;li&gt;the generated fetch key and the key used for display were calculated at the point and time where they were needed&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The best solution I could come up with in a short period of time was to send another fetch when the value retrieved from the util changed. What this means is that if we sent the fetch on an &lt;code class=&quot;language-text&quot;&gt;UNSAFE_componentWillMount()&lt;/code&gt; (on legacy code) we should check the prop changes in &lt;code class=&quot;language-text&quot;&gt;UNSAFE_componentWillReceiveProps()&lt;/code&gt;, and then send another fetch based on the next props, compared to the current props.&lt;/p&gt;
&lt;p&gt;In cases where we use &lt;code class=&quot;language-text&quot;&gt;getDerivedStateFromProps()&lt;/code&gt;, we don’t have access to the current props. In this scenario, I had to make a copy of the what I need to listen to into the current state, and on next &lt;code class=&quot;language-text&quot;&gt;getDerivedStateFromProps()&lt;/code&gt; I would have a copy of the current props to compare with.&lt;/p&gt;
&lt;p&gt;I think fundamentally the issue I’m facing is probably an architecture problem, but the way I solved it is probably the fastest and easiest way I know how. Do tweet at me if you have a better quick solution though!&lt;/p&gt;</content:encoded><content:raw>
**TLDR: file that used to be on code base became an API, listen to value changes on redux and send another fetch if neccessary** 

Recently I faced some problems with a component not appearing on live, despite no changes in the component&apos;s code for maybe months! It was very frustrating as this bug only happened in live, and not in staging, not in test, not in UAT. In fact even when I ran the code locally using live data, I could only reproduce the bug maybe once every ten tries. Now this blog post is something I&apos;m trying so maybe it will be too vague because I can&apos;t reveal company code, but I want to try to explain big picture concept without too much details.

The major problem I had was due to a site-wide refactor. We had a list of constants that we would use to decide what to show, depending on which locale it was in. Super useful! Naturally, in order to turn some features on and off, we had to change that constant via some tool, and then re-deploy to production. It works, there&apos;s no need to touch the code base,  and now we don&apos;t need software engineers to turn on and off features. Natural progression led us to improve this design. Of course, we want to turn features on and off without waiting for another deployment, so therefore this file should just be deployed as an api! We can fetch this file as and when we need it! Brilliant!

Except we just created a race condition. Turns out, some logic requires us to alter our fetch in some way due to said toggles. This resulted in my component not displaying anything. Now there were several problems in the component design, either due to legacy reasons, or maybe lack of experience. If we had the time and (mostly QA) resources, we might have wrote this component some other way, but that&apos;s not really the root problem. We need a fix quickly, and then maybe down the road we can fix the architectural problems.

Some issues with the implementation:
- we used the fetch parameters as keys in our redux store so that we could store multiple results from the same api
- fetch parameters was generated using the value from the file, which became the API
- the result from the file value would go through some util and would fail gracefully, when the params were to go into the fetch, we would assume nothing is wrong
- the generated fetch key and the key used for display were calculated at the point and time where they were needed

The best solution I could come up with in a short period of time was to send another fetch when the value retrieved from the util changed. What this means is that if we sent the fetch on an `UNSAFE_componentWillMount()` (on legacy code) we should check the prop changes in `UNSAFE_componentWillReceiveProps()`, and then send another fetch based on the next props, compared to the current props.

In cases where we use `getDerivedStateFromProps()`, we don&apos;t have access to the current props. In this scenario, I had to make a copy of the what I need to listen to into the current state, and on next `getDerivedStateFromProps()` I would have a copy of the current props to compare with.

I think fundamentally the issue I&apos;m facing is probably an architecture problem, but the way I solved it is probably the fastest and easiest way I know how. Do tweet at me if you have a better quick solution though!</content:raw></item><item><title><![CDATA[New blog, who dis?]]></title><description><![CDATA[So it all started out with a tweet  Nothing like telling everyone you’re going to do something to force yourself into totally doing it. So I…]]></description><link>https://blog.tenzhiyang.com/2019-07-07-new-blog-who-dis/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2019-07-07-new-blog-who-dis/</guid><pubDate>Sun, 07 Jul 2019 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;So it all started out with a tweet&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 61.486486486486484%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAABYlAAAWJQFJUiTwAAABpUlEQVQoz5VTyU7DQAzNZ/MFnOHOjRNHTogDEohDhQAVUKrSqinN1iyTpGlIszTLw55SKKgUsGLNZMZ+8Xt2lDAQODs9wWDQx2Siw7IsjEYaNE1DmqZga5oGbdv+yRXHtnB8dIhe7wkinGE+T5BlGeI4lkD/sbpuoKxfymUF1/UQzWYSbJ4k8HwfCa1CBAiCEFEUEQMbhmnKO59cCEF5rrxjU1qqIqtbChBUZQ+qqqLbfZCrSu+DwRDTqQPP82mdQtcN6IYh93zuOC4s20YYvgMScWTELKZK+OscJBMpaaXniKjUf6IsNeRNShXSg7woifoquai268e6bvV1UwgXC0LL8gKLjD2BbQ8x7j/C6nVwe3GOu6tLqA/30Cfar12XlF+pqmK5lKBlmSMMbETCQeqbmPafYb6MITyXJiBeAe4aGxnA/MmrbVoZwQbd9kOr7742JVuk6BIdlyrw/dUIOI6DmOcxz1GUJZZV9SVxE2DzjKVQ9BcNB/t7uOlcw6Qu81/CXf4Ao/nkgf0O8COg7CidcZfXlOvmsxrWlQN5dKqq3gnK9gaCu5yukaH82AAAAABJRU5ErkJggg==) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/7321e9c0a3a2fecec39c39b1b8deb8c1/12f09/tweet.png 148w,
/static/7321e9c0a3a2fecec39c39b1b8deb8c1/e4a3f/tweet.png 295w,
/static/7321e9c0a3a2fecec39c39b1b8deb8c1/fcda8/tweet.png 590w,
/static/7321e9c0a3a2fecec39c39b1b8deb8c1/efc66/tweet.png 885w,
/static/7321e9c0a3a2fecec39c39b1b8deb8c1/c83ae/tweet.png 1180w,
/static/7321e9c0a3a2fecec39c39b1b8deb8c1/e72de/tweet.png 1198w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/7321e9c0a3a2fecec39c39b1b8deb8c1/fcda8/tweet.png&quot;
        srcset=&quot;/static/7321e9c0a3a2fecec39c39b1b8deb8c1/12f09/tweet.png 148w,
/static/7321e9c0a3a2fecec39c39b1b8deb8c1/e4a3f/tweet.png 295w,
/static/7321e9c0a3a2fecec39c39b1b8deb8c1/fcda8/tweet.png 590w,
/static/7321e9c0a3a2fecec39c39b1b8deb8c1/efc66/tweet.png 885w,
/static/7321e9c0a3a2fecec39c39b1b8deb8c1/c83ae/tweet.png 1180w,
/static/7321e9c0a3a2fecec39c39b1b8deb8c1/e72de/tweet.png 1198w&quot;
        title=&quot;tweet i totally don&apos;t regret&quot;
        alt=&quot;tweet i totally don&apos;t regret&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;p&gt;Nothing like telling everyone you’re going to do something to force yourself into totally doing it.&lt;/p&gt;
&lt;p&gt;So I started working on this. Right now this is pretty much the default gatsby blog. There are some nice things coming over to gatsby from jekyll, the expressiveness of jsx over some templating engine is always nice. The &lt;code class=&quot;language-text&quot;&gt;automagical&lt;/code&gt; aspect of gatsby is in the source code, I just have to go and learn it.&lt;/p&gt;
&lt;p&gt;The build process on ubuntu has been far from great. None of the gatsby cli works on my ubuntu instance, maybe it’s my npm setup (I’m experimenting with asdf-vm). Right now I need to &lt;code class=&quot;language-text&quot;&gt;gatsby clean&lt;/code&gt; on my development machine, run &lt;code class=&quot;language-text&quot;&gt;gatsby build&lt;/code&gt;, commit my public folder, and host that on a http-server. Maybe I need to write some hack to make it better, maybe the solution exists, but I sure as heck couldn’t find it.&lt;/p&gt;
&lt;p&gt;I might publish another post explaining into more details what I’ve done with this blog and also the server this is running on, but for now I will focus on a few posts based on &lt;a href=&quot;https://twitter.com/devdevcharlie&quot;&gt;Charlie Gerard’s&lt;/a&gt; brilliant presentation from jsconf asia.&lt;/p&gt;
&lt;p&gt;Here’s a &lt;a href=&quot;https://httpserve.tenzhiyang.com/knnTransferLearning/&quot;&gt;sneak peek&lt;/a&gt; at one of my examples that I have in mind.&lt;/p&gt;</content:encoded><content:raw>
So it all started out with a tweet

![tweet i totally don&apos;t regret](./tweet.png)

Nothing like telling everyone you&apos;re going to do something to force yourself into totally doing it.

So I started working on this. Right now this is pretty much the default gatsby blog. There are some nice things coming over to gatsby from jekyll, the expressiveness of jsx over some templating engine is always nice. The `automagical` aspect of gatsby is in the source code, I just have to go and learn it.

The build process on ubuntu has been far from great. None of the gatsby cli works on my ubuntu instance, maybe it&apos;s my npm setup (I&apos;m experimenting with asdf-vm). Right now I need to `gatsby clean` on my development machine, run `gatsby build`, commit my public folder, and host that on a http-server. Maybe I need to write some hack to make it better, maybe the solution exists, but I sure as heck couldn&apos;t find it.

I might publish another post explaining into more details what I&apos;ve done with this blog and also the server this is running on, but for now I will focus on a few posts based on [Charlie Gerard&apos;s](https://twitter.com/devdevcharlie) brilliant presentation from jsconf asia.

Here&apos;s a [sneak peek](https://httpserve.tenzhiyang.com/knnTransferLearning/) at one of my examples that I have in mind.
</content:raw></item><item><title><![CDATA[Telegram ramblings]]></title><description><![CDATA[I have made it a point to write some of my ideas down on telegram, I will need to find a sustainable solution to update this list as and…]]></description><link>https://blog.tenzhiyang.com/2019-06-29-some-telegram-rablings/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2019-06-29-some-telegram-rablings/</guid><pubDate>Sat, 29 Jun 2019 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;I have made it a point to write some of my ideas down on telegram, I will need to find a sustainable solution to update this list as and when I write more stuff in it, for now I’ll just write the ideas down here&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;“who wrote this project” git crawler&lt;/li&gt;
&lt;li&gt;graph ui (basically the graphql of ui. write graph query in templating engine, generate ui?)&lt;/li&gt;
&lt;li&gt;slide controller using posenet&lt;/li&gt;
&lt;li&gt;shadow boxing guide&lt;/li&gt;
&lt;li&gt;Text to picture&lt;/li&gt;
&lt;li&gt;Electric ukulele visualisation&lt;/li&gt;
&lt;li&gt;Speech to text but with tone (represented with emoji?)&lt;/li&gt;
&lt;/ul&gt;</content:encoded><content:raw>
I have made it a point to write some of my ideas down on telegram, I will need to find a sustainable solution to update this list as and when I write more stuff in it, for now I&apos;ll just write the ideas down here

- &quot;who wrote this project&quot; git crawler
- graph ui (basically the graphql of ui. write graph query in templating engine, generate ui?)
- slide controller using posenet
- shadow boxing guide
- Text to picture
- Electric ukulele visualisation
- Speech to text but with tone (represented with emoji?)
</content:raw></item><item><title><![CDATA[Start of a new Era? maybe?]]></title><description><![CDATA[So maybe I will start blogging? This is part of learning in public from the really inspirational @swyx Here’s to many more bad blogs ahead]]></description><link>https://blog.tenzhiyang.com/2019-06-28-start-of-new-era-maybe-maybenot/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2019-06-28-start-of-new-era-maybe-maybenot/</guid><pubDate>Fri, 28 Jun 2019 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;So maybe I will start blogging? This is part of learning in public from the really inspirational &lt;a href=&quot;https://twitter.com/swyx/status/1009174159690264579&quot;&gt;@swyx&lt;/a&gt; Here’s to many more bad blogs ahead&lt;/p&gt;</content:encoded><content:raw>
So maybe I will start blogging? This is part of learning in public from the really inspirational [@swyx](https://twitter.com/swyx/status/1009174159690264579) Here&apos;s to many more bad blogs ahead
</content:raw></item><item><title><![CDATA[Post SEA hackathon 2019]]></title><description><![CDATA[This also spurred me to look into my 2018 success and write a blog about that. First thing out of the way is I won nothing and it sucks but…]]></description><link>https://blog.tenzhiyang.com/2019-06-23-post-hackathon/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2019-06-23-post-hackathon/</guid><pubDate>Sun, 23 Jun 2019 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;This also spurred me to look into my 2018 success and write a blog about that.&lt;/p&gt;
&lt;p&gt;First thing out of the way is&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I won nothing and it sucks&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;but the thing I realised about how it sucks here is that the way it sucks is a different suckage from how it used to suck when I entered hackathons. It sucks not because I didn’t win, not because I think my project was better than the other teams’ but mostly because of how hard we worked and how little results came of it. There’s a few ways of looking at this.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The idea just wasn’t presetable. I don’t really believe this is the case, as another group did something similar (but just better) and achieved great results.&lt;/li&gt;
&lt;li&gt;I am too unfamiliar with CNNs and transfer learning. This can be easily solved. I will eventually release a library that does all the heavy lifting for us.&lt;/li&gt;
&lt;li&gt;Our team composition and my delegation wasn’t good. I really think I lucked into my first team where I didn’t have to worry about whatever aspect that I delegated to. This time I think we should have maybe had one more backend and less FE devs. The AI was also kind of easy to implement maybe someone else would have been faster&lt;/li&gt;
&lt;/ol&gt;</content:encoded><content:raw>
This also spurred me to look into my 2018 success and write a blog about that.

First thing out of the way is

**I won nothing and it sucks**

but the thing I realised about how it sucks here is that the way it sucks is a different suckage from how it used to suck when I entered hackathons. It sucks not because I didn&apos;t win, not because I think my project was better than the other teams&apos; but mostly because of how hard we worked and how little results came of it. There&apos;s a few ways of looking at this.

1. The idea just wasn&apos;t presetable. I don&apos;t really believe this is the case, as another group did something similar (but just better) and achieved great results.

2. I am too unfamiliar with CNNs and transfer learning. This can be easily solved. I will eventually release a library that does all the heavy lifting for us.

3. Our team composition and my delegation wasn&apos;t good. I really think I lucked into my first team where I didn&apos;t have to worry about whatever aspect that I delegated to. This time I think we should have maybe had one more backend and less FE devs. The AI was also kind of easy to implement maybe someone else would have been faster
</content:raw></item><item><title><![CDATA[Post js conf]]></title><description><![CDATA[I’m writing this about 2 weeks after I’ve attended jsconf, so my memory will be hazy about everything. Here’s a few actionable things I want…]]></description><link>https://blog.tenzhiyang.com/2019-06-16-post-js-conf/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2019-06-16-post-js-conf/</guid><pubDate>Sun, 16 Jun 2019 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;I’m writing this about 2 weeks after I’ve attended jsconf, so my memory will be hazy about everything. Here’s a few actionable things I want to do after what I’ve learnt at jsconf:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Blog more.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This is really not too related to jsconf, but I did read &lt;a href=&quot;https://www.swyx.io/writing/learn-in-public/&quot;&gt;this brilliant post by swyx&lt;/a&gt; and it’s crazy inspiring. I’m not him and it’s unlikely I will be as active and as motivated as him, but I think this is a good way to be some inbetween, I may not be the second swyx or the second gaow, but at least I can be the first tenzy&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Play more with Tensorflow.js (and maybe git gud at AI once and for all)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://twitter.com/devdevcharlie&quot;&gt;Charlie Gerard&lt;/a&gt; made some really cool demos on stage, and after using the tensorflow.js in the hackathon (more on that next post) I realised that AI tools are so accessible now, I really should be doing more.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Participate more in twitter&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;particularly, write TILs for what I’ve learnt. Initally I wanted to do something every day, but I’m not really keeping up with it, so I will have to fine tune the frequency&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use more diverse frameworks&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The talk from &lt;a href=&quot;https://twitter.com/youyuxi&quot;&gt;Evan You&lt;/a&gt; made me rethink about framework loyalty. Every framework solving a different problem is such an obvious conclusion but the fact that I never reached there on my own makes me feel that I actually have some software engineering maturing to do&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Join community events more frequently&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It was after all the super silly hackathon that introduced me to this event and also the free tickets. Not to mention my dvd logo being plastered all over the event. I feel that there’s only good to be had from being in the community events, and in the worst case, maybe I’ll help someone&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</content:encoded><content:raw>
I&apos;m writing this about 2 weeks after I&apos;ve attended jsconf, so my memory will be hazy about everything. Here&apos;s a few actionable things I want to do after what I&apos;ve learnt at jsconf:

- Blog more.
  - This is really not too related to jsconf, but I did read [this brilliant post by swyx](https://www.swyx.io/writing/learn-in-public/) and it&apos;s crazy inspiring. I&apos;m not him and it&apos;s unlikely I will be as active and as motivated as him, but I think this is a good way to be some inbetween, I may not be the second swyx or the second gaow, but at least I can be the first tenzy
- Play more with Tensorflow.js (and maybe git gud at AI once and for all)
  - [Charlie Gerard](https://twitter.com/devdevcharlie) made some really cool demos on stage, and after using the tensorflow.js in the hackathon (more on that next post) I realised that AI tools are so accessible now, I really should be doing more.
- Participate more in twitter
  - particularly, write TILs for what I&apos;ve learnt. Initally I wanted to do something every day, but I&apos;m not really keeping up with it, so I will have to fine tune the frequency
- Use more diverse frameworks
  - The talk from [Evan You](https://twitter.com/youyuxi) made me rethink about framework loyalty. Every framework solving a different problem is such an obvious conclusion but the fact that I never reached there on my own makes me feel that I actually have some software engineering maturing to do
- Join community events more frequently
  - It was after all the super silly hackathon that introduced me to this event and also the free tickets. Not to mention my dvd logo being plastered all over the event. I feel that there&apos;s only good to be had from being in the community events, and in the worst case, maybe I&apos;ll help someone
</content:raw></item><item><title><![CDATA[Amp Slides]]></title><description><![CDATA[Having “volunteered” to give a talk about my experience in japan, I decided to make my slides out of AMP itself. By using handlebars…]]></description><link>https://blog.tenzhiyang.com/2019-05-28-amp-slides/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2019-05-28-amp-slides/</guid><pubDate>Tue, 28 May 2019 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Having “volunteered” to give a talk about my experience in japan, I decided to make my slides out of AMP itself. By using handlebars templating engine, I wrote &lt;a href=&quot;https://github.com/Tzyinc/amp-playground&quot;&gt;a tool that converted json into slides&lt;/a&gt; if i were to continue this project, I think I would write it in some proper framework and not use the completely uneccessary templating engine.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://httpserve.tenzhiyang.com/AMPslides/&quot;&gt;See the slides&lt;/a&gt;&lt;/p&gt;</content:encoded><content:raw>
Having &quot;volunteered&quot; to give a talk about my experience in japan, I decided to make my slides out of AMP itself. By using handlebars templating engine, I wrote [a tool that converted json into slides](https://github.com/Tzyinc/amp-playground) if i were to continue this project, I think I would write it in some proper framework and not use the completely uneccessary templating engine.

[See the slides](https://httpserve.tenzhiyang.com/AMPslides/)
</content:raw></item><item><title><![CDATA[JS Conf Animation: random tiled lines]]></title><description><![CDATA[This entry is for the programming nerds. 10 PRINT, a book about the commandore 64 takes one line of code to demonstrate the concept of…]]></description><link>https://blog.tenzhiyang.com/2018-12-24-js-conf3/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2018-12-24-js-conf3/</guid><pubDate>Mon, 24 Dec 2018 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;This entry is for the programming nerds. &lt;a href=&quot;https://10print.org/&quot;&gt;10 PRINT&lt;/a&gt;, a book about the commandore 64 takes one line of code to demonstrate the concept of generative art. It is incredibly simple for something that looks so amazing. This is literally only just randomised tiled diagonal lines.&lt;/p&gt;
&lt;iframe width=&quot;100%&quot; height=&quot;400px&quot; src=&quot;https://httpserve.tenzhiyang.com/tiledLines/&quot; /&gt;</content:encoded><content:raw>This entry is for the programming nerds. [10 PRINT](https://10print.org/), a book about the commandore 64 takes one line of code to demonstrate the concept of generative art. It is incredibly simple for something that looks so amazing. This is literally only just randomised tiled diagonal lines.

&lt;iframe width=&quot;100%&quot; height=&quot;400px&quot; src=&quot;https://httpserve.tenzhiyang.com/tiledLines/&quot; /&gt;
</content:raw></item><item><title><![CDATA[JS Conf Animation: Cantor Set]]></title><description><![CDATA[The idea for this entry was to hopefully spark a math nerd in the organisers.]]></description><link>https://blog.tenzhiyang.com/2018-12-23-js-conf2/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2018-12-23-js-conf2/</guid><pubDate>Sun, 23 Dec 2018 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;The idea for this entry was to hopefully spark a math nerd in the organisers.&lt;/p&gt;
&lt;iframe width=&quot;100%&quot; height=&quot;400px&quot; src=&quot;https://httpserve.tenzhiyang.com/cantor/&quot; /&gt;</content:encoded><content:raw>
The idea for this entry was to hopefully spark a math nerd in the organisers.

&lt;iframe width=&quot;100%&quot; height=&quot;400px&quot; src=&quot;https://httpserve.tenzhiyang.com/cantor/&quot; /&gt;
</content:raw></item><item><title><![CDATA[JS Conf Animation: DVD logo]]></title><description><![CDATA[The next few posts are pull requests for jsconf asia’s home page, hopefully they accept it and I get free tickets! The inspiration for this…]]></description><link>https://blog.tenzhiyang.com/2018-12-22-js-conf/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2018-12-22-js-conf/</guid><pubDate>Sat, 22 Dec 2018 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;The next few posts are pull requests for jsconf asia’s home page, hopefully they accept it and I get free tickets!&lt;/p&gt;
&lt;p&gt;The inspiration for this animation comes from the dvd bouncing logo meme.&lt;/p&gt;
&lt;iframe width=&quot;100%&quot; height=&quot;400px&quot; src=&quot;https://httpserve.tenzhiyang.com/dvdlogo/&quot; /&gt;</content:encoded><content:raw>
The next few posts are pull requests for jsconf asia&apos;s home page, hopefully they accept it and I get free tickets!

The inspiration for this animation comes from the dvd bouncing logo meme.

&lt;iframe width=&quot;100%&quot; height=&quot;400px&quot; src=&quot;https://httpserve.tenzhiyang.com/dvdlogo/&quot; /&gt;
</content:raw></item><item><title><![CDATA[Sew Many Images]]></title><description><![CDATA[100% JavaScript implementation for CSS image sprite generator. Use it now!]]></description><link>https://blog.tenzhiyang.com/2018-09-10-sew-many-images/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2018-09-10-sew-many-images/</guid><pubDate>Mon, 10 Sep 2018 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;100% JavaScript implementation for CSS image sprite generator.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.npmjs.com/package/sew-many-images&quot;&gt;Use it now!&lt;/a&gt;&lt;/p&gt;</content:encoded><content:raw>
100% JavaScript implementation for CSS image sprite generator.

[Use it now!](https://www.npmjs.com/package/sew-many-images)
</content:raw></item><item><title><![CDATA[Post hackathon 2018]]></title><description><![CDATA[I’m writing this in 2019, although it will be filed in 2018 for my life’s chronological order, but this is more of a reflection on what was…]]></description><link>https://blog.tenzhiyang.com/2018-08-05-post-hackathon/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2018-08-05-post-hackathon/</guid><pubDate>Sun, 05 Aug 2018 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 66.89189189189189%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAIEAwX/xAAWAQEBAQAAAAAAAAAAAAAAAAABAAL/2gAMAwEAAhADEAAAAcHknbrimX//xAAbEAADAAIDAAAAAAAAAAAAAAABAgMABCEzQv/aAAgBAQABBQIWKMtiGlyKZ51+v//EABURAQEAAAAAAAAAAAAAAAAAAAEQ/9oACAEDAQE/ASf/xAAVEQEBAAAAAAAAAAAAAAAAAAAAAf/aAAgBAgEBPwGq/8QAGhAAAgIDAAAAAAAAAAAAAAAAAAECURARgf/aAAgBAQAGPwJqzURt2LHT/8QAGhAAAgMBAQAAAAAAAAAAAAAAAAERITGhQf/aAAgBAQABPyFSNg+GRG9E9I2I2i4VifQ3Q//aAAwDAQACAAMAAAAQk8//xAAWEQEBAQAAAAAAAAAAAAAAAAAAASH/2gAIAQMBAT8QrEf/xAAXEQEBAQEAAAAAAAAAAAAAAAABABEh/9oACAECAQE/EBrLt//EABwQAQACAgMBAAAAAAAAAAAAAAEAESGBMUFRYf/aAAgBAQABPxC9xCgPiUoRN0K93EMA01qYK28cRw5u+3MZcP/Z) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/97ad3ab868c16f75cc43c07e2597d0e4/a80bd/hackathon.jpg 148w,
/static/97ad3ab868c16f75cc43c07e2597d0e4/1c91a/hackathon.jpg 295w,
/static/97ad3ab868c16f75cc43c07e2597d0e4/1c72d/hackathon.jpg 590w,
/static/97ad3ab868c16f75cc43c07e2597d0e4/a8a14/hackathon.jpg 885w,
/static/97ad3ab868c16f75cc43c07e2597d0e4/fbd2c/hackathon.jpg 1180w,
/static/97ad3ab868c16f75cc43c07e2597d0e4/127b0/hackathon.jpg 6669w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/97ad3ab868c16f75cc43c07e2597d0e4/1c72d/hackathon.jpg&quot;
        srcset=&quot;/static/97ad3ab868c16f75cc43c07e2597d0e4/a80bd/hackathon.jpg 148w,
/static/97ad3ab868c16f75cc43c07e2597d0e4/1c91a/hackathon.jpg 295w,
/static/97ad3ab868c16f75cc43c07e2597d0e4/1c72d/hackathon.jpg 590w,
/static/97ad3ab868c16f75cc43c07e2597d0e4/a8a14/hackathon.jpg 885w,
/static/97ad3ab868c16f75cc43c07e2597d0e4/fbd2c/hackathon.jpg 1180w,
/static/97ad3ab868c16f75cc43c07e2597d0e4/127b0/hackathon.jpg 6669w&quot;
        title=&quot;image&quot;
        alt=&quot;image&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;p&gt;I’m writing this in 2019, although it will be filed in 2018 for my life’s chronological order, but this is more of a reflection on what was different here as well as what I think was amazing here.&lt;/p&gt;
&lt;p&gt;Now apart from the incredible luck of having 1) a good idea delivered right to my team and 2) the really sicko teams were out of topic there’s some really good thing we can take from here.&lt;/p&gt;
&lt;p&gt;Firstly the fact that our idea was presentable. I think the problem with my 2019 idea was that unless we had a flawless implementation, we couldn’t demonstrate the idea properly. Our 2018 demonstration sucked ass but the idea was very obvious, the presentation itself was also very easy to understand what was going on at the end.&lt;/p&gt;
&lt;p&gt;Secondly, the project was an incredibly small scope. using a deterministic solution is really the key here. Having something that wasn’t up to chance means debugging is really do-able.&lt;/p&gt;
&lt;p&gt;Finally I think complexity of UI made this project take just a little bit too much time. UI has to look good, but it has also have to be simple.&lt;/p&gt;</content:encoded><content:raw>
![image](./hackathon.jpg)

I&apos;m writing this in 2019, although it will be filed in 2018 for my life&apos;s chronological order, but this is more of a reflection on what was different here as well as what I think was amazing here.

Now apart from the incredible luck of having 1) a good idea delivered right to my team and 2) the really sicko teams were out of topic there&apos;s some really good thing we can take from here.

Firstly the fact that our idea was presentable. I think the problem with my 2019 idea was that unless we had a flawless implementation, we couldn&apos;t demonstrate the idea properly. Our 2018 demonstration sucked ass but the idea was very obvious, the presentation itself was also very easy to understand what was going on at the end.

Secondly, the project was an incredibly small scope. using a deterministic solution is really the key here. Having something that wasn&apos;t up to chance means debugging is really do-able.

Finally I think complexity of UI made this project take just a little bit too much time. UI has to look good, but it has also have to be simple.
</content:raw></item><item><title><![CDATA[@sg_carparks_bot]]></title><description><![CDATA[Sg carparks is a telegram bot that I developed to help find nearby parking lots. You send the bot your current location, and it brings up…]]></description><link>https://blog.tenzhiyang.com/2017-10-16-sg-carparks/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2017-10-16-sg-carparks/</guid><pubDate>Mon, 16 Oct 2017 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Sg carparks is a telegram bot that I developed to help find nearby parking lots. You send the bot your current location, and it brings up the five nearest carparks from that location and lists out the carparks rate. You can also click on the carpark names returned to you and it will redirect you to google maps for you to find your current location.&lt;/p&gt;
&lt;h3&gt;bot is now down due to lack of maintenance and changes in api&lt;/h3&gt;</content:encoded><content:raw>
Sg carparks is a telegram bot that I developed to help find nearby parking lots. You send the bot your current location, and it brings up the five nearest carparks from that location and lists out the carparks rate. You can also click on the carpark names returned to you and it will redirect you to google maps for you to find your current location.

### bot is now down due to lack of maintenance and changes in api
</content:raw></item><item><title><![CDATA[Midichlorians]]></title><description><![CDATA[A project developed for a module, Midichlorians is an iPad app implementation of the famous Midi-controller Launchpad. This project was done…]]></description><link>https://blog.tenzhiyang.com/2017-10-16-midichlorians/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2017-10-16-midichlorians/</guid><pubDate>Mon, 16 Oct 2017 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;A project developed for a module, Midichlorians is an iPad app implementation of the famous Midi-controller Launchpad. This project was done over a period of 6 weeks, in a team of 4 people. Features include audio synch to dropbox, customised animations, recording playback, and multiple music profiles.&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 66.89189189189189%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAMEAv/EABUBAQEAAAAAAAAAAAAAAAAAAAID/9oADAMBAAIQAxAAAAEqmaEo0TX/xAAaEAACAgMAAAAAAAAAAAAAAAABAgADEhMi/9oACAEBAAEFAkv6LTIPNCljSItYVf/EABYRAQEBAAAAAAAAAAAAAAAAAAABEf/aAAgBAwEBPwFsf//EABYRAQEBAAAAAAAAAAAAAAAAAAEAEf/aAAgBAgEBPwHZHb//xAAdEAABAwUBAAAAAAAAAAAAAAAAAQIRAxIhMTNx/9oACAEBAAY/AnNqP8Oil2yRckH/xAAZEAEAAwEBAAAAAAAAAAAAAAABABEhMUH/2gAIAQEAAT8hQQ2Vg9ig5oWlEQgUJizs9iFW2Au6n//aAAwDAQACAAMAAAAQE8//xAAVEQEBAAAAAAAAAAAAAAAAAAABAP/aAAgBAwEBPxBCCL//xAAXEQEBAQEAAAAAAAAAAAAAAAABABEh/9oACAECAQE/EB52Um//xAAaEAEBAAMBAQAAAAAAAAAAAAABEQAhMUGh/9oACAEBAAE/EERhWs/EccbElUnnM0KSCMNZSbpHmIGxjrLbTZee5//Z) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/43006f58db6e792f3af6cb58b0630e5a/a80bd/midi.jpg 148w,
/static/43006f58db6e792f3af6cb58b0630e5a/1c91a/midi.jpg 295w,
/static/43006f58db6e792f3af6cb58b0630e5a/1c72d/midi.jpg 590w,
/static/43006f58db6e792f3af6cb58b0630e5a/a8a14/midi.jpg 885w,
/static/43006f58db6e792f3af6cb58b0630e5a/fbd2c/midi.jpg 1180w,
/static/43006f58db6e792f3af6cb58b0630e5a/c58a3/midi.jpg 1500w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/43006f58db6e792f3af6cb58b0630e5a/1c72d/midi.jpg&quot;
        srcset=&quot;/static/43006f58db6e792f3af6cb58b0630e5a/a80bd/midi.jpg 148w,
/static/43006f58db6e792f3af6cb58b0630e5a/1c91a/midi.jpg 295w,
/static/43006f58db6e792f3af6cb58b0630e5a/1c72d/midi.jpg 590w,
/static/43006f58db6e792f3af6cb58b0630e5a/a8a14/midi.jpg 885w,
/static/43006f58db6e792f3af6cb58b0630e5a/fbd2c/midi.jpg 1180w,
/static/43006f58db6e792f3af6cb58b0630e5a/c58a3/midi.jpg 1500w&quot;
        title=&quot;steps&quot;
        alt=&quot;steps&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;
&lt;p&gt;We won first place in our module (of 10 groups) during NUS’s
&lt;a href=&quot;http://isteps.comp.nus.edu.sg/event/10th-steps/modules&quot;&gt;10th STePS&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=_LfiVj5-uJ4&quot;&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 75%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAIFAQT/xAAVAQEBAAAAAAAAAAAAAAAAAAAAAf/aAAwDAQACEAMQAAABjOvZEs0r/8QAGhAAAgIDAAAAAAAAAAAAAAAAAgMAEwEEEP/aAAgBAQABBQJS7DcnKiiW1GW6Rc//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAbEAABBAMAAAAAAAAAAAAAAAABAAIQURExMv/aAAgBAQAGPwINtY3AdS5Ef//EABsQAQACAgMAAAAAAAAAAAAAAAEAERAhMWGR/9oACAEBAAE/IUM1arnIHasIKWwRv2i2rP/aAAwDAQACAAMAAAAQXw//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAWEQADAAAAAAAAAAAAAAAAAAAQESH/2gAIAQIBAT8QrH//xAAbEAADAAMBAQAAAAAAAAAAAAAAAREhMVFhcf/aAAgBAQABPxB49aCwqODqk/nV6QQjcqT1oaExcVszEkrsP//Z) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/87e2b38172b1c51fbe639187da26b5fa/a80bd/0.jpg 148w,
/static/87e2b38172b1c51fbe639187da26b5fa/1c91a/0.jpg 295w,
/static/87e2b38172b1c51fbe639187da26b5fa/7cc5e/0.jpg 480w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/87e2b38172b1c51fbe639187da26b5fa/7cc5e/0.jpg&quot;
        srcset=&quot;/static/87e2b38172b1c51fbe639187da26b5fa/a80bd/0.jpg 148w,
/static/87e2b38172b1c51fbe639187da26b5fa/1c91a/0.jpg 295w,
/static/87e2b38172b1c51fbe639187da26b5fa/7cc5e/0.jpg 480w&quot;
        title=&quot;midichlorians&quot;
        alt=&quot;midichlorians&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://itunes.apple.com/ca/app/midichlorians/id1229585861?mt=8&quot;&gt;Download here&lt;/a&gt;&lt;/p&gt;</content:encoded><content:raw>
A project developed for a module, Midichlorians is an iPad app implementation of the famous Midi-controller Launchpad. This project was done over a period of 6 weeks, in a team of 4 people. Features include audio synch to dropbox, customised animations, recording playback, and multiple music profiles.

![steps](./midi.jpg)

We won first place in our module (of 10 groups) during NUS&apos;s
[10th STePS](http://isteps.comp.nus.edu.sg/event/10th-steps/modules)

[![midichlorians](https://img.youtube.com/vi/_LfiVj5-uJ4/0.jpg)](https://www.youtube.com/watch?v=_LfiVj5-uJ4)

[Download here](https://itunes.apple.com/ca/app/midichlorians/id1229585861?mt=8)
</content:raw></item><item><title><![CDATA[F450 Programmable Drone]]></title><description><![CDATA[This was my first self-assembled quadcopter. Under the guidance of an NUS lecturer, Dr Colin Tan, I assembled the 450 frame drone and…]]></description><link>https://blog.tenzhiyang.com/2017-10-15-f450-drone/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2017-10-15-f450-drone/</guid><pubDate>Sun, 15 Oct 2017 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;This was my first self-assembled quadcopter. Under the guidance of an NUS lecturer, Dr Colin Tan, I assembled the 450 frame drone and changed the circuitry with 3DR’s pixhawk flight controller, and connected it to a Futaba transmitter and receiver kit.&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 75%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAQB/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAH/2gAMAwEAAhADEAAAAYlWRO0v/8QAGRABAQEAAwAAAAAAAAAAAAAAAQARAhAS/9oACAEBAAEFAvPKHbOsCUv/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAXEAEAAwAAAAAAAAAAAAAAAAARACAx/9oACAEBAAY/AnYV/8QAGhAAAwEBAQEAAAAAAAAAAAAAAAERIUFRYf/aAAgBAQABPyHobn0piXvwexasJXuvWVn/2gAMAwEAAgADAAAAEIzP/8QAFREBAQAAAAAAAAAAAAAAAAAAEBH/2gAIAQMBAT8Qp//EABURAQEAAAAAAAAAAAAAAAAAAAEQ/9oACAECAQE/ECf/xAAaEAEAAwEBAQAAAAAAAAAAAAABABEhMRBx/9oACAEBAAE/EMDrFOpiiLgEp4CiKrgs6LKdZ3UX5P/Z) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/f7db16470fa99f5b3a89472888d6e377/a80bd/f450.jpg 148w,
/static/f7db16470fa99f5b3a89472888d6e377/1c91a/f450.jpg 295w,
/static/f7db16470fa99f5b3a89472888d6e377/1c72d/f450.jpg 590w,
/static/f7db16470fa99f5b3a89472888d6e377/a8a14/f450.jpg 885w,
/static/f7db16470fa99f5b3a89472888d6e377/6a068/f450.jpg 960w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/f7db16470fa99f5b3a89472888d6e377/1c72d/f450.jpg&quot;
        srcset=&quot;/static/f7db16470fa99f5b3a89472888d6e377/a80bd/f450.jpg 148w,
/static/f7db16470fa99f5b3a89472888d6e377/1c91a/f450.jpg 295w,
/static/f7db16470fa99f5b3a89472888d6e377/1c72d/f450.jpg 590w,
/static/f7db16470fa99f5b3a89472888d6e377/a8a14/f450.jpg 885w,
/static/f7db16470fa99f5b3a89472888d6e377/6a068/f450.jpg 960w&quot;
        title=&quot;f450&quot;
        alt=&quot;f450&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;</content:encoded><content:raw>
This was my first self-assembled quadcopter. Under the guidance of an NUS lecturer, Dr Colin Tan, I assembled the 450 frame drone and changed the circuitry with 3DR&apos;s pixhawk flight controller, and connected it to a Futaba transmitter and receiver kit.

![f450](./f450.jpg)
</content:raw></item><item><title><![CDATA[Give For Free]]></title><description><![CDATA[Give For Free was a project thought up by a good friend of mine. The idea was simple: Snap pictures of your preloved goods on Give For Free…]]></description><link>https://blog.tenzhiyang.com/2017-10-14-giveforfree/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2017-10-14-giveforfree/</guid><pubDate>Sat, 14 Oct 2017 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Give For Free was a project thought up by a good friend of mine. The idea was simple: Snap pictures of your preloved goods on Give For Free, choose your favourite charity and how much you think your items are worth. When another user wants your item, they will donate to your charity at your listed price. We managed to onboard SPCA and had over 500 users within two weeks of launch.&lt;/p&gt;
&lt;p&gt;The actual site was taken down due to server costs, and we managed to raise almost 400 dollars for SPCA. &lt;a href=&quot;https://www.facebook.com/give4free/&quot;&gt;Facebook promotional page here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 75%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAMEAv/EABUBAQEAAAAAAAAAAAAAAAAAAAAC/9oADAMBAAIQAxAAAAGiNdMVoaH/xAAcEAACAgIDAAAAAAAAAAAAAAABAgADBBIREyL/2gAIAQEAAQUCddWBLP2SzI9VPzBXsP/EABURAQEAAAAAAAAAAAAAAAAAAAAh/9oACAEDAQE/AVf/xAAWEQEBAQAAAAAAAAAAAAAAAAAAESH/2gAIAQIBAT8BjH//xAAbEAACAgMBAAAAAAAAAAAAAAAAAQIhERIxIv/aAAgBAQAGPwJJEfJwqyLZtnp//8QAGhAAAwEBAQEAAAAAAAAAAAAAAAERITFBUf/aAAgBAQABPyHUbbTZ8O9Q9OXCV9uUVAmeGop6P//aAAwDAQACAAMAAAAQKy//xAAVEQEBAAAAAAAAAAAAAAAAAAAREP/aAAgBAwEBPxBZ/8QAFhEAAwAAAAAAAAAAAAAAAAAAARAR/9oACAECAQE/EBCf/8QAGhABAAMBAQEAAAAAAAAAAAAAAQARIUFRMf/aAAgBAQABPxC8Io0orix5UKBH3sUCuksekw8VHQyGWxVHpfkMlaVhP//Z) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/c69aa4e071f329eb83601e0673afdddf/a80bd/gff.jpg 148w,
/static/c69aa4e071f329eb83601e0673afdddf/1c91a/gff.jpg 295w,
/static/c69aa4e071f329eb83601e0673afdddf/1c72d/gff.jpg 590w,
/static/c69aa4e071f329eb83601e0673afdddf/a8a14/gff.jpg 885w,
/static/c69aa4e071f329eb83601e0673afdddf/6a068/gff.jpg 960w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/c69aa4e071f329eb83601e0673afdddf/1c72d/gff.jpg&quot;
        srcset=&quot;/static/c69aa4e071f329eb83601e0673afdddf/a80bd/gff.jpg 148w,
/static/c69aa4e071f329eb83601e0673afdddf/1c91a/gff.jpg 295w,
/static/c69aa4e071f329eb83601e0673afdddf/1c72d/gff.jpg 590w,
/static/c69aa4e071f329eb83601e0673afdddf/a8a14/gff.jpg 885w,
/static/c69aa4e071f329eb83601e0673afdddf/6a068/gff.jpg 960w&quot;
        title=&quot;gff&quot;
        alt=&quot;gff&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;</content:encoded><content:raw>
Give For Free was a project thought up by a good friend of mine. The idea was simple: Snap pictures of your preloved goods on Give For Free, choose your favourite charity and how much you think your items are worth. When another user wants your item, they will donate to your charity at your listed price. We managed to onboard SPCA and had over 500 users within two weeks of launch.

The actual site was taken down due to server costs, and we managed to raise almost 400 dollars for SPCA. [Facebook promotional page here](https://www.facebook.com/give4free/)

![gff](./gff.jpg)
</content:raw></item><item><title><![CDATA[USB Game Controller (From Old Portfolio)]]></title><description><![CDATA[When playing Binding of Isaac which was a dual thumb stick shooter (control character with one thumb stick, control direction of your…]]></description><link>https://blog.tenzhiyang.com/2017-10-12-usb-controller/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2017-10-12-usb-controller/</guid><pubDate>Thu, 12 Oct 2017 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;When playing Binding of Isaac which was a dual thumb stick shooter (control character with one thumb stick, control direction of your bullets with another) , I realised that the market does not really sell a controller that has dual thumb sticks in the center, most are either too far down (PS style) or at offset positions (Xbox style). As I wanted to make some custom controllers for a while (more on that when the parts arrive!), I decided to make a USB controller specifically for this game.&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 56.08108108108108%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAQBAwX/xAAVAQEBAAAAAAAAAAAAAAAAAAAAAf/aAAwDAQACEAMQAAABWthuXKGQ/8QAGxAAAgIDAQAAAAAAAAAAAAAAAQIAAxETIjH/2gAIAQEAAQUC1plVQw4Mr9Q9WDv/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAVEQEBAAAAAAAAAAAAAAAAAAAQMf/aAAgBAgEBPwGH/8QAGhAAAwEAAwAAAAAAAAAAAAAAAAECERAhcf/aAAgBAQAGPwKm61IyZfp2iuGf/8QAGhABAAIDAQAAAAAAAAAAAAAAAQAhETFhcf/aAAgBAQABPyFBVpJDb3GRahSweMNfkQINMIIJ/9oADAMBAAIAAwAAABBbL//EABcRAAMBAAAAAAAAAAAAAAAAAAABIRH/2gAIAQMBAT8QVWlP/8QAFREBAQAAAAAAAAAAAAAAAAAAAQD/2gAIAQIBAT8QYJf/xAAbEAEBAQADAQEAAAAAAAAAAAABEQAhMUGBof/aAAgBAQABPxCdC/S1zxFvoCclPbqEITtP3FwiRz66fzgQwSAHf//Z) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/2994a5cb3bff99c5b2b517068345e137/a80bd/contro1.jpg 148w,
/static/2994a5cb3bff99c5b2b517068345e137/1c91a/contro1.jpg 295w,
/static/2994a5cb3bff99c5b2b517068345e137/1c72d/contro1.jpg 590w,
/static/2994a5cb3bff99c5b2b517068345e137/a8a14/contro1.jpg 885w,
/static/2994a5cb3bff99c5b2b517068345e137/fbd2c/contro1.jpg 1180w,
/static/2994a5cb3bff99c5b2b517068345e137/3fe84/contro1.jpg 1599w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/2994a5cb3bff99c5b2b517068345e137/1c72d/contro1.jpg&quot;
        srcset=&quot;/static/2994a5cb3bff99c5b2b517068345e137/a80bd/contro1.jpg 148w,
/static/2994a5cb3bff99c5b2b517068345e137/1c91a/contro1.jpg 295w,
/static/2994a5cb3bff99c5b2b517068345e137/1c72d/contro1.jpg 590w,
/static/2994a5cb3bff99c5b2b517068345e137/a8a14/contro1.jpg 885w,
/static/2994a5cb3bff99c5b2b517068345e137/fbd2c/contro1.jpg 1180w,
/static/2994a5cb3bff99c5b2b517068345e137/3fe84/contro1.jpg 1599w&quot;
        title=&quot;usb&quot;
        alt=&quot;usb&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    

      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 56.08108108108108%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAIEAf/EABYBAQEBAAAAAAAAAAAAAAAAAAEAA//aAAwDAQACEAMQAAABjskzMcQn/8QAGRAAAwEBAQAAAAAAAAAAAAAAAAECEQMS/9oACAEBAAEFAuclQlJLw91p/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFhABAQEAAAAAAAAAAAAAAAAAEDEA/9oACAEBAAY/AtWn/8QAGBAAAwEBAAAAAAAAAAAAAAAAAAERMYH/2gAIAQEAAT8htrKIdGYKQ2Kf/9oADAMBAAIAAwAAABCXz//EABYRAQEBAAAAAAAAAAAAAAAAAAABEf/aAAgBAwEBPxBtf//EABcRAAMBAAAAAAAAAAAAAAAAAAEQMRH/2gAIAQIBAT8QGG1f/8QAGBABAQEBAQAAAAAAAAAAAAAAAREAITH/2gAIAQEAAT8QvTp6syApQsTLHkaQqLxymkeTKeu//9k=) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/2e4820bef3ea9cab44f4ea7cc96450d9/a80bd/contro2.jpg 148w,
/static/2e4820bef3ea9cab44f4ea7cc96450d9/1c91a/contro2.jpg 295w,
/static/2e4820bef3ea9cab44f4ea7cc96450d9/1c72d/contro2.jpg 590w,
/static/2e4820bef3ea9cab44f4ea7cc96450d9/a8a14/contro2.jpg 885w,
/static/2e4820bef3ea9cab44f4ea7cc96450d9/fbd2c/contro2.jpg 1180w,
/static/2e4820bef3ea9cab44f4ea7cc96450d9/3fe84/contro2.jpg 1599w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/2e4820bef3ea9cab44f4ea7cc96450d9/1c72d/contro2.jpg&quot;
        srcset=&quot;/static/2e4820bef3ea9cab44f4ea7cc96450d9/a80bd/contro2.jpg 148w,
/static/2e4820bef3ea9cab44f4ea7cc96450d9/1c91a/contro2.jpg 295w,
/static/2e4820bef3ea9cab44f4ea7cc96450d9/1c72d/contro2.jpg 590w,
/static/2e4820bef3ea9cab44f4ea7cc96450d9/a8a14/contro2.jpg 885w,
/static/2e4820bef3ea9cab44f4ea7cc96450d9/fbd2c/contro2.jpg 1180w,
/static/2e4820bef3ea9cab44f4ea7cc96450d9/3fe84/contro2.jpg 1599w&quot;
        title=&quot;usb&quot;
        alt=&quot;usb&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    

      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 56.08108108108108%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAwABBP/EABUBAQEAAAAAAAAAAAAAAAAAAAID/9oADAMBAAIQAxAAAAEdDoKaCc//xAAZEAACAwEAAAAAAAAAAAAAAAABAgADISL/2gAIAQEAAQUCqPLjVuKA46aAJ//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oACAEDAQE/AUf/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAZEAACAwEAAAAAAAAAAAAAAAAAARARIjH/2gAIAQEABj8C0zLKopcG3H//xAAbEAEAAgIDAAAAAAAAAAAAAAABABEhMUFRof/aAAgBAQABPyGleGJzlEsldFvM6dYgNwDEBNT/2gAMAwEAAgADAAAAEMDv/8QAFxEAAwEAAAAAAAAAAAAAAAAAAAERUf/aAAgBAwEBPxB1laf/xAAXEQADAQAAAAAAAAAAAAAAAAAAARFR/9oACAECAQE/EFEVYf/EABkQAQEBAQEBAAAAAAAAAAAAAAERACExQf/aAAgBAQABPxCx+kKgNMPMIvE9MdBrqYjCBA99DGRZl5O54td3/9k=) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/b19253aa15dcd686a9b2ce73bcdb5f26/a80bd/contro3.jpg 148w,
/static/b19253aa15dcd686a9b2ce73bcdb5f26/1c91a/contro3.jpg 295w,
/static/b19253aa15dcd686a9b2ce73bcdb5f26/1c72d/contro3.jpg 590w,
/static/b19253aa15dcd686a9b2ce73bcdb5f26/a8a14/contro3.jpg 885w,
/static/b19253aa15dcd686a9b2ce73bcdb5f26/fbd2c/contro3.jpg 1180w,
/static/b19253aa15dcd686a9b2ce73bcdb5f26/3fe84/contro3.jpg 1599w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/b19253aa15dcd686a9b2ce73bcdb5f26/1c72d/contro3.jpg&quot;
        srcset=&quot;/static/b19253aa15dcd686a9b2ce73bcdb5f26/a80bd/contro3.jpg 148w,
/static/b19253aa15dcd686a9b2ce73bcdb5f26/1c91a/contro3.jpg 295w,
/static/b19253aa15dcd686a9b2ce73bcdb5f26/1c72d/contro3.jpg 590w,
/static/b19253aa15dcd686a9b2ce73bcdb5f26/a8a14/contro3.jpg 885w,
/static/b19253aa15dcd686a9b2ce73bcdb5f26/fbd2c/contro3.jpg 1180w,
/static/b19253aa15dcd686a9b2ce73bcdb5f26/3fe84/contro3.jpg 1599w&quot;
        title=&quot;usb&quot;
        alt=&quot;usb&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    

      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 56.08108108108108%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAIBAwT/xAAVAQEBAAAAAAAAAAAAAAAAAAABAP/aAAwDAQACEAMQAAABrkQUMxP/xAAaEAACAgMAAAAAAAAAAAAAAAABAgADISIz/9oACAEBAAEFAqwpV9Vy0p42kwT/xAAWEQEBAQAAAAAAAAAAAAAAAAAAARL/2gAIAQMBAT8BZtf/xAAWEQEBAQAAAAAAAAAAAAAAAAAAARH/2gAIAQIBAT8BbH//xAAaEAACAgMAAAAAAAAAAAAAAAAAARARIlFx/9oACAEBAAY/AtmJaYuz/8QAGxABAAIDAQEAAAAAAAAAAAAAAQARIVFhMUH/2gAIAQEAAT8hGlUNyvyGomYnJ5eoIoZmZn//2gAMAwEAAgADAAAAEAs//8QAGBEBAQADAAAAAAAAAAAAAAAAAQARITH/2gAIAQMBAT8QDG7sG//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oACAECAQE/EKg//8QAHBABAAIDAAMAAAAAAAAAAAAAAQARITFBUWFx/9oACAEBAAE/ECM7WfrsBAWteDHwim2KY14G33SS4kHYQXLVFLWf/9k=) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/aac4692f482b300d11086c64feeb68d2/a80bd/contro4.jpg 148w,
/static/aac4692f482b300d11086c64feeb68d2/1c91a/contro4.jpg 295w,
/static/aac4692f482b300d11086c64feeb68d2/1c72d/contro4.jpg 590w,
/static/aac4692f482b300d11086c64feeb68d2/a8a14/contro4.jpg 885w,
/static/aac4692f482b300d11086c64feeb68d2/fbd2c/contro4.jpg 1180w,
/static/aac4692f482b300d11086c64feeb68d2/3fe84/contro4.jpg 1599w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/aac4692f482b300d11086c64feeb68d2/1c72d/contro4.jpg&quot;
        srcset=&quot;/static/aac4692f482b300d11086c64feeb68d2/a80bd/contro4.jpg 148w,
/static/aac4692f482b300d11086c64feeb68d2/1c91a/contro4.jpg 295w,
/static/aac4692f482b300d11086c64feeb68d2/1c72d/contro4.jpg 590w,
/static/aac4692f482b300d11086c64feeb68d2/a8a14/contro4.jpg 885w,
/static/aac4692f482b300d11086c64feeb68d2/fbd2c/contro4.jpg 1180w,
/static/aac4692f482b300d11086c64feeb68d2/3fe84/contro4.jpg 1599w&quot;
        title=&quot;usb&quot;
        alt=&quot;usb&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;</content:encoded><content:raw>
When playing Binding of Isaac which was a dual thumb stick shooter (control character with one thumb stick, control direction of your bullets with another) , I realised that the market does not really sell a controller that has dual thumb sticks in the center, most are either too far down (PS style) or at offset positions (Xbox style). As I wanted to make some custom controllers for a while (more on that when the parts arrive!), I decided to make a USB controller specifically for this game.

![usb](./contro1.jpg)
![usb](./contro2.jpg)
![usb](./contro3.jpg)
![usb](./contro4.jpg)
</content:raw></item><item><title><![CDATA[Project Dawn (From Old Portfolio)]]></title><description><![CDATA[My first foray into Internet Of Things, this was quite a leap of faith for me. A friend (Hi Wei Lun!) asked me “is it possible to feel what…]]></description><link>https://blog.tenzhiyang.com/2017-10-11-Project-Dawn/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2017-10-11-Project-Dawn/</guid><pubDate>Wed, 11 Oct 2017 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;My first foray into Internet Of Things, this was quite a leap of faith for me. A friend (Hi Wei Lun!) asked me “is it possible to feel what it is like to be in another persons shoes?” This would be the start of my involvement in Project Dawn.&lt;/p&gt;
&lt;p&gt;Project Dawn aimed to present a novel and innovative experiential approach to learning about the stigma surrounding mental illnesses. Essentially, Project dawn was an interactive exhibition. Powered by an Arduino Mega (clone), I had android phones connected via tcp sockets to my computer which was acting as the command center of the whole set up. The android phones would play a narration, asking participants to interact with various objects and would pause until they did the required action, after which the mobile app would continue playing the narration&lt;/p&gt;
&lt;p&gt;For Interaction with the objects, I used RFID tags and Sensors. When the object was picked up, the Sensor would stop reading signal from the RFID. The mega would then listen for when the object was placed back on again.&lt;/p&gt;
&lt;p&gt;To track which room the participants were in, I set up laser pointers wired to be permanently on, and put LDRs on the other side. This crude set up was due to my failure at implementing an Indoor Positioning System with Bluetooth, and running out of time. I could have used better forms of Proximity sensors, but waiting for delivery would have been too long. I intend to come back to IPS one day.&lt;/p&gt;
&lt;p&gt;Unfortunately I was not wise enough to take pictures of the set up, but here are a couple of pictures of the event:&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 75%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAMFBP/EABUBAQEAAAAAAAAAAAAAAAAAAAEA/9oADAMBAAIQAxAAAAGPVTslI8H/xAAaEAADAAMBAAAAAAAAAAAAAAABAgMAEiIR/9oACAEBAAEFAh00rEKvWRTR0CLTT0//xAAVEQEBAAAAAAAAAAAAAAAAAAAQEf/aAAgBAwEBPwGH/8QAFREBAQAAAAAAAAAAAAAAAAAAARD/2gAIAQIBAT8BWf/EABoQAAMBAAMAAAAAAAAAAAAAAAABEQISMVH/2gAIAQEABj8CiXZxwmO+kebo0pC5Z//EABoQAAMBAQEBAAAAAAAAAAAAAAABESExUWH/2gAIAQEAAT8hqCXg5Gvo2ixhaMjbeGFKJoasxN7fT//aAAwDAQACAAMAAAAQA+//xAAXEQADAQAAAAAAAAAAAAAAAAABEBEx/9oACAEDAQE/EBGr/8QAFhEBAQEAAAAAAAAAAAAAAAAAAQBB/9oACAECAQE/EMCG/8QAHBABAAMAAgMAAAAAAAAAAAAAAQARITFRQXGh/9oACAEBAAE/EGC4AptQWQG1a295MmihLuBbZcEfj3CMg2boTh705m6qP0T/2Q==) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/3c0c5d8e0f0704f6b3da1e74ab0eac0c/a80bd/dawn1.jpg 148w,
/static/3c0c5d8e0f0704f6b3da1e74ab0eac0c/1c91a/dawn1.jpg 295w,
/static/3c0c5d8e0f0704f6b3da1e74ab0eac0c/1c72d/dawn1.jpg 590w,
/static/3c0c5d8e0f0704f6b3da1e74ab0eac0c/a8a14/dawn1.jpg 885w,
/static/3c0c5d8e0f0704f6b3da1e74ab0eac0c/fbd2c/dawn1.jpg 1180w,
/static/3c0c5d8e0f0704f6b3da1e74ab0eac0c/768c6/dawn1.jpg 3264w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/3c0c5d8e0f0704f6b3da1e74ab0eac0c/1c72d/dawn1.jpg&quot;
        srcset=&quot;/static/3c0c5d8e0f0704f6b3da1e74ab0eac0c/a80bd/dawn1.jpg 148w,
/static/3c0c5d8e0f0704f6b3da1e74ab0eac0c/1c91a/dawn1.jpg 295w,
/static/3c0c5d8e0f0704f6b3da1e74ab0eac0c/1c72d/dawn1.jpg 590w,
/static/3c0c5d8e0f0704f6b3da1e74ab0eac0c/a8a14/dawn1.jpg 885w,
/static/3c0c5d8e0f0704f6b3da1e74ab0eac0c/fbd2c/dawn1.jpg 1180w,
/static/3c0c5d8e0f0704f6b3da1e74ab0eac0c/768c6/dawn1.jpg 3264w&quot;
        title=&quot;dawn&quot;
        alt=&quot;dawn&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    

      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 75%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAQCAwX/xAAVAQEBAAAAAAAAAAAAAAAAAAABAv/aAAwDAQACEAMQAAABVmpaVpigx//EABoQAAMBAAMAAAAAAAAAAAAAAAECAxEAEjH/2gAIAQEAAQUCodKhlLzcGftK7btz/8QAFREBAQAAAAAAAAAAAAAAAAAAACL/2gAIAQMBAT8BU//EABYRAQEBAAAAAAAAAAAAAAAAAAARIf/aAAgBAgEBPwGRj//EABsQAAICAwEAAAAAAAAAAAAAAAABAhEhMUFx/9oACAEBAAY/AlFMjjZhWL0vhbWz/8QAGxABAAMBAAMAAAAAAAAAAAAAAQARMSFBgeH/2gAIAQEAAT8hahh6wzd9ZTfQiuraTrMtVAoI8uP2f//aAAwDAQACAAMAAAAQKz//xAAXEQADAQAAAAAAAAAAAAAAAAAAASER/9oACAEDAQE/EINajP/EABYRAQEBAAAAAAAAAAAAAAAAAAERAP/aAAgBAgEBPxBpLhz/xAAbEAEAAwEBAQEAAAAAAAAAAAABABEhMVGRof/aAAgBAQABPxAcAlQtsclYgqML5z7KyCGvA+bFOgwem9uUNrSrwYtOiimnD8T/2Q==) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/ab7de6bec45778f99398a68f58a48470/a80bd/dawn2.jpg 148w,
/static/ab7de6bec45778f99398a68f58a48470/1c91a/dawn2.jpg 295w,
/static/ab7de6bec45778f99398a68f58a48470/1c72d/dawn2.jpg 590w,
/static/ab7de6bec45778f99398a68f58a48470/a8a14/dawn2.jpg 885w,
/static/ab7de6bec45778f99398a68f58a48470/fbd2c/dawn2.jpg 1180w,
/static/ab7de6bec45778f99398a68f58a48470/768c6/dawn2.jpg 3264w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/ab7de6bec45778f99398a68f58a48470/1c72d/dawn2.jpg&quot;
        srcset=&quot;/static/ab7de6bec45778f99398a68f58a48470/a80bd/dawn2.jpg 148w,
/static/ab7de6bec45778f99398a68f58a48470/1c91a/dawn2.jpg 295w,
/static/ab7de6bec45778f99398a68f58a48470/1c72d/dawn2.jpg 590w,
/static/ab7de6bec45778f99398a68f58a48470/a8a14/dawn2.jpg 885w,
/static/ab7de6bec45778f99398a68f58a48470/fbd2c/dawn2.jpg 1180w,
/static/ab7de6bec45778f99398a68f58a48470/768c6/dawn2.jpg 3264w&quot;
        title=&quot;dawn&quot;
        alt=&quot;dawn&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;</content:encoded><content:raw>
My first foray into Internet Of Things, this was quite a leap of faith for me. A friend (Hi Wei Lun!) asked me &quot;is it possible to feel what it is like to be in another persons shoes?&quot; This would be the start of my involvement in Project Dawn.

Project Dawn aimed to present a novel and innovative experiential approach to learning about the stigma surrounding mental illnesses. Essentially, Project dawn was an interactive exhibition. Powered by an Arduino Mega (clone), I had android phones connected via tcp sockets to my computer which was acting as the command center of the whole set up. The android phones would play a narration, asking participants to interact with various objects and would pause until they did the required action, after which the mobile app would continue playing the narration

For Interaction with the objects, I used RFID tags and Sensors. When the object was picked up, the Sensor would stop reading signal from the RFID. The mega would then listen for when the object was placed back on again.

To track which room the participants were in, I set up laser pointers wired to be permanently on, and put LDRs on the other side. This crude set up was due to my failure at implementing an Indoor Positioning System with Bluetooth, and running out of time. I could have used better forms of Proximity sensors, but waiting for delivery would have been too long. I intend to come back to IPS one day.

Unfortunately I was not wise enough to take pictures of the set up, but here are a couple of pictures of the event:

![dawn](./dawn1.jpg)
![dawn](./dawn2.jpg)
</content:raw></item><item><title><![CDATA[IoT Scale (From Old Portfolio)]]></title><description><![CDATA[This is a project for my internship at Boon Software for Breadtalk. Powered by an Arduino clone(again), this device uses and ESP8266 which…]]></description><link>https://blog.tenzhiyang.com/2017-10-10-iot-scale/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2017-10-10-iot-scale/</guid><pubDate>Tue, 10 Oct 2017 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;This is a project for my internship at Boon Software for Breadtalk. Powered by an Arduino clone(again), this device uses and ESP8266 which communicates to the Arduino via Serial i/o. I wrote my own TCP Sender and Receiver on both the Arduino side as well as the Java side. There are many things that could be improved, but this is the first version.&lt;/p&gt;
&lt;p&gt;The idea of this Weighing scale is that whenever the number of bread (teabags are used in the video) falls below a certain threshold, the bakers will get a message in their kitchen that they need to bake more. This is especially useful for promotional items, such as the currently running salted egg yolk croissant where the manager is unable to use previous sales value (because it is a one-off item) to estimate how much bread each outlet needs.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=wi4-E1bA4Mc&quot;&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 75%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAEEAwX/xAAVAQEBAAAAAAAAAAAAAAAAAAAAAf/aAAwDAQACEAMQAAAB5tSUYlBX/8QAGhAAAwEBAQEAAAAAAAAAAAAAAQIDAAQSFP/aAAgBAQABBQJpBQs4+CswV6ZjHplvqQb/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAVEQEBAAAAAAAAAAAAAAAAAAABEP/aAAgBAgEBPwEn/8QAGRAAAgMBAAAAAAAAAAAAAAAAABEBMTKh/9oACAEBAAY/AmiJXSipMMzw/8QAGxABAAICAwAAAAAAAAAAAAAAAQARITFRYXH/2gAIAQEAAT8hzoSWsbTMV67xAdvsQ79mBqKx/9oADAMBAAIAAwAAABDYL//EABYRAQEBAAAAAAAAAAAAAAAAABEAAf/aAAgBAwEBPxBNnb//xAAWEQEBAQAAAAAAAAAAAAAAAAARECH/2gAIAQIBAT8QRs//xAAeEAEAAgIBBQAAAAAAAAAAAAABABEhUXExodHh8P/aAAgBAQABPxAkmMdfcVlXJWHi4goFVAuL5iwbeg13iRVPxVy6I6B5n//Z) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/1b0de777c1f9139a95794ec0c0de1c2f/a80bd/0.jpg 148w,
/static/1b0de777c1f9139a95794ec0c0de1c2f/1c91a/0.jpg 295w,
/static/1b0de777c1f9139a95794ec0c0de1c2f/7cc5e/0.jpg 480w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/1b0de777c1f9139a95794ec0c0de1c2f/7cc5e/0.jpg&quot;
        srcset=&quot;/static/1b0de777c1f9139a95794ec0c0de1c2f/a80bd/0.jpg 148w,
/static/1b0de777c1f9139a95794ec0c0de1c2f/1c91a/0.jpg 295w,
/static/1b0de777c1f9139a95794ec0c0de1c2f/7cc5e/0.jpg 480w&quot;
        title=&quot;IoT Scale&quot;
        alt=&quot;IoT Scale&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/a&gt;&lt;/p&gt;</content:encoded><content:raw>This is a project for my internship at Boon Software for Breadtalk. Powered by an Arduino clone(again), this device uses and ESP8266 which communicates to the Arduino via Serial i/o. I wrote my own TCP Sender and Receiver on both the Arduino side as well as the Java side. There are many things that could be improved, but this is the first version.

The idea of this Weighing scale is that whenever the number of bread (teabags are used in the video) falls below a certain threshold, the bakers will get a message in their kitchen that they need to bake more. This is especially useful for promotional items, such as the currently running salted egg yolk croissant where the manager is unable to use previous sales value (because it is a one-off item) to estimate how much bread each outlet needs.

[![IoT Scale](https://img.youtube.com/vi/wi4-E1bA4Mc/0.jpg)](https://www.youtube.com/watch?v=wi4-E1bA4Mc)
</content:raw></item><item><title><![CDATA[LiPo USB Charger (From Old Portfolio)]]></title><description><![CDATA[Another quick but more useful project, I used what I learnt from the bench top power supply to make this USB power-cutter (for lack of a…]]></description><link>https://blog.tenzhiyang.com/2017-10-09-drone-charger-v1/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2017-10-09-drone-charger-v1/</guid><pubDate>Mon, 09 Oct 2017 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Another quick but more useful project, I used what I learnt from the bench top power supply to make this USB power-cutter (for lack of a better name). I needed a Device to turn off power after charging my Hubsan X4 for exactly 1 hour, as over charging the batteries was highly discouraged. I got a cheap Arduino micro clone I had lying around and attached it to a couple of female jumper wires. This was then connected to a relay. The timer is hardcoded into the Arduino. Maybe one day I will upgrade it with an LCD and some buttons, maybe use a one channel relay since that is all I need and put it in a proper enclosure. In the meantime, this will do!&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 56.08108108108108%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAABAACBf/EABUBAQEAAAAAAAAAAAAAAAAAAAIB/9oADAMBAAIQAxAAAAELgdUtlmM//8QAGxAAAgEFAAAAAAAAAAAAAAAAAAMBAhEhIjL/2gAIAQEAAQUC6qVq4VkTEWP/xAAXEQADAQAAAAAAAAAAAAAAAAACEBES/9oACAEDAQE/ARmV/8QAFREBAQAAAAAAAAAAAAAAAAAAARD/2gAIAQIBAT8BZ//EABgQAAIDAAAAAAAAAAAAAAAAAAAQESGB/9oACAEBAAY/AjFZK//EABsQAAMAAgMAAAAAAAAAAAAAAAABERAhMUGB/9oACAEBAAE/IYvWCyWo4GhL7bZQhVPnH//aAAwDAQACAAMAAAAQr+//xAAXEQADAQAAAAAAAAAAAAAAAAAAAREx/9oACAEDAQE/EEpdIf/EABYRAQEBAAAAAAAAAAAAAAAAAAARAf/aAAgBAgEBPxDcV//EABoQAAMBAQEBAAAAAAAAAAAAAAABESExQZH/2gAIAQEAAT8QTS/XxYRutDj4JoqiVSjzNqlGpFZ//9k=) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/8298575e0b879741c17850d516abac1b/a80bd/lipo.jpg 148w,
/static/8298575e0b879741c17850d516abac1b/1c91a/lipo.jpg 295w,
/static/8298575e0b879741c17850d516abac1b/1c72d/lipo.jpg 590w,
/static/8298575e0b879741c17850d516abac1b/a8a14/lipo.jpg 885w,
/static/8298575e0b879741c17850d516abac1b/fbd2c/lipo.jpg 1180w,
/static/8298575e0b879741c17850d516abac1b/3fe84/lipo.jpg 1599w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/8298575e0b879741c17850d516abac1b/1c72d/lipo.jpg&quot;
        srcset=&quot;/static/8298575e0b879741c17850d516abac1b/a80bd/lipo.jpg 148w,
/static/8298575e0b879741c17850d516abac1b/1c91a/lipo.jpg 295w,
/static/8298575e0b879741c17850d516abac1b/1c72d/lipo.jpg 590w,
/static/8298575e0b879741c17850d516abac1b/a8a14/lipo.jpg 885w,
/static/8298575e0b879741c17850d516abac1b/fbd2c/lipo.jpg 1180w,
/static/8298575e0b879741c17850d516abac1b/3fe84/lipo.jpg 1599w&quot;
        title=&quot;lipo&quot;
        alt=&quot;lipo&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;</content:encoded><content:raw>
Another quick but more useful project, I used what I learnt from the bench top power supply to make this USB power-cutter (for lack of a better name). I needed a Device to turn off power after charging my Hubsan X4 for exactly 1 hour, as over charging the batteries was highly discouraged. I got a cheap Arduino micro clone I had lying around and attached it to a couple of female jumper wires. This was then connected to a relay. The timer is hardcoded into the Arduino. Maybe one day I will upgrade it with an LCD and some buttons, maybe use a one channel relay since that is all I need and put it in a proper enclosure. In the meantime, this will do!

![lipo](./lipo.jpg)
</content:raw></item><item><title><![CDATA[Bottle Dynamo (From Old Portfolio)]]></title><description><![CDATA[I saw this bottle dynamo on sale at Sim Lim towers and learnt that bottle dynamos could be retrofitted on most bicycles and decided to try…]]></description><link>https://blog.tenzhiyang.com/2017-10-08-Bottle-Dynamo/</link><guid isPermaLink="false">https://blog.tenzhiyang.com/2017-10-08-Bottle-Dynamo/</guid><pubDate>Sun, 08 Oct 2017 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;I saw this bottle dynamo on sale at Sim Lim towers and learnt that bottle dynamos could be retrofitted on most bicycles and decided to try to add it on my bike. I learnt to make a diode bridge to change the AC circuit into DC, and put a capacitor over the circuit so that the light would not blink. Pretty simple circuit, and the results were decent although not very pretty.&lt;/p&gt;
&lt;p&gt;
      &lt;div class=&quot;gria-image-wrapper&quot; style=&quot;
        position: relative;
        overflow: hidden;
        
      &quot;&gt;
      
        
          &lt;div class=&quot;gria-image-padding&quot; style=&quot;
        width: 100%;
        padding-bottom: 177.70270270270268%;
      &quot;&gt;&lt;/div&gt;
        
        
      
      &lt;div
        class=&quot;gria-image-placeholder&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          background: #fff url(data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAkABQDASIAAhEBAxEB/8QAGAABAQEBAQAAAAAAAAAAAAAAAAQCBQP/xAAVAQEBAAAAAAAAAAAAAAAAAAAAAf/aAAwDAQACEAMQAAABs5fRhSVSjecXLh7COoTQX//EABwQAAIBBQEAAAAAAAAAAAAAAAABAgMQERIhIv/aAAgBAQABBQKt0kjUmVEaE8xFGTEuSErY82//xAAVEQEBAAAAAAAAAAAAAAAAAAARIP/aAAgBAwEBPwEr/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAgEBPwFf/8QAGxAAAgIDAQAAAAAAAAAAAAAAARAAEQIgIUH/2gAIAQEABj8C0oerhMtW84F//8QAHRAAAwACAgMAAAAAAAAAAAAAAAERITEQUUFhcf/aAAgBAQABPyGc0hZBl5ERMyEiUOkvbpIfZPJtstvKKmjrhpSdi188f//aAAwDAQACAAMAAAAQi/qNDC//xAAXEQEBAQEAAAAAAAAAAAAAAAABABEg/9oACAEDAQE/EBWRx//EABcRAQEBAQAAAAAAAAAAAAAAAAEAESD/2gAIAQIBAT8QW2eP/8QAHhABAQEBAQABBQAAAAAAAAAAAREAITFBYXGBkaH/2gAIAQEAAT8QTLD7kyFuabj6mewXkfgwj1CVMerI6WZlMmC9/OgnzBq9ylXMU9e9/RMAkIvNA5NwxR73afQ/zK3f/9k=) center / cover no-repeat;
        &quot;
      &gt;&lt;/div&gt;
    
    &lt;picture&gt;
      &lt;source srcset=&quot;/static/8adb2ad86bcbfdd71ed69df8e345517f/a80bd/bike.jpg 148w,
/static/8adb2ad86bcbfdd71ed69df8e345517f/1c91a/bike.jpg 295w,
/static/8adb2ad86bcbfdd71ed69df8e345517f/1c72d/bike.jpg 590w,
/static/8adb2ad86bcbfdd71ed69df8e345517f/80e3c/bike.jpg 720w&quot;&gt;
      &lt;img
        class=&quot;gria-image&quot;
        src=&quot;/static/8adb2ad86bcbfdd71ed69df8e345517f/1c72d/bike.jpg&quot;
        srcset=&quot;/static/8adb2ad86bcbfdd71ed69df8e345517f/a80bd/bike.jpg 148w,
/static/8adb2ad86bcbfdd71ed69df8e345517f/1c91a/bike.jpg 295w,
/static/8adb2ad86bcbfdd71ed69df8e345517f/1c72d/bike.jpg 590w,
/static/8adb2ad86bcbfdd71ed69df8e345517f/80e3c/bike.jpg 720w&quot;
        title=&quot;BottleDynamo&quot;
        alt=&quot;BottleDynamo&quot;
        loading=&quot;lazy&quot;
        style=&quot;
          
  position: absolute;
  top: 0; left: 0;
  width: 100%;
  height: 100%;

          object-fit: cover;
          object-position: center center;&quot;
      &gt;
    &lt;/picture&gt;
  
      &lt;/div&gt;
    &lt;/p&gt;</content:encoded><content:raw>
I saw this bottle dynamo on sale at Sim Lim towers and learnt that bottle dynamos could be retrofitted on most bicycles and decided to try to add it on my bike. I learnt to make a diode bridge to change the AC circuit into DC, and put a capacitor over the circuit so that the light would not blink. Pretty simple circuit, and the results were decent although not very pretty.

![BottleDynamo](./bike.jpg)
</content:raw></item></channel></rss>